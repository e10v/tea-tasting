{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"tea-tasting: statistical analysis of A/B tests","text":"<p>tea-tasting is a Python package for the statistical analysis of A/B tests featuring:</p> <ul> <li>Student's t-test, Z-test, bootstrap, and quantile metrics out of the box.</li> <li>Extensible API that lets you define and use statistical tests of your choice.</li> <li>Delta method for ratio metrics.</li> <li>Variance reduction using CUPED/CUPAC, which can be combined with the Delta method for ratio metrics.</li> <li>Confidence intervals for both absolute and percentage changes.</li> <li>Checks for sample-ratio mismatches.</li> <li>Power analysis.</li> <li>Multiple hypothesis testing (family-wise error rate and false discovery rate).</li> <li>Simulated experiments, including A/A tests.</li> </ul> <p>tea-tasting calculates statistics directly within data backends such as BigQuery, ClickHouse, DuckDB, PostgreSQL, Snowflake, Spark, and many other backends supported by Ibis. This approach eliminates the need to import granular data into a Python environment.</p> <p>tea-tasting also accepts dataframes supported by Narwhals: cuDF, Dask, Modin, pandas, Polars, PyArrow.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>uv pip install tea-tasting\n</code></pre>"},{"location":"#basic-example","title":"Basic example","text":"<pre><code>&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; data = tt.make_users_data(seed=42)\n&gt;&gt;&gt; experiment = tt.Experiment(\n...     sessions_per_user=tt.Mean(\"sessions\"),\n...     orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\"),\n...     orders_per_user=tt.Mean(\"orders\"),\n...     revenue_per_user=tt.Mean(\"revenue\"),\n... )\n&gt;&gt;&gt; result = experiment.analyze(data)\n&gt;&gt;&gt; result\n            metric control treatment rel_effect_size rel_effect_size_ci pvalue\n sessions_per_user    2.00      1.98          -0.66%      [-3.7%, 2.5%]  0.674\norders_per_session   0.266     0.289            8.8%      [-0.89%, 19%] 0.0762\n   orders_per_user   0.530     0.573            8.0%       [-2.0%, 19%]  0.118\n  revenue_per_user    5.24      5.73            9.3%       [-2.4%, 22%]  0.123\n</code></pre> <p>Learn more in the detailed user guide. Additionally, see the guides on more specific topics:</p> <ul> <li>Data backends.</li> <li>Power analysis.</li> <li>Multiple hypothesis testing.</li> <li>Custom metrics.</li> <li>Simulated experiments.</li> </ul>"},{"location":"#examples","title":"Examples","text":"<p>The tea-tasting repository includes examples as copies of the guides in the marimo notebook format. You can either download them from GitHub and run in your local environment, or you can run them as WASM notebooks in the online playground.</p>"},{"location":"#run-in-a-local-environment","title":"Run in a local environment","text":"<p>To run the examples in your local environment, clone the repository and change the directory:</p> <pre><code>git clone git@github.com:e10v/tea-tasting.git &amp;&amp; cd tea-tasting\n</code></pre> <p>Install marimo, tea-tasting, and other packages used in the examples:</p> <pre><code>uv venv &amp;&amp; uv pip install marimo tea-tasting polars ibis-framework[duckdb]\n</code></pre> <p>Launch the notebook server:</p> <pre><code>uv run marimo edit examples\n</code></pre> <p>Now you can choose and run the example notebooks.</p>"},{"location":"#run-in-the-online-playground","title":"Run in the online playground","text":"<p>To run the examples as WASM notebooks in the online playground, open the following links:</p> <ul> <li>User guide.</li> <li>Data backends.</li> <li>Power analysis.</li> <li>Multiple hypothesis testing.</li> <li>Custom metrics.</li> <li>Simulated experiments.</li> </ul> <p>WASM notebooks run entirely in the browser on Pyodide and thus have some limitations. In particular:</p> <ul> <li>Tables and dataframes render less attractively because Pyodide doesn't always include the latest packages versions.</li> <li>You can't simulate experiments in parallel because Pyodide currently doesn't support multiprocessing.</li> <li>Other unpredictable issues may arise, such as the inability to use duckdb with ibis.</li> </ul>"},{"location":"#package-name","title":"Package name","text":"<p>The package name \"tea-tasting\" is a play on words that refers to two subjects:</p> <ul> <li>Lady tasting tea is a famous experiment which was devised by Ronald Fisher. In this experiment, Fisher developed the null hypothesis significance testing framework to analyze a lady's claim that she could discern whether the tea or the milk was added first to the cup.</li> <li>\"tea-tasting\" phonetically resembles \"t-testing\", referencing Student's t-test, a statistical method developed by William Gosset.</li> </ul>"},{"location":"custom-metrics/","title":"Custom metrics","text":""},{"location":"custom-metrics/#intro","title":"Intro","text":"<p>tea-tasting supports Student's t-test, Z-test, and some other statistical tests out of the box. However, you might want to analyze an experiment using other statistical criteria. In this case, you can define a custom metric with a statistical test of your choice.</p> <p>In tea-tasting, there are two types of metrics:</p> <ul> <li>Metrics that require only aggregated statistics for the analysis.</li> <li>Metrics that require granular data for the analysis.</li> </ul> <p>This guide explains how to define a custom metric for each type.</p> <p>First, let's import all the required modules and prepare the data:</p> <pre><code>&gt;&gt;&gt; from typing import Literal, NamedTuple\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import pyarrow.compute as pc\n&gt;&gt;&gt; import scipy.stats\n&gt;&gt;&gt; import tea_tasting as tt\n&gt;&gt;&gt; import tea_tasting.aggr\n&gt;&gt;&gt; import tea_tasting.config\n&gt;&gt;&gt; import tea_tasting.metrics\n&gt;&gt;&gt; import tea_tasting.utils\n\n&gt;&gt;&gt; data = tt.make_users_data(seed=42)\n&gt;&gt;&gt; data = data.append_column(\n...     \"has_order\",\n...     pc.greater(data[\"orders\"], 0).cast(pa.int64()),\n... )\n&gt;&gt;&gt; data\npyarrow.Table\nuser: int64\nvariant: int64\nsessions: int64\norders: int64\nrevenue: double\nhas_order: int64\n----\nuser: [[0,1,2,3,4,...,3995,3996,3997,3998,3999]]\nvariant: [[1,0,1,1,0,...,0,0,0,0,0]]\nsessions: [[2,2,2,2,1,...,2,2,3,1,5]]\norders: [[1,1,1,1,1,...,0,0,0,0,2]]\nrevenue: [[9.17,6.43,7.94,15.93,7.14,...,0,0,0,0,17.16]]\nhas_order: [[1,1,1,1,1,...,0,0,0,0,1]]\n</code></pre> <p>This guide uses PyArrow as the data backend, but it's valid for other backends as well. See the guide on data backends for more details.</p>"},{"location":"custom-metrics/#metrics-based-on-aggregated-statistics","title":"Metrics based on aggregated statistics","text":"<p>Let's define a metric that performs a proportion test, G-test or Pearson's chi-squared test, on a binary column (with values <code>0</code> or <code>1</code>).</p> <p>The first step is defining a result class. It should be a named tuple or a dictionary.</p> <pre><code>&gt;&gt;&gt; class ProportionResult(NamedTuple):\n...     control: float\n...     treatment: float\n...     effect_size: float\n...     rel_effect_size: float\n...     pvalue: float\n...     statistic: float\n... \n</code></pre> <p>The second step is defining the metric class itself. A metric based on aggregated statistics should be a subclass of <code>MetricBaseAggregated</code>. <code>MetricBaseAggregated</code> is a generic class with the result class as a type variable.</p> <p>The metric should have the following methods and properties defined:</p> <ul> <li>Method <code>__init__</code> checks and saves metric parameters.</li> <li>Property <code>aggr_cols</code> returns columns to be aggregated for analysis for each type of statistic.</li> <li>Method <code>analyze_aggregates</code> analyzes the metric using aggregated statistics.</li> </ul> <p>Let's define the metric and discuss each method in details:</p> <pre><code>&gt;&gt;&gt; class Proportion(tea_tasting.metrics.MetricBaseAggregated[ProportionResult]):\n...     def __init__(\n...         self,\n...         column: str,\n...         *,\n...         correction: bool = True,\n...         method: Literal[\"g-test\", \"pearson\"] = \"g-test\",\n...     ) -&gt; None:\n...         self.column = tea_tasting.utils.check_scalar(column, \"column\", typ=str)\n...         self.correction = tea_tasting.utils.auto_check(correction, \"correction\")\n...         self.method = tea_tasting.utils.check_scalar(\n...             method, \"method\", typ=str, in_={\"g-test\", \"pearson\"})\n...     @property\n...     def aggr_cols(self) -&gt; tea_tasting.metrics.AggrCols:\n...         return tea_tasting.metrics.AggrCols(\n...             has_count=True,\n...             mean_cols=(self.column,),\n...         )\n...     def analyze_aggregates(\n...         self,\n...         control: tea_tasting.aggr.Aggregates,\n...         treatment: tea_tasting.aggr.Aggregates,\n...     ) -&gt; ProportionResult:\n...         observed = np.empty(shape=(2, 2), dtype=np.int64)\n...         observed[0, 0] = round(control.count() * control.mean(self.column))\n...         observed[1, 0] = control.count() - observed[0, 0]\n...         observed[0, 1] = round(treatment.count() * treatment.mean(self.column))\n...         observed[1, 1] = treatment.count() - observed[0, 1]\n...         res = scipy.stats.chi2_contingency(\n...             observed=observed,\n...             correction=self.correction,\n...             lambda_=int(self.method == \"pearson\"),\n...         )\n...         return ProportionResult(\n...             control=control.mean(self.column),\n...             treatment=treatment.mean(self.column),\n...             effect_size=treatment.mean(self.column) - control.mean(self.column),\n...             rel_effect_size=treatment.mean(self.column)/control.mean(self.column) - 1,\n...             pvalue=res.pvalue,\n...             statistic=res.statistic,\n...         )\n... \n</code></pre> <p>Method <code>__init__</code> saves metric parameters to be used in the analysis. You can use utility functions <code>check_scalar</code> and <code>auto_check</code> to check parameter values.</p> <p>Property <code>aggr_cols</code> returns an instance of <code>AggrCols</code>. Analysis of proportion requires the number of rows (<code>has_count=True</code>) and the average value for the column of interest (<code>mean_cols=(self.column,)</code>) for each variant.</p> <p>Method <code>analyze_aggregates</code> accepts two parameters: <code>control</code> and <code>treatment</code> data as instances of class <code>Aggregates</code>. They contain values for statistics and columns specified in <code>aggr_cols</code>.</p> <p>Method <code>analyze_aggregates</code> returns an instance of <code>ProportionResult</code>, defined earlier, with the analysis result.</p> <p>Now we can analyze the proportion of users who created at least one order during the experiment. For comparison, let's also add a metric that performs a Z-test on the same column.</p> <pre><code>&gt;&gt;&gt; experiment_prop = tt.Experiment(\n...     prop_users_with_orders=Proportion(\"has_order\"),\n...     mean_users_with_orders=tt.Mean(\"has_order\", use_t=False),\n... )\n&gt;&gt;&gt; experiment_prop.analyze(data)\n                metric control treatment rel_effect_size rel_effect_size_ci pvalue\nprop_users_with_orders   0.345     0.384             11%             [-, -] 0.0117\nmean_users_with_orders   0.345     0.384             11%        [2.5%, 21%] 0.0106\n</code></pre>"},{"location":"custom-metrics/#metrics-based-on-granular-data","title":"Metrics based on granular data","text":"<p>Now let's define a metric that performs the Mann-Whitney U test. While it's possible to use the aggregated sum of ranks for the test, this example uses granular data for analysis.</p> <p>The result class:</p> <pre><code>&gt;&gt;&gt; class MannWhitneyUResult(NamedTuple):\n...     pvalue: float\n...     statistic: float\n... \n</code></pre> <p>A metric that analyzes granular data should be a subclass of <code>MetricBaseGranular</code>. <code>MetricBaseGranular</code> is a generic class with the result class as a type variable.</p> <p>Metric should have the following methods and properties defined:</p> <ul> <li>Method <code>__init__</code> checks and saves metric parameters.</li> <li>Property <code>cols</code> returns columns to be fetched for an analysis.</li> <li>Method <code>analyze_granular</code> analyzes the metric using granular data.</li> </ul> <pre><code>&gt;&gt;&gt; class MannWhitneyU(tea_tasting.metrics.MetricBaseGranular[MannWhitneyUResult]):\n...     def __init__(\n...         self,\n...         column: str,\n...         *,\n...         correction: bool = True,\n...         alternative: Literal[\"two-sided\", \"less\", \"greater\"] | None = None,\n...     ) -&gt; None:\n...         self.column = tea_tasting.utils.check_scalar(column, \"column\", typ=str)\n...         self.correction = tea_tasting.utils.auto_check(correction, \"correction\")\n...         self.alternative = (\n...             tea_tasting.utils.auto_check(alternative, \"alternative\")\n...             if alternative is not None\n...             else tea_tasting.config.get_config(\"alternative\")\n...         )\n...     @property\n...     def cols(self) -&gt; tuple[str]:\n...         return (self.column,)\n...     def analyze_granular(\n...         self,\n...         control: pa.Table,\n...         treatment: pa.Table,\n...     ) -&gt; MannWhitneyUResult:\n...         res = scipy.stats.mannwhitneyu(\n...             treatment[self.column].combine_chunks().to_numpy(zero_copy_only=False),\n...             control[self.column].combine_chunks().to_numpy(zero_copy_only=False),\n...             use_continuity=self.correction,\n...             alternative=self.alternative,\n...         )\n...         return MannWhitneyUResult(\n...             pvalue=res.pvalue,\n...             statistic=res.statistic,\n...         )\n... \n</code></pre> <p>Property <code>cols</code> should return a sequence of strings.</p> <p>Method <code>analyze_granular</code> accepts two parameters: control and treatment data as PyArrow Tables. Even with data backend different from PyArrow, tea-tasting will retrieve the data and transform into a PyArrow Table.</p> <p>Method <code>analyze_granular</code> returns an instance of <code>MannWhitneyUResult</code>, defined earlier, with analysis result.</p> <p>Now we can perform the Mann-Whitney U test:</p> <pre><code>&gt;&gt;&gt; experiment_mwu = tt.Experiment(\n...     mwu_orders=MannWhitneyU(\"orders\"),\n...     mwu_revenue=MannWhitneyU(\"revenue\"),\n... )\n&gt;&gt;&gt; result_mwu = experiment_mwu.analyze(data)\n&gt;&gt;&gt; result_mwu.with_keys((\"metric\", \"pvalue\", \"statistic\"))\n     metric pvalue statistic\n mwu_orders 0.0263   2069092\nmwu_revenue 0.0300   2068060\n</code></pre>"},{"location":"custom-metrics/#analyzing-two-types-of-metrics-together","title":"Analyzing two types of metrics together","text":"<p>It's also possible to analyze two types of metrics in one experiment:</p> <pre><code>&gt;&gt;&gt; experiment = tt.Experiment(\n...     prop_users_with_orders=Proportion(\"has_order\"),\n...     mean_users_with_orders=tt.Mean(\"has_order\"),\n...     mwu_orders=MannWhitneyU(\"orders\"),\n...     mwu_revenue=MannWhitneyU(\"revenue\"),\n... )\n&gt;&gt;&gt; experiment.analyze(data)\n                metric control treatment rel_effect_size rel_effect_size_ci pvalue\nprop_users_with_orders   0.345     0.384             11%             [-, -] 0.0117\nmean_users_with_orders   0.345     0.384             11%        [2.5%, 21%] 0.0106\n            mwu_orders       -         -               -             [-, -] 0.0263\n           mwu_revenue       -         -               -             [-, -] 0.0300\n</code></pre> <p>In this case, tea-tasting performs two queries on the experimental data:</p> <ul> <li>With aggregated statistics required for analysis of metrics of type <code>MetricBaseAggregated</code>.</li> <li>With detailed data with columns required for analysis of metrics of type <code>MetricBaseGranular</code>.</li> </ul>"},{"location":"custom-metrics/#recommendations","title":"Recommendations","text":"<p>Follow these recommendations when defining custom metrics:</p> <ul> <li>Use parameter and attribute names consistent with the ones that are already defined in tea-tasting. For example, use <code>pvalue</code> instead of <code>p_value</code> or <code>correction</code> instead of <code>use_continuity</code>.</li> <li>End confidence interval boundary names with <code>\"_ci_lower\"</code> and <code>\"_ci_upper\"</code>.</li> <li>During initialization, save parameter values in metric attributes using the same names. For example, use <code>self.correction = correction</code> instead of <code>self.use_continuity = correction</code>.</li> <li>Use global settings as default values for standard parameters, such as <code>alternative</code> or <code>confidence_level</code>. See the reference for the full list of standard parameters. You can also define and use your own global parameters.</li> </ul>"},{"location":"data-backends/","title":"Data backends","text":""},{"location":"data-backends/#intro","title":"Intro","text":"<p>tea-tasting supports a wide range of data backends such as BigQuery, ClickHouse, DuckDB, PostgreSQL, Snowflake, Spark, and many other backends supported by Ibis. Ibis is a DataFrame API to various data backends.</p> <p>Many statistical tests, such as the Student's t-test or the Z-test, require only aggregated data for analysis. For these tests, tea-tasting retrieves only aggregated statistics like mean and variance instead of downloading all detailed data.</p> <p>For example, if the raw experimental data are stored in ClickHouse, it's faster and more efficient to calculate counts, averages, variances, and covariances directly in ClickHouse rather than fetching granular data and performing aggregations in a Python environment.</p> <p>tea-tasting also accepts dataframes supported by Narwhals: cuDF, Dask, Modin, pandas, Polars, PyArrow. Narwhals is a compatibility layer between dataframe libraries.</p> <p>This guide:</p> <ul> <li>Shows how to use tea-tasting with a data backend of your choice for the analysis of an experiment.</li> <li>Explains some internals of how tea-tasting uses Ibis to work with data backends.</li> </ul>"},{"location":"data-backends/#demo-database","title":"Demo database","text":"<p>Note</p> <p>This guide uses DuckDB, an in-process analytical database, and Polars as example data backends. Install these packages in addition to tea-tasting to reproduce the examples:</p> <pre><code>uv pip install ibis-framework[duckdb] polars\n</code></pre> <p>First, let's prepare a demo database:</p> <pre><code>&gt;&gt;&gt; import ibis\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; users_data = tt.make_users_data(seed=42)\n&gt;&gt;&gt; con = ibis.connect(\"duckdb://\")\n&gt;&gt;&gt; con.create_table(\"users_data\", users_data)\nDatabaseTable: memory.main.users_data\n  user     int64\n  variant  int64\n  sessions int64\n  orders   int64\n  revenue  float64\n</code></pre> <p>In the example above:</p> <ul> <li>Function <code>tt.make_users_data</code> returns a PyArrow Table with example experimental data.</li> <li>Function <code>ibis.duckdb.connect</code> creates a DuckDB in-process database using Ibis API.</li> <li>Method <code>con.create_table</code> creates and populates a table in the database based on the PyArrow Table.</li> </ul> <p>See the Ibis documentation on how to create connections to other data backends.</p>"},{"location":"data-backends/#querying-experimental-data","title":"Querying experimental data","text":"<p>Method <code>con.create_table</code> in the example above returns an Ibis Table which already can be used in the analysis of the experiment. But let's see how to use an SQL query to create an Ibis Table:</p> <pre><code>&gt;&gt;&gt; data = con.sql(\"select * from users_data\")\n&gt;&gt;&gt; data\nSQLQueryResult\n  query:\n    select * from users_data\n  schema:\n    user     int64\n    variant  int64\n    sessions int64\n    orders   int64\n    revenue  float64\n</code></pre> <p>It's a very simple query. In the real world, you might need to use joins, aggregations, and CTEs to get the data. You can define any SQL query supported by your data backend and use it to create Ibis Table.</p> <p>Keep in mind that tea-tasting assumes that:</p> <ul> <li>Data is grouped by randomization units, such as individual users.</li> <li>There is a column indicating the variant of the A/B test (typically labeled as A, B, etc.).</li> <li>All necessary columns for metric calculations (like the number of orders, revenue, etc.) are included in the table.</li> </ul> <p>Ibis Table is a lazy object. It doesn't fetch the data when created. You can use Ibis DataFrame API to query the table and fetch the result:</p> <pre><code>&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; print(data.head(5))\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 user  \u2503 variant \u2503 sessions \u2503 orders \u2503 revenue \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64 \u2502 int64   \u2502 int64    \u2502 int64  \u2502 float64 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502     0 \u2502       1 \u2502        2 \u2502      1 \u2502    9.17 \u2502\n\u2502     1 \u2502       0 \u2502        2 \u2502      1 \u2502    6.43 \u2502\n\u2502     2 \u2502       1 \u2502        2 \u2502      1 \u2502    7.94 \u2502\n\u2502     3 \u2502       1 \u2502        2 \u2502      1 \u2502   15.93 \u2502\n\u2502     4 \u2502       0 \u2502        1 \u2502      1 \u2502    7.14 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n&gt;&gt;&gt; ibis.options.interactive = False\n</code></pre>"},{"location":"data-backends/#ibis-example","title":"Ibis example","text":"<p>To better understand what Ibis does, let's consider the example with grouping and aggregation by variants:</p> <pre><code>&gt;&gt;&gt; aggr_data = data.group_by(\"variant\").aggregate(\n...     sessions_per_user=data.sessions.mean(),\n...     orders_per_session=data.orders.mean() / data.sessions.mean(),\n...     orders_per_user=data.orders.mean(),\n...     revenue_per_user=data.revenue.mean(),\n... )\n&gt;&gt;&gt; aggr_data\nr0 := SQLQueryResult\n  query:\n    select * from users_data\n  schema:\n    user     int64\n    variant  int64\n    sessions int64\n    orders   int64\n    revenue  float64\n\nAggregate[r0]\n  groups:\n    variant: r0.variant\n  metrics:\n    sessions_per_user:  Mean(r0.sessions)\n    orders_per_session: Mean(r0.orders) / Mean(r0.sessions)\n    orders_per_user:    Mean(r0.orders)\n    revenue_per_user:   Mean(r0.revenue)\n</code></pre> <p><code>aggr_data</code> is another Ibis Table defined as a query over the previously defined <code>data</code>. Let's fetch the result:</p> <pre><code>&gt;&gt;&gt; ibis.options.interactive = True\n&gt;&gt;&gt; print(aggr_data)\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 variant \u2503 sessions_per_user \u2503 orders_per_session \u2503 orders_per_user \u2503 revenue_per_user \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 int64   \u2502 float64           \u2502 float64            \u2502 float64         \u2502 float64          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502       0 \u2502          1.996045 \u2502           0.265726 \u2502        0.530400 \u2502         5.241028 \u2502\n\u2502       1 \u2502          1.982802 \u2502           0.289031 \u2502        0.573091 \u2502         5.730111 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n&gt;&gt;&gt; ibis.options.interactive = False\n</code></pre> <p>Internally, Ibis compiles a Table to an SQL query supported by the backend:</p> <pre><code>&gt;&gt;&gt; print(aggr_data.compile(pretty=True))\nSELECT\n  \"t0\".\"variant\",\n  AVG(\"t0\".\"sessions\") AS \"sessions_per_user\",\n  AVG(\"t0\".\"orders\") / AVG(\"t0\".\"sessions\") AS \"orders_per_session\",\n  AVG(\"t0\".\"orders\") AS \"orders_per_user\",\n  AVG(\"t0\".\"revenue\") AS \"revenue_per_user\"\nFROM (\n  SELECT\n    *\n  FROM users_data\n) AS \"t0\"\nGROUP BY\n  1\n</code></pre> <p>See Ibis documentation for more details.</p>"},{"location":"data-backends/#experiment-analysis","title":"Experiment analysis","text":"<p>The example above shows how to query the metric averages. But for statistical inference, it's not enough. For example, Student's t-test and Z-test also require number of rows and variance. Additionally, analysis of ratio metrics and variance reduction with CUPED requires covariances.</p> <p>Querying all the required statistics manually can be a daunting and error-prone task. But don't worry\u2014tea-tasting does this work for you. You just need to specify the metrics:</p> <pre><code>&gt;&gt;&gt; experiment = tt.Experiment(\n...     sessions_per_user=tt.Mean(\"sessions\"),\n...     orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\"),\n...     orders_per_user=tt.Mean(\"orders\"),\n...     revenue_per_user=tt.Mean(\"revenue\"),\n... )\n&gt;&gt;&gt; result = experiment.analyze(data)\n&gt;&gt;&gt; result\n            metric control treatment rel_effect_size rel_effect_size_ci pvalue\n sessions_per_user    2.00      1.98          -0.66%      [-3.7%, 2.5%]  0.674\norders_per_session   0.266     0.289            8.8%      [-0.89%, 19%] 0.0762\n   orders_per_user   0.530     0.573            8.0%       [-2.0%, 19%]  0.118\n  revenue_per_user    5.24      5.73            9.3%       [-2.4%, 22%]  0.123\n</code></pre> <p>In the example above, tea-tasting fetches all the required statistics with a single query and then uses them to analyze the experiment.</p> <p>Some statistical methods, like bootstrap, require granular data for analysis. In this case, tea-tasting fetches the detailed data as well.</p>"},{"location":"data-backends/#example-with-cuped","title":"Example with CUPED","text":"<p>An example of a slightly more complicated analysis using variance reduction with CUPED:</p> <pre><code>&gt;&gt;&gt; users_data_cuped = tt.make_users_data(seed=42, covariates=True)\n&gt;&gt;&gt; con.create_table(\"users_data_cuped\", users_data_cuped)\nDatabaseTable: memory.main.users_data_cuped\n  user               int64\n  variant            int64\n  sessions           int64\n  orders             int64\n  revenue            float64\n  sessions_covariate int64\n  orders_covariate   int64\n  revenue_covariate  float64\n\n&gt;&gt;&gt; data_cuped = con.sql(\"select * from users_data_cuped\")\n&gt;&gt;&gt; experiment_cuped = tt.Experiment(\n...     sessions_per_user=tt.Mean(\"sessions\", \"sessions_covariate\"),\n...     orders_per_session=tt.RatioOfMeans(\n...         numer=\"orders\",\n...         denom=\"sessions\",\n...         numer_covariate=\"orders_covariate\",\n...         denom_covariate=\"sessions_covariate\",\n...     ),\n...     orders_per_user=tt.Mean(\"orders\", \"orders_covariate\"),\n...     revenue_per_user=tt.Mean(\"revenue\", \"revenue_covariate\"),\n... )\n&gt;&gt;&gt; result_cuped = experiment_cuped.analyze(data_cuped)\n&gt;&gt;&gt; result_cuped\n            metric control treatment rel_effect_size rel_effect_size_ci  pvalue\n sessions_per_user    2.00      1.98          -0.68%      [-3.2%, 1.9%]   0.603\norders_per_session   0.262     0.293             12%        [4.2%, 21%] 0.00229\n   orders_per_user   0.523     0.581             11%        [2.9%, 20%] 0.00733\n  revenue_per_user    5.12      5.85             14%        [3.8%, 26%] 0.00674\n</code></pre>"},{"location":"data-backends/#polars-example","title":"Polars example","text":"<p>Here\u2019s an example of how to analyze data using a Polars DataFrame:</p> <pre><code>&gt;&gt;&gt; data_polars = pl.from_arrow(users_data)\n&gt;&gt;&gt; experiment.analyze(data_polars)\n            metric control treatment rel_effect_size rel_effect_size_ci pvalue\n sessions_per_user    2.00      1.98          -0.66%      [-3.7%, 2.5%]  0.674\norders_per_session   0.266     0.289            8.8%      [-0.89%, 19%] 0.0762\n   orders_per_user   0.530     0.573            8.0%       [-2.0%, 19%]  0.118\n  revenue_per_user    5.24      5.73            9.3%       [-2.4%, 22%]  0.123\n</code></pre>"},{"location":"multiple-testing/","title":"Multiple testing","text":""},{"location":"multiple-testing/#multiple-hypothesis-testing-problem","title":"Multiple hypothesis testing problem","text":"<p>Note</p> <p>This guide uses Polars as an example data backend. Install Polars in addition to tea-tasting to reproduce the examples:</p> <pre><code>uv pip install polars\n</code></pre> <p>The multiple hypothesis testing problem arises when there is more than one success metric or more than one treatment variant in an A/B test.</p> <p>tea-tasting provides the following methods for multiple testing correction:</p> <ul> <li>False discovery rate (FDR) controlling procedures:<ul> <li>Benjamini-Hochberg procedure, assuming non-negative correlation between hypotheses.</li> <li>Benjamini-Yekutieli procedure, assuming arbitrary dependence between hypotheses.</li> </ul> </li> <li>Family-wise error rate (FWER) controlling procedures:<ul> <li>Hochberg's step-up procedure, assuming non-negative correlation between hypotheses.</li> <li>Holm's step-down procedure, assuming arbitrary dependence between hypotheses.</li> </ul> </li> </ul> <p>As an example, consider an experiment with three variants, a control and two treatments:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; data = pl.concat((\n...     tt.make_users_data(\n...         seed=42,\n...         orders_uplift=0.10,\n...         revenue_uplift=0.15,\n...         return_type=\"polars\",\n...     ),\n...     tt.make_users_data(\n...         seed=21,\n...         orders_uplift=0.15,\n...         revenue_uplift=0.20,\n...         return_type=\"polars\",\n...     )\n...         .filter(pl.col(\"variant\").eq(1))\n...         .with_columns(variant=pl.lit(2, pl.Int64)),\n... ))\n&gt;&gt;&gt; data\nshape: (6_046, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 user \u2506 variant \u2506 sessions \u2506 orders \u2506 revenue \u2502\n\u2502 ---  \u2506 ---     \u2506 ---      \u2506 ---    \u2506 ---     \u2502\n\u2502 i64  \u2506 i64     \u2506 i64      \u2506 i64    \u2506 f64     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0    \u2506 1       \u2506 2        \u2506 1      \u2506 9.58    \u2502\n\u2502 1    \u2506 0       \u2506 2        \u2506 1      \u2506 6.43    \u2502\n\u2502 2    \u2506 1       \u2506 2        \u2506 1      \u2506 8.3     \u2502\n\u2502 3    \u2506 1       \u2506 2        \u2506 1      \u2506 16.65   \u2502\n\u2502 4    \u2506 0       \u2506 1        \u2506 1      \u2506 7.14    \u2502\n\u2502 \u2026    \u2506 \u2026       \u2506 \u2026        \u2506 \u2026      \u2506 \u2026       \u2502\n\u2502 3989 \u2506 2       \u2506 4        \u2506 4      \u2506 34.93   \u2502\n\u2502 3991 \u2506 2       \u2506 1        \u2506 0      \u2506 0.0     \u2502\n\u2502 3992 \u2506 2       \u2506 3        \u2506 3      \u2506 27.96   \u2502\n\u2502 3994 \u2506 2       \u2506 2        \u2506 1      \u2506 17.22   \u2502\n\u2502 3998 \u2506 2       \u2506 3        \u2506 0      \u2506 0.0     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Let's calculate the experiment results:</p> <pre><code>&gt;&gt;&gt; experiment = tt.Experiment(\n...     sessions_per_user=tt.Mean(\"sessions\"),\n...     orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\"),\n...     orders_per_user=tt.Mean(\"orders\"),\n...     revenue_per_user=tt.Mean(\"revenue\"),\n... )\n&gt;&gt;&gt; results = experiment.analyze(data, control=0, all_variants=True)\n&gt;&gt;&gt; results\nvariants             metric control treatment rel_effect_size rel_effect_size_ci  pvalue\n  (0, 1)  sessions_per_user    2.00      1.98          -0.66%      [-3.7%, 2.5%]   0.674\n  (0, 1) orders_per_session   0.266     0.289            8.8%      [-0.89%, 19%]  0.0762\n  (0, 1)    orders_per_user   0.530     0.573            8.0%       [-2.0%, 19%]   0.118\n  (0, 1)   revenue_per_user    5.24      5.99             14%        [2.1%, 28%]  0.0211\n  (0, 2)  sessions_per_user    2.00      2.02           0.98%      [-2.1%, 4.1%]   0.532\n  (0, 2) orders_per_session   0.266     0.295             11%        [1.2%, 22%]  0.0273\n  (0, 2)    orders_per_user   0.530     0.594             12%        [1.7%, 23%]  0.0213\n  (0, 2)   revenue_per_user    5.24      6.25             19%        [6.6%, 33%] 0.00218\n</code></pre> <p>Suppose only the two metrics <code>orders_per_user</code> and <code>revenue_per_user</code> are considered as success metrics, while the other two metrics <code>sessions_per_user</code> and <code>orders_per_session</code> are second-order diagnostic metrics.</p> <pre><code>&gt;&gt;&gt; metrics = {\"orders_per_user\", \"revenue_per_user\"}\n</code></pre> <p>With two treatment variants and two success metrics, there are four hypotheses in total, which increases the probability of false positives (also called \"false discoveries\"). It's recommended to adjust the p-values or the significance level (alpha) in this case. Let's explore the correction methods provided by tea-tasting.</p>"},{"location":"multiple-testing/#false-discovery-rate","title":"False discovery rate","text":"<p>False discovery rate (FDR) is the expected value of the proportion of false discoveries among the discoveries (rejections of the null hypothesis). To control for FDR, use the <code>adjust_fdr</code> method:</p> <pre><code>&gt;&gt;&gt; adjusted_results_fdr = tt.adjust_fdr(results, metrics)\n&gt;&gt;&gt; adjusted_results_fdr\ncomparison           metric control treatment rel_effect_size  pvalue pvalue_adj\n    (0, 1)  orders_per_user   0.530     0.573            8.0%   0.118      0.118\n    (0, 1) revenue_per_user    5.24      5.99             14%  0.0211     0.0284\n    (0, 2)  orders_per_user   0.530     0.594             12%  0.0213     0.0284\n    (0, 2) revenue_per_user    5.24      6.25             19% 0.00218    0.00872\n</code></pre> <p>The method adjusts p-values and saves them as <code>pvalue_adj</code>. Compare these values to the desired significance level alpha to determine if the null hypotheses can be rejected.</p> <p>The method also adjusts the significance level alpha and saves it as <code>alpha_adj</code>. Compare non-adjusted p-values (<code>pvalue</code>) to the <code>alpha_adj</code> to determine if the null hypotheses can be rejected:</p> <pre><code>&gt;&gt;&gt; adjusted_results_fdr.with_keys((\n...     \"comparison\",\n...     \"metric\",\n...     \"control\",\n...     \"treatment\",\n...     \"rel_effect_size\",\n...     \"pvalue\",\n...     \"alpha_adj\",\n... ))\ncomparison           metric control treatment rel_effect_size  pvalue alpha_adj\n    (0, 1)  orders_per_user   0.530     0.573            8.0%   0.118    0.0500\n    (0, 1) revenue_per_user    5.24      5.99             14%  0.0211    0.0375\n    (0, 2)  orders_per_user   0.530     0.594             12%  0.0213    0.0375\n    (0, 2) revenue_per_user    5.24      6.25             19% 0.00218    0.0375\n</code></pre> <p>By default, tea-tasting assumes non-negative correlation between hypotheses and performs the Benjamini-Hochberg procedure. To perform the Benjamini-Yekutieli procedure, assuming arbitrary dependence between hypotheses, set the <code>arbitrary_dependence</code> parameter to <code>True</code>:</p> <pre><code>&gt;&gt;&gt; tt.adjust_fdr(results, metrics, arbitrary_dependence=True)\ncomparison           metric control treatment rel_effect_size  pvalue pvalue_adj\n    (0, 1)  orders_per_user   0.530     0.573            8.0%   0.118      0.245\n    (0, 1) revenue_per_user    5.24      5.99             14%  0.0211     0.0592\n    (0, 2)  orders_per_user   0.530     0.594             12%  0.0213     0.0592\n    (0, 2) revenue_per_user    5.24      6.25             19% 0.00218     0.0182\n</code></pre>"},{"location":"multiple-testing/#family-wise-error-rate","title":"Family-wise error rate","text":"<p>Family-wise error rate (FWER) is the probability of making at least one type I error. To control for FWER, use the <code>adjust_fwer</code> method:</p> <pre><code>&gt;&gt;&gt; tt.adjust_fwer(results, metrics)\ncomparison           metric control treatment rel_effect_size  pvalue pvalue_adj\n    (0, 1)  orders_per_user   0.530     0.573            8.0%   0.118      0.118\n    (0, 1) revenue_per_user    5.24      5.99             14%  0.0211     0.0422\n    (0, 2)  orders_per_user   0.530     0.594             12%  0.0213     0.0422\n    (0, 2) revenue_per_user    5.24      6.25             19% 0.00218    0.00869\n</code></pre> <p>By default, tea-tasting assumes non-negative correlation between hypotheses and performs the Hochberg's step-up procedure with the \u0160id\u00e1k correction, which is slightly more powerful than the Bonferroni correction.</p> <p>To perform the Holm's step-down procedure, assuming arbitrary dependence between hypotheses, set the <code>arbitrary_dependence</code> parameter to <code>True</code>. In this case, it's recommended to use the Bonferroni correction, since the \u0160id\u00e1k correction assumes non-negative correlation between hypotheses:</p> <pre><code>&gt;&gt;&gt; tt.adjust_fwer(\n...     results,\n...     metrics,\n...     arbitrary_dependence=True,\n...     method=\"bonferroni\",\n... )\ncomparison           metric control treatment rel_effect_size  pvalue pvalue_adj\n    (0, 1)  orders_per_user   0.530     0.573            8.0%   0.118      0.118\n    (0, 1) revenue_per_user    5.24      5.99             14%  0.0211     0.0634\n    (0, 2)  orders_per_user   0.530     0.594             12%  0.0213     0.0634\n    (0, 2) revenue_per_user    5.24      6.25             19% 0.00218    0.00872\n</code></pre>"},{"location":"multiple-testing/#other-inputs","title":"Other inputs","text":"<p>In the examples above, the methods <code>adjust_fdr</code> and <code>adjust_fwer</code> received results from a single experiment with more than two variants. They can also accept the results from multiple experiments with two variants in each:</p> <pre><code>&gt;&gt;&gt; data1 = tt.make_users_data(seed=42, orders_uplift=0.10, revenue_uplift=0.15)\n&gt;&gt;&gt; data2 = tt.make_users_data(seed=21, orders_uplift=0.15, revenue_uplift=0.20)\n&gt;&gt;&gt; result1 = experiment.analyze(data1)\n&gt;&gt;&gt; result2 = experiment.analyze(data2)\n&gt;&gt;&gt; tt.adjust_fdr(\n...     {\"Experiment 1\": result1, \"Experiment 2\": result2},\n...     metrics,\n... )\n  comparison           metric control treatment rel_effect_size   pvalue pvalue_adj\nExperiment 1  orders_per_user   0.530     0.573            8.0%    0.118      0.118\nExperiment 1 revenue_per_user    5.24      5.99             14%   0.0211     0.0282\nExperiment 2  orders_per_user   0.514     0.594             16%  0.00427    0.00853\nExperiment 2 revenue_per_user    5.10      6.25             22% 6.27e-04    0.00251\n</code></pre> <p>The methods <code>adjust_fdr</code> and <code>adjust_fwer</code> can also accept the result of a single experiment with two variants:</p> <pre><code>&gt;&gt;&gt; tt.adjust_fwer(result2, metrics)\ncomparison           metric control treatment rel_effect_size   pvalue pvalue_adj\n         -  orders_per_user   0.514     0.594             16%  0.00427    0.00427\n         - revenue_per_user    5.10      6.25             22% 6.27e-04    0.00125\n</code></pre>"},{"location":"power-analysis/","title":"Power analysis","text":"<p>In tea-tasting, you can analyze the statistical power for <code>Mean</code> and <code>RatioOfMeans</code> metrics. There are three possible options:</p> <ul> <li>Calculate the effect size, given statistical power and the total number of observations.</li> <li>Calculate the total number of observations, given statistical power and the effect size.</li> <li>Calculate statistical power, given the effect size and the total number of observations.</li> </ul> <p>In this example, tea-tasting calculates statistical power given the relative effect size and the number of observations:</p> <pre><code>&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; data = tt.make_users_data(\n...     seed=42,\n...     sessions_uplift=0,\n...     orders_uplift=0,\n...     revenue_uplift=0,\n...     covariates=True,\n... )\n&gt;&gt;&gt; orders_per_session = tt.RatioOfMeans(\"orders\", \"sessions\", rel_effect_size=0.1)\n&gt;&gt;&gt; orders_per_session.solve_power(data, \"power\")\npower effect_size rel_effect_size n_obs\n  52%      0.0261             10%  4000\n</code></pre> <p>Besides <code>alternative</code>, <code>equal_var</code>, <code>use_t</code>, and covariates (CUPED), the following metric parameters affect the result:</p> <ul> <li><code>alpha</code>: Significance level.</li> <li><code>ratio</code>: Ratio of the number of observations in the treatment relative to the control.</li> <li><code>power</code>: Statistical power.</li> <li><code>effect_size</code> and <code>rel_effect_size</code>: Absolute and relative effect size. Only one of them can be defined.</li> <li><code>n_obs</code>: Number of observations in the control and in the treatment together. If the number of observations is not set explicitly, it's inferred from the dataset.</li> </ul> <p>You can change the default values of <code>alpha</code>, <code>ratio</code>, <code>power</code>, and <code>n_obs</code> using the global settings.</p> <p>tea-tasting can analyze power for several values of parameters <code>effect_size</code>, <code>rel_effect_size</code>, or <code>n_obs</code>. Example:</p> <pre><code>&gt;&gt;&gt; orders_per_user = tt.Mean(\"orders\", alpha=0.1, power=0.7, n_obs=(10_000, 20_000))\n&gt;&gt;&gt; orders_per_user.solve_power(data, \"rel_effect_size\")\npower effect_size rel_effect_size n_obs\n  70%      0.0367            7.1% 10000\n  70%      0.0260            5.0% 20000\n</code></pre> <p>You can analyze power for all metrics in the experiment. Example:</p> <pre><code>&gt;&gt;&gt; with tt.config_context(n_obs=(10_000, 20_000)):\n...     experiment = tt.Experiment(\n...         sessions_per_user=tt.Mean(\"sessions\", \"sessions_covariate\"),\n...         orders_per_session=tt.RatioOfMeans(\n...             numer=\"orders\",\n...             denom=\"sessions\",\n...             numer_covariate=\"orders_covariate\",\n...             denom_covariate=\"sessions_covariate\",\n...         ),\n...         orders_per_user=tt.Mean(\"orders\", \"orders_covariate\"),\n...         revenue_per_user=tt.Mean(\"revenue\", \"revenue_covariate\"),\n...     )\n... \n&gt;&gt;&gt; power_result = experiment.solve_power(data)\n&gt;&gt;&gt; power_result\n            metric power effect_size rel_effect_size n_obs\n sessions_per_user   80%      0.0458            2.3% 10000\n sessions_per_user   80%      0.0324            1.6% 20000\norders_per_session   80%      0.0177            6.8% 10000\norders_per_session   80%      0.0125            4.8% 20000\n   orders_per_user   80%      0.0374            7.2% 10000\n   orders_per_user   80%      0.0264            5.1% 20000\n  revenue_per_user   80%       0.488            9.2% 10000\n  revenue_per_user   80%       0.345            6.5% 20000\n</code></pre> <p>In the example above, tea-tasting calculates both the relative and absolute effect size for all metrics for two possible sample size values, <code>10_000</code> and <code>20_000</code>.</p> <p>The <code>solve_power</code> methods of a metric and of an experiment return the instances of <code>MetricPowerResults</code> and <code>ExperimentPowerResult</code> respectively. These result classes provide the serialization methods similar to the experiment result: <code>to_dicts</code>, <code>to_arrow</code>, <code>to_pandas</code>, <code>to_polars</code>, <code>to_pretty_dicts</code>, <code>to_string</code>, <code>to_html</code>. They are also rendered as an HTML tables in IPython and Jupyter, and as a table in marimo notebooks.</p>"},{"location":"simulated-experiments/","title":"Simulated experiments","text":""},{"location":"simulated-experiments/#intro","title":"Intro","text":"<p>In tea-tasting, you can run multiple simulated A/A or A/B tests. In each simulation, tea-tasting splits the data into control and treatment groups and can optionally modify the treatment data. A simulation without changing the treatment data is called an A/A test.</p> <p>A/A tests are useful for identifying potential issues before conducting the actual A/B test. Treatment simulations are great for power analysis\u2014especially when you need a specific uplift distribution or when an analytical formula doesn\u2019t exist.</p> <p>Note</p> <p>This guide uses Polars and tqdm. Install these packages in addition to tea-tasting to reproduce the examples:</p> <pre><code>uv pip install polars tqdm\n</code></pre>"},{"location":"simulated-experiments/#running-aa-tests","title":"Running A/A tests","text":"<p>First, let's prepare the data without any uplift and drop the <code>\"variant\"</code> column.</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; data = (\n...     tt.make_users_data(seed=42, orders_uplift=0, revenue_uplift=0)\n...     .drop_columns(\"variant\")\n... )\n&gt;&gt;&gt; data\npyarrow.Table\nuser: int64\nsessions: int64\norders: int64\nrevenue: double\n----\nuser: [[0,1,2,3,4,...,3995,3996,3997,3998,3999]]\nsessions: [[2,2,2,2,1,...,2,2,3,1,5]]\norders: [[1,1,1,0,1,...,0,1,1,0,4]]\nrevenue: [[19.06,12.09,8.84,0,9.9,...,0,4.8,9.63,0,12.7]]\n</code></pre> <p>To run A/A tests, first define the metrics for the experiment, then call the <code>simulate</code> method, providing the data and the number of simulations as arguments.</p> <pre><code>&gt;&gt;&gt; experiment = tt.Experiment(\n...     sessions_per_user=tt.Mean(\"sessions\"),\n...     orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\"),\n...     orders_per_user=tt.Mean(\"orders\"),\n...     revenue_per_user=tt.Mean(\"revenue\"),\n...     n_users=tt.SampleRatio(),\n... )\n&gt;&gt;&gt; results = experiment.simulate(data, 100, seed=42)\n&gt;&gt;&gt; results_data = results.to_polars()\n&gt;&gt;&gt; results_data.select(\n...     \"metric\",\n...     \"control\",\n...     \"treatment\",\n...     \"rel_effect_size\",\n...     \"rel_effect_size_ci_lower\",\n...     \"rel_effect_size_ci_upper\",\n...     \"pvalue\",\n... )\nshape: (500, 7)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 metric             \u2506 control  \u2506 treatment \u2506 rel_effect_size \u2506 rel_effect_size_ci \u2506 rel_effect_size_ci \u2506 pvalue   \u2502\n\u2502 ---                \u2506 ---      \u2506 ---       \u2506 ---             \u2506 _lower             \u2506 _upper             \u2506 ---      \u2502\n\u2502 str                \u2506 f64      \u2506 f64       \u2506 f64             \u2506 ---                \u2506 ---                \u2506 f64      \u2502\n\u2502                    \u2506          \u2506           \u2506                 \u2506 f64                \u2506 f64                \u2506          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 sessions_per_user  \u2506 1.98004  \u2506 1.998998  \u2506 0.009575        \u2506 -0.021272          \u2506 0.041393           \u2506 0.547091 \u2502\n\u2502 orders_per_session \u2506 0.263105 \u2506 0.258647  \u2506 -0.016945       \u2506 -0.108177          \u2506 0.083621           \u2506 0.730827 \u2502\n\u2502 orders_per_user    \u2506 0.520958 \u2506 0.517034  \u2506 -0.007532       \u2506 -0.102993          \u2506 0.098087           \u2506 0.883462 \u2502\n\u2502 revenue_per_user   \u2506 5.446662 \u2506 5.14521   \u2506 -0.055346       \u2506 -0.162811          \u2506 0.065914           \u2506 0.356327 \u2502\n\u2502 n_users            \u2506 2004.0   \u2506 1996.0    \u2506 null            \u2506 null               \u2506 null               \u2506 0.91187  \u2502\n\u2502 \u2026                  \u2506 \u2026        \u2506 \u2026         \u2506 \u2026               \u2506 \u2026                  \u2506 \u2026                  \u2506 \u2026        \u2502\n\u2502 sessions_per_user  \u2506 1.993624 \u2506 1.985212  \u2506 -0.00422        \u2506 -0.034685          \u2506 0.027207           \u2506 0.78959  \u2502\n\u2502 orders_per_session \u2506 0.269373 \u2506 0.251991  \u2506 -0.064527       \u2506 -0.151401          \u2506 0.03124            \u2506 0.179445 \u2502\n\u2502 orders_per_user    \u2506 0.537028 \u2506 0.500255  \u2506 -0.068475       \u2506 -0.158141          \u2506 0.030742           \u2506 0.169217 \u2502\n\u2502 revenue_per_user   \u2506 5.511967 \u2506 5.071928  \u2506 -0.079833       \u2506 -0.184806          \u2506 0.038656           \u2506 0.177868 \u2502\n\u2502 n_users            \u2506 2039.0   \u2506 1961.0    \u2506 null            \u2506 null               \u2506 null               \u2506 0.223423 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>The <code>simulate</code> method accepts data in the same formats as the <code>analyze</code> method. Internally, however, it converts the data to a PyArrow Table before running the simulations.</p> <p>The method returns an instance of the <code>SimulationResults</code> class, which contains the results of all simulations for all metrics. The resulting object provides serialization methods to those of the experiment result, including <code>to_dicts</code>, <code>to_arrow</code>, <code>to_pandas</code>, <code>to_polars</code>, <code>to_pretty_dicts</code>, <code>to_string</code>, <code>to_html</code>.</p> <p>For instance, we can now calculate the proportion of rejected null hypotheses, using various significance levels (<code>alpha</code>). In A/A tests, it estimates the type I error rate.</p> <pre><code>&gt;&gt;&gt; def null_rejected(\n...     results_data: pl.DataFrame,\n...     alphas: tuple[float, ...] = (0.01, 0.02, 0.05),\n... ) -&gt; pl.DataFrame:\n...     return results_data.group_by(\"metric\", maintain_order=True).agg(\n...         pl.col(\"pvalue\").le(alpha).mean().alias(f\"null_rejected_{alpha}\")\n...         for alpha in alphas\n...     )\n... \n&gt;&gt;&gt; null_rejected(results_data)\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 metric             \u2506 null_rejected_0.01 \u2506 null_rejected_0.02 \u2506 null_rejected_0.05 \u2502\n\u2502 ---                \u2506 ---                \u2506 ---                \u2506 ---                \u2502\n\u2502 str                \u2506 f64                \u2506 f64                \u2506 f64                \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 sessions_per_user  \u2506 0.01               \u2506 0.02               \u2506 0.05               \u2502\n\u2502 orders_per_session \u2506 0.02               \u2506 0.02               \u2506 0.06               \u2502\n\u2502 orders_per_user    \u2506 0.01               \u2506 0.02               \u2506 0.05               \u2502\n\u2502 revenue_per_user   \u2506 0.02               \u2506 0.03               \u2506 0.06               \u2502\n\u2502 n_users            \u2506 0.01               \u2506 0.01               \u2506 0.04               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>100 simulations, as in the example above, produce a very rough estimate. In practice, a larger number of simulations, such as the default <code>10_000</code>, is recommended.</p>"},{"location":"simulated-experiments/#simulating-experiments-with-treatment","title":"Simulating experiments with treatment","text":"<p>To simulate experiments with treatment, define a treatment function that takes data in the form of a PyArrow Table and returns a PyArrow Table with the modified data:</p> <pre><code>&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import pyarrow.compute as pc\n\n&gt;&gt;&gt; def treat(data: pa.Table) -&gt; pa.Table:\n...     return (\n...         data.drop_columns([\"orders\", \"revenue\"])\n...         .append_column(\"orders\", pc.multiply(data[\"orders\"], pa.scalar(1.1)))\n...         .append_column(\"revenue\", pc.multiply(data[\"revenue\"], pa.scalar(1.1)))\n...     )\n... \n&gt;&gt;&gt; results_treat = experiment.simulate(data, 100, seed=42, treat=treat)\n&gt;&gt;&gt; null_rejected(results_treat.to_polars())\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 metric             \u2506 null_rejected_0.01 \u2506 null_rejected_0.02 \u2506 null_rejected_0.05 \u2502\n\u2502 ---                \u2506 ---                \u2506 ---                \u2506 ---                \u2502\n\u2502 str                \u2506 f64                \u2506 f64                \u2506 f64                \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 sessions_per_user  \u2506 0.01               \u2506 0.02               \u2506 0.05               \u2502\n\u2502 orders_per_session \u2506 0.23               \u2506 0.31               \u2506 0.42               \u2502\n\u2502 orders_per_user    \u2506 0.21               \u2506 0.29               \u2506 0.4                \u2502\n\u2502 revenue_per_user   \u2506 0.11               \u2506 0.16               \u2506 0.31               \u2502\n\u2502 n_users            \u2506 0.01               \u2506 0.01               \u2506 0.04               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>In the example above, we've defined a function that increases the number of orders and the revenue by 10%. For these metrics, the proportion of rejected null hypotheses is an estimate of statistical power.</p>"},{"location":"simulated-experiments/#using-a-function-instead-of-static-data","title":"Using a function instead of static data","text":"<p>You can use a function instead of static data to generate input dynamically. The function should take an instance of <code>numpy.random.Generator</code> as a parameter named <code>seed</code> and return experimental data in any format supported by tea-tasting.</p> <p>As an example, let's use the <code>make_users_data</code> function.</p> <pre><code>&gt;&gt;&gt; results_data_gen = experiment.simulate(tt.make_users_data, 100, seed=42)\n&gt;&gt;&gt; null_rejected(results_data_gen.to_polars())\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 metric             \u2506 null_rejected_0.01 \u2506 null_rejected_0.02 \u2506 null_rejected_0.05 \u2502\n\u2502 ---                \u2506 ---                \u2506 ---                \u2506 ---                \u2502\n\u2502 str                \u2506 f64                \u2506 f64                \u2506 f64                \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 sessions_per_user  \u2506 0.01               \u2506 0.01               \u2506 0.06               \u2502\n\u2502 orders_per_session \u2506 0.27               \u2506 0.36               \u2506 0.54               \u2502\n\u2502 orders_per_user    \u2506 0.24               \u2506 0.32               \u2506 0.49               \u2502\n\u2502 revenue_per_user   \u2506 0.17               \u2506 0.26               \u2506 0.39               \u2502\n\u2502 n_users            \u2506 0.01               \u2506 0.01               \u2506 0.04               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>On each iteration, tea-tasting calls <code>make_users_data</code> with a new <code>seed</code> and uses the returned data for the analysis of the experiment. The data returned by <code>make_users_data</code> already contains the <code>\"variant\"</code> column, so tea-tasting reuses that split. By default, <code>make_users_data</code> also adds the treatment uplift, and you can see it in the proportion of rejected null hypotheses.</p>"},{"location":"simulated-experiments/#tracking-progress","title":"Tracking progress","text":"<p>To track the progress of simulations with <code>tqdm</code> or <code>marimo.status.progress_bar</code>, use the <code>progress</code> parameter.</p> <pre><code>&gt;&gt;&gt; import tqdm\n\n&gt;&gt;&gt; results_progress = experiment.simulate(\n...     data,\n...     100,\n...     seed=42,\n...     progress=tqdm.tqdm,\n... )\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:01&lt;00:00, 64.47it/s]\n</code></pre>"},{"location":"simulated-experiments/#parallel-execution","title":"Parallel execution","text":"<p>Note</p> <p>The code below won't work in the marimo online playground as it relies on the <code>multiprocessing</code> module which is currently not supported by WASM notebooks. WASM notebooks are the marimo notebooks that run entirely in the browser.</p> <p>To speed up simulations and run them in parallel, use the <code>map_</code> parameter with an alternative mapping function.</p> <pre><code>&gt;&gt;&gt; import concurrent.futures\n\n&gt;&gt;&gt; with concurrent.futures.ProcessPoolExecutor() as executor:\n...     results_parallel = experiment.simulate(\n...         data,\n...         100,\n...         seed=42,\n...         treat=treat,\n...         map_=executor.map,\n...         progress=tqdm.tqdm,\n...     )\n... \n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100/100 [00:00&lt;00:00, 251.60it/s]\n</code></pre> <p>As an alternative to <code>concurrent.futures.ProcessPoolExecutor</code>, you can use the <code>map</code>, <code>imap</code>, or <code>imap_unordered</code> methods of <code>multiprocessing.pool.Pool</code>.</p> <p>It's also possible to run simulations on a distributed Dask or Ray cluster.</p>"},{"location":"user-guide/","title":"User guide","text":""},{"location":"user-guide/#installation","title":"Installation","text":"<pre><code>uv pip install tea-tasting\n</code></pre> <p>Install Pandas or Polars to serialize analysis results as a Pandas DataFrame or a Polars DataFrame, respectively. These packages are not installed with tea-tasting by default.</p>"},{"location":"user-guide/#basic-usage","title":"Basic usage","text":"<p>Begin with this simple example to understand the basic functionality:</p> <pre><code>&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; data = tt.make_users_data(seed=42)\n&gt;&gt;&gt; experiment = tt.Experiment(\n...     sessions_per_user=tt.Mean(\"sessions\"),\n...     orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\"),\n...     orders_per_user=tt.Mean(\"orders\"),\n...     revenue_per_user=tt.Mean(\"revenue\"),\n... )\n&gt;&gt;&gt; result = experiment.analyze(data)\n&gt;&gt;&gt; result\n            metric control treatment rel_effect_size rel_effect_size_ci pvalue\n sessions_per_user    2.00      1.98          -0.66%      [-3.7%, 2.5%]  0.674\norders_per_session   0.266     0.289            8.8%      [-0.89%, 19%] 0.0762\n   orders_per_user   0.530     0.573            8.0%       [-2.0%, 19%]  0.118\n  revenue_per_user    5.24      5.73            9.3%       [-2.4%, 22%]  0.123\n</code></pre> <p>In the following sections, each step of this process is explained in detail.</p>"},{"location":"user-guide/#input-data","title":"Input data","text":"<p>The <code>make_users_data</code> function creates synthetic data for demonstration purposes. This data mimics what you might encounter in an A/B test for an online store. Each row represents an individual user, with the following columns:</p> <ul> <li><code>user</code>: The unique identifier for each user.</li> <li><code>variant</code>: The specific variant (e.g., 0 or 1) assigned to each user in the A/B test.</li> <li><code>sessions</code>: The total number of user's sessions.</li> <li><code>orders</code>: The total number of user's orders.</li> <li><code>revenue</code>: The total revenue generated by the user.</li> </ul> <p>By default, <code>make_users_data</code> returns a PyArrow Table:</p> <pre><code>&gt;&gt;&gt; data\npyarrow.Table\nuser: int64\nvariant: int64\nsessions: int64\norders: int64\nrevenue: double\n----\nuser: [[0,1,2,3,4,...,3995,3996,3997,3998,3999]]\nvariant: [[1,0,1,1,0,...,0,0,0,0,0]]\nsessions: [[2,2,2,2,1,...,2,2,3,1,5]]\norders: [[1,1,1,1,1,...,0,0,0,0,2]]\nrevenue: [[9.17,6.43,7.94,15.93,7.14,...,0,0,0,0,17.16]]\n</code></pre> <p>You can control return type using the <code>return_type</code> parameter. The other possible output types are Pandas DataFrame and Polars DataFrame. They require Pandas or Polars packages respectively.</p> <p>tea-tasting can process data in the form of an Ibis Table or a DataFrame supported by Narwhals:</p> <ul> <li>Ibis is a DataFrame API to various data backends. It supports many backends including BigQuery, ClickHouse, DuckDB, PostgreSQL, Snowflake, Spark etc. You can write an SQL query, wrap it as an Ibis Table and pass it to tea-tasting.</li> <li>Narwhals is a compatibility layer between dataframe libraries. It supports cuDF, Dask, Modin, pandas, Polars, PyArrow dataframes. You can use any of these dataframes as an input to tea-tasting.</li> </ul> <p>Many statistical tests, such as the Student's t-test or the Z-test, require only aggregated data for analysis. For these tests, tea-tasting retrieves only aggregated statistics like mean and variance instead of downloading all detailed data. See more details in the guide on data backends.</p> <p>tea-tasting assumes that:</p> <ul> <li>Data is grouped by randomization units, such as individual users.</li> <li>There is a column indicating the variant of the A/B test (typically labeled as A, B, etc.).</li> <li>All necessary columns for metric calculations (like the number of orders, revenue, etc.) are included in the table.</li> </ul>"},{"location":"user-guide/#ab-test-definition","title":"A/B test definition","text":"<p>The <code>Experiment</code> class defines parameters of an A/B test: metrics and a variant column name. There are two ways to define metrics:</p> <ul> <li>Using keyword parameters, with metric names as parameter names, and metric definitions as parameter values, as in example above.</li> <li>Using the first argument <code>metrics</code> which accepts metrics in a form of dictionary with metric names as keys and metric definitions as values.</li> </ul> <p>By default, tea-tasting assumes that the A/B test variant is stored in a column named <code>\"variant\"</code>. You can change it using the <code>variant</code> parameter of the <code>Experiment</code> class.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; new_experiment = tt.Experiment(\n...     {\n...         \"sessions per user\": tt.Mean(\"sessions\"),\n...         \"orders per session\": tt.RatioOfMeans(\"orders\", \"sessions\"),\n...         \"orders per user\": tt.Mean(\"orders\"),\n...         \"revenue per user\": tt.Mean(\"revenue\"),\n...     },\n...     variant=\"variant\",\n... )\n</code></pre>"},{"location":"user-guide/#metrics","title":"Metrics","text":"<p>Metrics are instances of metric classes which define how metrics are calculated. Those calculations include calculation of effect size, confidence interval, p-value and other statistics.</p> <p>Use the <code>Mean</code> class to compare averages between variants of an A/B test. For example, average number of orders per user, where user is a randomization unit of an experiment. Specify the column containing the metric values using the first parameter <code>value</code>.</p> <p>Use the <code>RatioOfMeans</code> class to compare ratios of averages between variants of an A/B test. For example, average number of orders per average number of sessions. Specify the columns containing the numerator and denominator values using parameters <code>numer</code> and <code>denom</code>.</p> <p>Use the following parameters of <code>Mean</code> and <code>RatioOfMeans</code> to customize the analysis:</p> <ul> <li><code>alternative</code>: Alternative hypothesis. The following options are available:<ul> <li><code>\"two-sided\"</code> (default): the means are unequal.</li> <li><code>\"greater\"</code>: the mean in the treatment variant is greater than the mean in the control variant.</li> <li><code>\"less\"</code>: the mean in the treatment variant is less than the mean in the control variant.</li> </ul> </li> <li><code>confidence_level</code>: Confidence level of the confidence interval. Default is <code>0.95</code>.</li> <li><code>equal_var</code>: Defines whether equal variance is assumed. If <code>True</code>, pooled variance is used for the calculation of the standard error of the difference between two means. Default is <code>False</code>.</li> <li><code>use_t</code>: Defines whether to use the Student's t-distribution (<code>True</code>) or the Normal distribution (<code>False</code>). Default is <code>True</code>.</li> </ul> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; another_experiment = tt.Experiment(\n...     sessions_per_user=tt.Mean(\"sessions\", alternative=\"greater\"),\n...     orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\", confidence_level=0.9),\n...     orders_per_user=tt.Mean(\"orders\", equal_var=True),\n...     revenue_per_user=tt.Mean(\"revenue\", use_t=False),\n... )\n</code></pre> <p>Look for other supported metrics in the Metrics reference.</p> <p>You can change default values of these four parameters using the global settings.</p>"},{"location":"user-guide/#analyzing-and-retrieving-experiment-results","title":"Analyzing and retrieving experiment results","text":"<p>After defining an experiment and metrics, you can analyze the experiment data using the <code>analyze</code> method of the <code>Experiment</code> class. This method takes data as an input and returns an <code>ExperimentResult</code> object with experiment result.</p> <pre><code>&gt;&gt;&gt; new_result = experiment.analyze(data)\n</code></pre> <p>By default, tea-tasting assumes that the variant with the lowest ID is a control. Change default behavior using the <code>control</code> parameter:</p> <pre><code>&gt;&gt;&gt; result_with_non_default_control = experiment.analyze(data, control=1)\n</code></pre> <p><code>ExperimentResult</code> is a mapping. Get a metric's analysis result using metric name as a key.</p> <pre><code>&gt;&gt;&gt; import pprint\n\n&gt;&gt;&gt; pprint.pprint(result[\"orders_per_user\"]._asdict())\n{'control': 0.5304003954522986,\n 'effect_size': 0.04269014577177832,\n 'effect_size_ci_lower': -0.010800201598205515,\n 'effect_size_ci_upper': 0.09618049314176216,\n 'pvalue': np.float64(0.11773177998716214),\n 'rel_effect_size': 0.08048664016431273,\n 'rel_effect_size_ci_lower': -0.019515294044061937,\n 'rel_effect_size_ci_upper': 0.1906880061278886,\n 'statistic': 1.5647028839586707,\n 'treatment': 0.5730905412240769}\n</code></pre> <p>Fields in result depend on metrics. For <code>Mean</code> and <code>RatioOfMeans</code>, the fields include:</p> <ul> <li><code>metric</code>: Metric name.</li> <li><code>control</code>: Mean or ratio of means in the control variant.</li> <li><code>treatment</code>: Mean or ratio of means in the treatment variant.</li> <li><code>effect_size</code>: Absolute effect size. Difference between two means.</li> <li><code>effect_size_ci_lower</code>: Lower bound of the absolute effect size confidence interval.</li> <li><code>effect_size_ci_upper</code>: Upper bound of the absolute effect size confidence interval.</li> <li><code>rel_effect_size</code>: Relative effect size. Difference between two means, divided by the control mean.</li> <li><code>rel_effect_size_ci_lower</code>: Lower bound of the relative effect size confidence interval.</li> <li><code>rel_effect_size_ci_upper</code>: Upper bound of the relative effect size confidence interval.</li> <li><code>pvalue</code>: P-value</li> <li><code>statistic</code>: Statistic (standardized effect size).</li> </ul> <p><code>ExperimentResult</code> provides the following methods to serialize and view the experiment result:</p> <ul> <li><code>to_dicts</code>: Convert the result to a sequence of dictionaries.</li> <li><code>to_arrow</code>: Convert the result to a PyArrow Table.</li> <li><code>to_pandas</code>: Convert the result to a Pandas DataFrame. Requires Pandas to be installed.</li> <li><code>to_polars</code>: Convert the result to a Polars DataFrame. Requires Polars to be installed.</li> <li><code>to_pretty_dicts</code>: Convert the result to a sequence of dictionaries with formatted values (as strings).</li> <li><code>to_string</code>: Convert the result to a string.</li> <li><code>to_html</code>: Convert the result to HTML.</li> </ul> <p><code>result</code> is the same as <code>print(result.to_string())</code>. <code>ExperimentResult</code> provides also the <code>_repr_html_</code> method that renders it as an HTML table in IPython and Jupyter, and the <code>_mime_</code> method that renders it as a table in marimo notebooks.</p> <pre><code>&gt;&gt;&gt; result\n            metric control treatment rel_effect_size rel_effect_size_ci pvalue\n sessions_per_user    2.00      1.98          -0.66%      [-3.7%, 2.5%]  0.674\norders_per_session   0.266     0.289            8.8%      [-0.89%, 19%] 0.0762\n   orders_per_user   0.530     0.573            8.0%       [-2.0%, 19%]  0.118\n  revenue_per_user    5.24      5.73            9.3%       [-2.4%, 22%]  0.123\n</code></pre> <p>By default, methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code> return a predefined list of attributes. This list can be customized:</p> <pre><code>&gt;&gt;&gt; result.with_keys((\n...     \"metric\",\n...     \"control\",\n...     \"treatment\",\n...     \"effect_size\",\n...     \"effect_size_ci\",\n... ))\n            metric control treatment effect_size     effect_size_ci\n sessions_per_user    2.00      1.98     -0.0132  [-0.0750, 0.0485]\norders_per_session   0.266     0.289      0.0233 [-0.00246, 0.0491]\n   orders_per_user   0.530     0.573      0.0427  [-0.0108, 0.0962]\n  revenue_per_user    5.24      5.73       0.489     [-0.133, 1.11]\n</code></pre> <p>Or:</p> <pre><code>&gt;&gt;&gt; print(result.to_string(keys=(\n...     \"metric\",\n...     \"control\",\n...     \"treatment\",\n...     \"effect_size\",\n...     \"effect_size_ci\",\n... )))\n            metric control treatment effect_size     effect_size_ci\n sessions_per_user    2.00      1.98     -0.0132  [-0.0750, 0.0485]\norders_per_session   0.266     0.289      0.0233 [-0.00246, 0.0491]\n   orders_per_user   0.530     0.573      0.0427  [-0.0108, 0.0962]\n  revenue_per_user    5.24      5.73       0.489     [-0.133, 1.11]\n</code></pre>"},{"location":"user-guide/#more-features","title":"More features","text":""},{"location":"user-guide/#variance-reduction-with-cupedcupac","title":"Variance reduction with CUPED/CUPAC","text":"<p>tea-tasting supports variance reduction with CUPED/CUPAC, within both <code>Mean</code> and <code>RatioOfMeans</code> classes.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; data_cuped = tt.make_users_data(seed=42, covariates=True)\n&gt;&gt;&gt; experiment_cuped = tt.Experiment(\n...     sessions_per_user=tt.Mean(\"sessions\", \"sessions_covariate\"),\n...     orders_per_session=tt.RatioOfMeans(\n...         numer=\"orders\",\n...         denom=\"sessions\",\n...         numer_covariate=\"orders_covariate\",\n...         denom_covariate=\"sessions_covariate\",\n...     ),\n...     orders_per_user=tt.Mean(\"orders\", \"orders_covariate\"),\n...     revenue_per_user=tt.Mean(\"revenue\", \"revenue_covariate\"),\n... )\n&gt;&gt;&gt; result_cuped = experiment_cuped.analyze(data_cuped)\n&gt;&gt;&gt; result_cuped\n            metric control treatment rel_effect_size rel_effect_size_ci  pvalue\n sessions_per_user    2.00      1.98          -0.68%      [-3.2%, 1.9%]   0.603\norders_per_session   0.262     0.293             12%        [4.2%, 21%] 0.00229\n   orders_per_user   0.523     0.581             11%        [2.9%, 20%] 0.00733\n  revenue_per_user    5.12      5.85             14%        [3.8%, 26%] 0.00674\n</code></pre> <p>Set the <code>covariates</code> parameter of the <code>make_users_data</code> functions to <code>True</code> to add the following columns with pre-experimental data:</p> <ul> <li><code>sessions_covariate</code>: Number of sessions before the experiment.</li> <li><code>orders_covariate</code>: Number of orders before the experiment.</li> <li><code>revenue_covariate</code>: Revenue before the experiment.</li> </ul> <p>Define the metrics' covariates:</p> <ul> <li>In <code>Mean</code>, specify the covariate using the <code>covariate</code> parameter.</li> <li>In <code>RatioOfMeans</code>, specify the covariates for the numerator and denominator using the <code>numer_covariate</code> and <code>denom_covariate</code> parameters, respectively.</li> </ul>"},{"location":"user-guide/#sample-ratio-mismatch-check","title":"Sample ratio mismatch check","text":"<p>The <code>SampleRatio</code> class in tea-tasting detects mismatches in the sample ratios of different variants of an A/B test.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; experiment_sample_ratio = tt.Experiment(\n...     orders_per_user=tt.Mean(\"orders\"),\n...     revenue_per_user=tt.Mean(\"revenue\"),\n...     sample_ratio=tt.SampleRatio(),\n... )\n&gt;&gt;&gt; result_sample_ratio = experiment_sample_ratio.analyze(data)\n&gt;&gt;&gt; result_sample_ratio\n          metric control treatment rel_effect_size rel_effect_size_ci pvalue\n orders_per_user   0.530     0.573            8.0%       [-2.0%, 19%]  0.118\nrevenue_per_user    5.24      5.73            9.3%       [-2.4%, 22%]  0.123\n    sample_ratio    2023      1977               -             [-, -]  0.477\n</code></pre> <p>By default, <code>SampleRatio</code> expects equal number of observations across all variants. To specify a different ratio, use the <code>ratio</code> parameter. It accepts two types of values:</p> <ul> <li>Ratio of the number of observation in treatment relative to control, as a positive number. Example: <code>SampleRatio(0.5)</code>.</li> <li>A dictionary with variants as keys and expected ratios as values. Example: <code>SampleRatio({\"A\": 2, \"B\": 1})</code>.</li> </ul> <p>The <code>method</code> parameter determines the statistical test to apply:</p> <ul> <li><code>\"auto\"</code>: Apply exact binomial test if the total number of observations is less than 1000, or normal approximation otherwise.</li> <li><code>\"binom\"</code>: Apply exact binomial test.</li> <li><code>\"norm\"</code>: Apply normal approximation of the binomial distribution.</li> </ul> <p>The result of the sample ratio mismatch includes the following attributes:</p> <ul> <li><code>metric</code>: Metric name.</li> <li><code>control</code>: Number of observations in control.</li> <li><code>treatment</code>: Number of observations in treatment.</li> <li><code>pvalue</code>: P-value</li> </ul>"},{"location":"user-guide/#global-settings","title":"Global settings","text":"<p>In tea-tasting, you can change defaults for the following parameters:</p> <ul> <li><code>alternative</code>: Alternative hypothesis.</li> <li><code>confidence_level</code>: Confidence level of the confidence interval.</li> <li><code>equal_var</code>: If <code>False</code>, assume unequal population variances in calculation of the standard deviation and the number of degrees of freedom. Otherwise, assume equal population variance and calculate pooled standard deviation.</li> <li><code>n_resamples</code>: The number of resamples performed to form the bootstrap distribution of a statistic.</li> <li><code>use_t</code>: If <code>True</code>, use Student's t-distribution in p-value and confidence interval calculations. Otherwise use Normal distribution.</li> <li>And more.</li> </ul> <p>Use <code>get_config</code> with the option name as a parameter to get a global option value:</p> <pre><code>&gt;&gt;&gt; tt.get_config(\"equal_var\")\nFalse\n</code></pre> <p>Use <code>get_config</code> without parameters to get a dictionary of global options:</p> <pre><code>&gt;&gt;&gt; global_config = tt.get_config()\n</code></pre> <p>Use <code>set_config</code> to set a global option value:</p> <pre><code>&gt;&gt;&gt; tt.set_config(equal_var=True, use_t=False)\n&gt;&gt;&gt; experiment_with_config = tt.Experiment(\n...     sessions_per_user=tt.Mean(\"sessions\"),\n...     orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\"),\n...     orders_per_user=tt.Mean(\"orders\"),\n...     revenue_per_user=tt.Mean(\"revenue\"),\n... )\n&gt;&gt;&gt; tt.set_config(equal_var=False, use_t=True)\n&gt;&gt;&gt; orders_per_user = experiment_with_config.metrics[\"orders_per_user\"]\n&gt;&gt;&gt; print(\n...     f\"orders_per_user.equal_var: {orders_per_user.equal_var}\\n\"\n...     f\"orders_per_user.use_t: {orders_per_user.use_t}\"\n... )\norders_per_user.equal_var: True\norders_per_user.use_t: False\n</code></pre> <p>Use <code>config_context</code> to temporarily set a global option value within a context:</p> <pre><code>&gt;&gt;&gt; with tt.config_context(equal_var=True, use_t=False):\n...     experiment_within_context = tt.Experiment(\n...         sessions_per_user=tt.Mean(\"sessions\"),\n...         orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\"),\n...         orders_per_user=tt.Mean(\"orders\"),\n...         revenue_per_user=tt.Mean(\"revenue\"),\n...     )\n... \n&gt;&gt;&gt; orders_per_user_context = experiment_with_config.metrics[\"orders_per_user\"]\n&gt;&gt;&gt; print(\n...     f\"global_config.equal_var: {tt.get_config('equal_var')}\\n\"\n...     f\"global_config.use_t: {tt.get_config('use_t')}\\n\\n\"\n...     f\"orders_per_user_context.equal_var: {orders_per_user_context.equal_var}\\n\"\n...     f\"orders_per_user_context.use_t: {orders_per_user_context.use_t}\"\n... )\nglobal_config.equal_var: False\nglobal_config.use_t: True\n\norders_per_user_context.equal_var: True\norders_per_user_context.use_t: False\n</code></pre>"},{"location":"user-guide/#more-than-two-variants","title":"More than two variants","text":"<p>Note</p> <p>This guide uses Polars as an example data backend. Install Polars in addition to tea-tasting to reproduce the examples:</p> <pre><code>uv pip install polars\n</code></pre> <p>In tea-tasting, it's possible to analyze experiments with more than two variants. However, the variants will be compared in pairs through two-sample statistical tests.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n\n&gt;&gt;&gt; data_three_variants = pl.concat((\n...     tt.make_users_data(seed=42, return_type=\"polars\"),\n...     tt.make_users_data(seed=21, return_type=\"polars\")\n...         .filter(pl.col(\"variant\").eq(1))\n...         .with_columns(variant=pl.lit(2, pl.Int64)),\n... ))\n&gt;&gt;&gt; results = experiment.analyze(data_three_variants, control=0, all_variants=True)\n&gt;&gt;&gt; results\nvariants             metric control treatment rel_effect_size rel_effect_size_ci pvalue\n  (0, 1)  sessions_per_user    2.00      1.98          -0.66%      [-3.7%, 2.5%]  0.674\n  (0, 1) orders_per_session   0.266     0.289            8.8%      [-0.89%, 19%] 0.0762\n  (0, 1)    orders_per_user   0.530     0.573            8.0%       [-2.0%, 19%]  0.118\n  (0, 1)   revenue_per_user    5.24      5.73            9.3%       [-2.4%, 22%]  0.123\n  (0, 2)  sessions_per_user    2.00      2.02           0.98%      [-2.1%, 4.1%]  0.532\n  (0, 2) orders_per_session   0.266     0.273            2.8%       [-6.6%, 13%]  0.575\n  (0, 2)    orders_per_user   0.530     0.550            3.8%       [-6.0%, 15%]  0.465\n  (0, 2)   revenue_per_user    5.24      5.41            3.1%       [-8.1%, 16%]  0.599\n</code></pre> <p>How variant pairs are determined:</p> <ul> <li>Specified control variant: If a specific variant is set as <code>control</code>, as in the example above, it is then compared against each of the other variants.</li> <li>Default control variant: When the <code>control</code> parameter of the <code>analyze</code> method is set to <code>None</code>, tea-tasting automatically compares each variant pair. The variant with the lowest ID in each pair is a control.</li> </ul> <p>Example usage without specifying a control variant:</p> <pre><code>&gt;&gt;&gt; results_all = experiment.analyze(data_three_variants, all_variants=True)\n&gt;&gt;&gt; results_all\nvariants             metric control treatment rel_effect_size rel_effect_size_ci pvalue\n  (0, 1)  sessions_per_user    2.00      1.98          -0.66%      [-3.7%, 2.5%]  0.674\n  (0, 1) orders_per_session   0.266     0.289            8.8%      [-0.89%, 19%] 0.0762\n  (0, 1)    orders_per_user   0.530     0.573            8.0%       [-2.0%, 19%]  0.118\n  (0, 1)   revenue_per_user    5.24      5.73            9.3%       [-2.4%, 22%]  0.123\n  (0, 2)  sessions_per_user    2.00      2.02           0.98%      [-2.1%, 4.1%]  0.532\n  (0, 2) orders_per_session   0.266     0.273            2.8%       [-6.6%, 13%]  0.575\n  (0, 2)    orders_per_user   0.530     0.550            3.8%       [-6.0%, 15%]  0.465\n  (0, 2)   revenue_per_user    5.24      5.41            3.1%       [-8.1%, 16%]  0.599\n  (1, 2)  sessions_per_user    1.98      2.02            1.7%      [-1.4%, 4.8%]  0.294\n  (1, 2) orders_per_session   0.289     0.273           -5.5%       [-14%, 3.6%]  0.225\n  (1, 2)    orders_per_user   0.573     0.550           -4.0%       [-13%, 5.7%]  0.407\n  (1, 2)   revenue_per_user    5.73      5.41           -5.7%       [-16%, 5.8%]  0.319\n</code></pre> <p>The result of the analysis is a mapping of <code>ExperimentResult</code> objects with tuples (control, treatment) as keys. You can view the result for a selected pair of variants:</p> <pre><code>&gt;&gt;&gt; results[0, 1]\n            metric control treatment rel_effect_size rel_effect_size_ci pvalue\n sessions_per_user    2.00      1.98          -0.66%      [-3.7%, 2.5%]  0.674\norders_per_session   0.266     0.289            8.8%      [-0.89%, 19%] 0.0762\n   orders_per_user   0.530     0.573            8.0%       [-2.0%, 19%]  0.118\n  revenue_per_user    5.24      5.73            9.3%       [-2.4%, 22%]  0.123\n</code></pre> <p>By default, tea-tasting does not adjust for multiple hypothesis testing. However, it provides several methods for multiple testing correction. For more details, see the guide on multiple hypothesis testing.</p>"},{"location":"api/","title":"API reference","text":""},{"location":"api/#tea_tasting","title":"<code>tea_tasting</code>","text":"<p>A Python package for the statistical analysis of A/B tests.</p> <p>All classes and functions for the analysis of the experiments can be imported from the root <code>tea_tasting</code> module.</p> <p>There are functions and classes for advanced use cases such as defining custom metrics. They can be imported from submodules of <code>tea_tasting</code>.</p> <p>For convenience, the API reference is provided by submodules:</p> <ul> <li><code>tea_tasting.metrics</code>: Built-in metrics.</li> <li><code>tea_tasting.experiment</code>: Experiment and experiment result.</li> <li><code>tea_tasting.multiplicity</code>: Multiple hypothesis testing.</li> <li><code>tea_tasting.datasets</code>: Example datasets.</li> <li><code>tea_tasting.config</code>: Global configuration.</li> <li><code>tea_tasting.aggr</code>: Module for working with aggregated statistics.</li> <li><code>tea_tasting.utils</code>: Useful functions and classes.</li> </ul>"},{"location":"api/aggr/","title":"Aggregates","text":""},{"location":"api/aggr/#tea_tasting.aggr","title":"<code>tea_tasting.aggr</code>","text":"<p>Module for working with aggregated statistics: count, mean, var, cov.</p>"},{"location":"api/aggr/#tea_tasting.aggr.Aggregates","title":"<code>Aggregates(count_=None, mean_={}, var_={}, cov_={})</code>","text":"<p>               Bases: <code>ReprMixin</code></p> <p>Aggregated statistics.</p> <p>Parameters:</p> Name Type Description Default <code>count_</code> <code>int | None</code> <p>Sample size (number of observations).</p> <code>None</code> <code>mean_</code> <code>dict[str, float | int]</code> <p>Dictionary of sample means with variable names as keys.</p> <code>{}</code> <code>var_</code> <code>dict[str, float | int]</code> <p>Dictionary of sample variances with variable names as keys.</p> <code>{}</code> <code>cov_</code> <code>dict[tuple[str, str], float | int]</code> <p>Dictionary of sample covariances with pairs of variable names as keys.</p> <code>{}</code> Source code in <code>src/tea_tasting/aggr.py</code> <pre><code>def __init__(\n    self,\n    count_: int | None = None,\n    mean_: dict[str, float | int] = {},  # noqa: B006\n    var_: dict[str, float | int] = {},  # noqa: B006\n    cov_: dict[tuple[str, str], float | int] = {},  # noqa: B006\n) -&gt; None:\n    \"\"\"Aggregated statistics.\n\n    Args:\n        count_: Sample size (number of observations).\n        mean_: Dictionary of sample means with variable names as keys.\n        var_: Dictionary of sample variances with variable names as keys.\n        cov_: Dictionary of sample covariances with pairs of variable names as keys.\n    \"\"\"\n    self.count_ = count_\n    self.mean_ = mean_\n    self.var_ = var_\n    self.cov_ = {_sorted_tuple(*k): v for k, v in cov_.items()}\n</code></pre>"},{"location":"api/aggr/#tea_tasting.aggr.Aggregates.count","title":"<code>count()</code>","text":"<p>Sample size (number of observations).</p> <p>Returns:</p> Type Description <code>int</code> <p>Sample size (number of observations).</p> Source code in <code>src/tea_tasting/aggr.py</code> <pre><code>def count(self) -&gt; int:\n    \"\"\"Sample size (number of observations).\n\n    Returns:\n        Sample size (number of observations).\n    \"\"\"\n    if self.count_ is None:\n        raise RuntimeError(\"Count is None.\")\n    return self.count_\n</code></pre>"},{"location":"api/aggr/#tea_tasting.aggr.Aggregates.cov","title":"<code>cov(left, right)</code>","text":"<p>Sample covariance.</p> <p>Assume the variable is a constant if the variable name is <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>left</code> <code>str | None</code> <p>First variable name.</p> required <code>right</code> <code>str | None</code> <p>Second variable name.</p> required <p>Returns:</p> Type Description <code>float | int</code> <p>Sample covariance.</p> Source code in <code>src/tea_tasting/aggr.py</code> <pre><code>def cov(self, left: str | None, right: str | None) -&gt; float | int:\n    \"\"\"Sample covariance.\n\n    Assume the variable is a constant if the variable name is `None`.\n\n    Args:\n        left: First variable name.\n        right: Second variable name.\n\n    Returns:\n        Sample covariance.\n    \"\"\"\n    if left is None or right is None:\n        return 0\n    return self.cov_[_sorted_tuple(left, right)]\n</code></pre>"},{"location":"api/aggr/#tea_tasting.aggr.Aggregates.mean","title":"<code>mean(name)</code>","text":"<p>Sample mean.</p> <p>Assume the variable is a constant <code>1</code> if the variable name is <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Variable name.</p> required <p>Returns:</p> Type Description <code>float | int</code> <p>Sample mean.</p> Source code in <code>src/tea_tasting/aggr.py</code> <pre><code>def mean(self, name: str | None) -&gt; float | int:\n    \"\"\"Sample mean.\n\n    Assume the variable is a constant `1` if the variable name is `None`.\n\n    Args:\n        name: Variable name.\n\n    Returns:\n        Sample mean.\n    \"\"\"\n    if name is None:\n        return 1\n    return self.mean_[name]\n</code></pre>"},{"location":"api/aggr/#tea_tasting.aggr.Aggregates.ratio_cov","title":"<code>ratio_cov(left_numer, left_denom, right_numer, right_denom)</code>","text":"<p>Sample covariance of the ratios of variables using the Delta method.</p> <p>Parameters:</p> Name Type Description Default <code>left_numer</code> <code>str | None</code> <p>First numerator variable name.</p> required <code>left_denom</code> <code>str | None</code> <p>First denominator variable name.</p> required <code>right_numer</code> <code>str | None</code> <p>Second numerator variable name.</p> required <code>right_denom</code> <code>str | None</code> <p>Second denominator variable name.</p> required <p>Returns:</p> Type Description <code>float | int</code> <p>Sample covariance of the ratios of variables.</p> References <ul> <li>Delta method.</li> <li>Taylor expansions for the moments of functions of random variables.</li> </ul> Source code in <code>src/tea_tasting/aggr.py</code> <pre><code>def ratio_cov(\n    self,\n    left_numer: str | None,\n    left_denom: str | None,\n    right_numer: str | None,\n    right_denom: str | None,\n) -&gt; float | int:\n    \"\"\"Sample covariance of the ratios of variables using the Delta method.\n\n    Args:\n        left_numer: First numerator variable name.\n        left_denom: First denominator variable name.\n        right_numer: Second numerator variable name.\n        right_denom: Second denominator variable name.\n\n    Returns:\n        Sample covariance of the ratios of variables.\n\n    References:\n        - [Delta method](https://en.wikipedia.org/wiki/Delta_method).\n        - [Taylor expansions for the moments of functions of random variables](https://en.wikipedia.org/wiki/Taylor_expansions_for_the_moments_of_functions_of_random_variables).\n    \"\"\"\n    left_ratio_of_means = self.mean(left_numer) / self.mean(left_denom)\n    right_ratio_of_means = self.mean(right_numer) / self.mean(right_denom)\n    return (\n        self.cov(left_numer, right_numer)\n        - self.cov(left_numer, right_denom) * right_ratio_of_means\n        - self.cov(left_denom, right_numer) * left_ratio_of_means\n        + self.cov(left_denom, right_denom)\n            * left_ratio_of_means * right_ratio_of_means\n    ) / self.mean(left_denom) / self.mean(right_denom)\n</code></pre>"},{"location":"api/aggr/#tea_tasting.aggr.Aggregates.ratio_var","title":"<code>ratio_var(numer, denom)</code>","text":"<p>Sample variance of the ratio of two variables using the Delta method.</p> <p>Parameters:</p> Name Type Description Default <code>numer</code> <code>str | None</code> <p>Numerator variable name.</p> required <code>denom</code> <code>str | None</code> <p>Denominator variable name.</p> required <p>Returns:</p> Type Description <code>float | int</code> <p>Sample variance of the ratio of two variables.</p> References <ul> <li>Delta method.</li> <li>Taylor expansions for the moments of functions of random variables.</li> </ul> Source code in <code>src/tea_tasting/aggr.py</code> <pre><code>def ratio_var(\n    self,\n    numer: str | None,\n    denom: str | None,\n) -&gt; float | int:\n    \"\"\"Sample variance of the ratio of two variables using the Delta method.\n\n    Args:\n        numer: Numerator variable name.\n        denom: Denominator variable name.\n\n    Returns:\n        Sample variance of the ratio of two variables.\n\n    References:\n        - [Delta method](https://en.wikipedia.org/wiki/Delta_method).\n        - [Taylor expansions for the moments of functions of random variables](https://en.wikipedia.org/wiki/Taylor_expansions_for_the_moments_of_functions_of_random_variables).\n    \"\"\"\n    numer_mean_sq = self.mean(numer) * self.mean(numer)\n    denom_mean_sq = self.mean(denom) * self.mean(denom)\n    return (\n        self.var(numer)\n        - 2 * self.cov(numer, denom) * self.mean(numer) / self.mean(denom)\n        + self.var(denom) * numer_mean_sq / denom_mean_sq\n    ) / denom_mean_sq\n</code></pre>"},{"location":"api/aggr/#tea_tasting.aggr.Aggregates.var","title":"<code>var(name)</code>","text":"<p>Sample variance.</p> <p>Assume the variable is a constant if the variable name is <code>None</code>.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Variable name.</p> required <p>Returns:</p> Type Description <code>float | int</code> <p>Sample variance.</p> Source code in <code>src/tea_tasting/aggr.py</code> <pre><code>def var(self, name: str | None) -&gt; float | int:\n    \"\"\"Sample variance.\n\n    Assume the variable is a constant if the variable name is `None`.\n\n    Args:\n        name: Variable name.\n\n    Returns:\n        Sample variance.\n    \"\"\"\n    if name is None:\n        return 0\n    return self.var_[name]\n</code></pre>"},{"location":"api/aggr/#tea_tasting.aggr.Aggregates.with_zero_div","title":"<code>with_zero_div()</code>","text":"<p>Return aggregates that do not raise an error on division by zero.</p> <p>Division by zero returns:</p> <ul> <li><code>inf</code> if numerator is greater than <code>0</code>,</li> <li><code>nan</code> if numerator is equal to or less than <code>0</code>.</li> </ul> Source code in <code>src/tea_tasting/aggr.py</code> <pre><code>def with_zero_div(self) -&gt; Aggregates:\n    \"\"\"Return aggregates that do not raise an error on division by zero.\n\n    Division by zero returns:\n\n    - `inf` if numerator is greater than `0`,\n    - `nan` if numerator is equal to or less than `0`.\n    \"\"\"\n    return Aggregates(\n        count_=None if self.count_ is None else tea_tasting.utils.Int(self.count_),\n        mean_={k: tea_tasting.utils.numeric(v) for k, v in self.mean_.items()},\n        var_={k: tea_tasting.utils.numeric(v) for k, v in self.var_.items()},\n        cov_={k: tea_tasting.utils.numeric(v) for k, v in self.cov_.items()},\n    )\n</code></pre>"},{"location":"api/aggr/#tea_tasting.aggr.read_aggregates","title":"<code>read_aggregates(data, group_col, *, has_count, mean_cols, var_cols, cov_cols)</code>","text":"<p>Extract aggregated statistics.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Table | IntoFrame</code> <p>Granular data.</p> required <code>group_col</code> <code>str | None</code> <p>Column name to group by before aggregation. If <code>None</code>, total aggregates are calculated.</p> required <code>has_count</code> <code>bool</code> <p>If <code>True</code>, calculate the sample size.</p> required <code>mean_cols</code> <code>Sequence[str]</code> <p>Column names for calculation of sample means.</p> required <code>var_cols</code> <code>Sequence[str]</code> <p>Column names for calculation of sample variances.</p> required <code>cov_cols</code> <code>Sequence[tuple[str, str]]</code> <p>Pairs of column names for calculation of sample covariances.</p> required <p>Returns:</p> Type Description <code>dict[object, Aggregates] | Aggregates</code> <p>Aggregated statistics.</p> Source code in <code>src/tea_tasting/aggr.py</code> <pre><code>def read_aggregates(\n    data: ibis.expr.types.Table | narwhals.typing.IntoFrame,\n    group_col: str | None,\n    *,\n    has_count: bool,\n    mean_cols: Sequence[str],\n    var_cols: Sequence[str],\n    cov_cols: Sequence[tuple[str, str]],\n) -&gt; dict[object, Aggregates] | Aggregates:\n    \"\"\"Extract aggregated statistics.\n\n    Args:\n        data: Granular data.\n        group_col: Column name to group by before aggregation.\n            If `None`, total aggregates are calculated.\n        has_count: If `True`, calculate the sample size.\n        mean_cols: Column names for calculation of sample means.\n        var_cols: Column names for calculation of sample variances.\n        cov_cols: Pairs of column names for calculation of sample covariances.\n\n    Returns:\n        Aggregated statistics.\n    \"\"\"\n    mean_cols, var_cols, cov_cols = _validate_aggr_cols(mean_cols, var_cols, cov_cols)\n\n    if isinstance(data, ibis.expr.types.Table):\n        aggr_data = _read_aggr_ibis(\n            data=data,\n            group_col=group_col,\n            has_count=has_count,\n            mean_cols=mean_cols,\n            var_cols=var_cols,\n            cov_cols=cov_cols,\n        )\n    else:\n        aggr_data = _read_aggr_narwhals(\n            data=data,\n            group_col=group_col,\n            has_count=has_count,\n            mean_cols=mean_cols,\n            var_cols=var_cols,\n            cov_cols=cov_cols,\n        )\n\n    if group_col is None:\n        return _get_aggregates(\n            aggr_data[0],\n            has_count=has_count,\n            mean_cols=mean_cols,\n            var_cols=var_cols,\n            cov_cols=cov_cols,\n        )\n\n    return {\n        group_data[group_col]: _get_aggregates(\n            group_data,\n            has_count=has_count,\n            mean_cols=mean_cols,\n            var_cols=var_cols,\n            cov_cols=cov_cols,\n        )\n        for group_data in aggr_data\n    }\n</code></pre>"},{"location":"api/config/","title":"Global configuration","text":""},{"location":"api/config/#tea_tasting.config","title":"<code>tea_tasting.config</code>","text":"<p>Global configuration.</p>"},{"location":"api/config/#tea_tasting.config.config_context","title":"<code>config_context(*, alpha=None, alternative=None, confidence_level=None, equal_var=None, n_obs=None, n_resamples=None, power=None, ratio=None, use_t=None, **kwargs)</code>","text":"<p>A context manager that temporarily modifies the global configuration.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float | None</code> <p>Significance level. Default is 0.05.</p> <code>None</code> <code>alternative</code> <code>Literal['two-sided', 'greater', 'less'] | None</code> <p>Alternative hypothesis:</p> <ul> <li><code>\"two-sided\"</code>: the means are unequal,</li> <li><code>\"greater\"</code>: the mean in the treatment variant is greater than the mean     in the control variant,</li> <li><code>\"less\"</code>: the mean in the treatment variant is less than the mean     in the control variant.</li> </ul> <p>Default is <code>\"two-sided\"</code>.</p> <code>None</code> <code>confidence_level</code> <code>float | None</code> <p>Confidence level for the confidence interval. Default is <code>0.95</code>.</p> <code>None</code> <code>equal_var</code> <code>bool | None</code> <p>Defines whether equal variance is assumed. If <code>True</code>, pooled variance is used for the calculation of the standard error of the difference between two means. Default is <code>False</code>.</p> <code>None</code> <code>n_obs</code> <code>int | Sequence[int] | None</code> <p>Number of observations in the control and in the treatment together. Default is <code>None</code>.</p> <code>None</code> <code>n_resamples</code> <code>int | None</code> <p>The number of resamples performed to form the bootstrap distribution of a statistic. Default is <code>10_000</code>.</p> <code>None</code> <code>power</code> <code>float | None</code> <p>Statistical power. Default is 0.8.</p> <code>None</code> <code>ratio</code> <code>float | int | None</code> <p>Ratio of the number of observations in the treatment relative to the control. Default is 1.</p> <code>None</code> <code>use_t</code> <code>bool | None</code> <p>Defines whether to use the Student's t-distribution (<code>True</code>) or the Normal distribution (<code>False</code>) by default. Default is <code>True</code>.</p> <code>None</code> <code>**kwargs</code> <code>object</code> <p>User-defined global parameters.</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; with tt.config_context(equal_var=True, use_t=False):\n...     experiment = tt.Experiment(\n...         sessions_per_user=tt.Mean(\"sessions\"),\n...         orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\"),\n...         orders_per_user=tt.Mean(\"orders\"),\n...         revenue_per_user=tt.Mean(\"revenue\"),\n...     )\n&gt;&gt;&gt; experiment.metrics[\"orders_per_user\"]\nMean(value='orders', covariate=None, alternative='two-sided', confidence_level=0.95, equal_var=True, use_t=False, alpha=0.05, ratio=1, power=0.8, effect_size=None, rel_effect_size=None, n_obs=None)\n</code></pre> Source code in <code>src/tea_tasting/config.py</code> <pre><code>@contextlib.contextmanager\ndef config_context(\n    *,\n    alpha: float | None = None,\n    alternative: Literal[\"two-sided\", \"greater\", \"less\"] | None = None,\n    confidence_level: float | None = None,\n    equal_var: bool | None = None,\n    n_obs: int | Sequence[int] | None = None,\n    n_resamples: int | None = None,\n    power: float | None = None,\n    ratio: float | int | None = None,\n    use_t: bool | None = None,\n    **kwargs: object,\n) -&gt; Iterator[object]:\n    \"\"\"A context manager that temporarily modifies the global configuration.\n\n    Args:\n        alpha: Significance level. Default is 0.05.\n        alternative: Alternative hypothesis:\n\n            - `\"two-sided\"`: the means are unequal,\n            - `\"greater\"`: the mean in the treatment variant is greater than the mean\n                in the control variant,\n            - `\"less\"`: the mean in the treatment variant is less than the mean\n                in the control variant.\n\n            Default is `\"two-sided\"`.\n\n        confidence_level: Confidence level for the confidence interval.\n            Default is `0.95`.\n        equal_var: Defines whether equal variance is assumed. If `True`,\n            pooled variance is used for the calculation of the standard error\n            of the difference between two means. Default is `False`.\n        n_obs: Number of observations in the control and in the treatment together.\n            Default is `None`.\n        n_resamples: The number of resamples performed to form the bootstrap\n            distribution of a statistic. Default is `10_000`.\n        power: Statistical power. Default is 0.8.\n        ratio: Ratio of the number of observations in the treatment\n            relative to the control. Default is 1.\n        use_t: Defines whether to use the Student's t-distribution (`True`) or\n            the Normal distribution (`False`) by default. Default is `True`.\n        **kwargs: User-defined global parameters.\n\n    Examples:\n        ```pycon\n        &gt;&gt;&gt; import tea_tasting as tt\n\n        &gt;&gt;&gt; with tt.config_context(equal_var=True, use_t=False):\n        ...     experiment = tt.Experiment(\n        ...         sessions_per_user=tt.Mean(\"sessions\"),\n        ...         orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\"),\n        ...         orders_per_user=tt.Mean(\"orders\"),\n        ...         revenue_per_user=tt.Mean(\"revenue\"),\n        ...     )\n        &gt;&gt;&gt; experiment.metrics[\"orders_per_user\"]\n        Mean(value='orders', covariate=None, alternative='two-sided', confidence_level=0.95, equal_var=True, use_t=False, alpha=0.05, ratio=1, power=0.8, effect_size=None, rel_effect_size=None, n_obs=None)\n\n        ```\n    \"\"\"  # noqa: E501\n    token = _set_config(\n        **{k: v for k, v in locals().items() if k != \"kwargs\"},\n        **kwargs,\n    )\n    try:\n        yield\n    finally:\n        _config_var.reset(token)\n</code></pre>"},{"location":"api/config/#tea_tasting.config.get_config","title":"<code>get_config(option=None)</code>","text":"<p>Retrieve the current settings of the global configuration.</p> <p>Parameters:</p> Name Type Description Default <code>option</code> <code>str | None</code> <p>The option name.</p> <code>None</code> <p>Returns:</p> Type Description <code>object</code> <p>The specified option value if its name is provided, or a dictionary containing all options otherwise.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; tt.get_config(\"equal_var\")\nFalse\n</code></pre> Source code in <code>src/tea_tasting/config.py</code> <pre><code>def get_config(option: str | None = None) -&gt; object:\n    \"\"\"Retrieve the current settings of the global configuration.\n\n    Args:\n        option: The option name.\n\n    Returns:\n        The specified option value if its name is provided,\n            or a dictionary containing all options otherwise.\n\n    Examples:\n        ```pycon\n        &gt;&gt;&gt; import tea_tasting as tt\n\n        &gt;&gt;&gt; tt.get_config(\"equal_var\")\n        False\n\n        ```\n    \"\"\"\n    config = _config_var.get()\n    return config[option] if option is not None else config.copy()\n</code></pre>"},{"location":"api/config/#tea_tasting.config.set_config","title":"<code>set_config(*, alpha=None, alternative=None, confidence_level=None, equal_var=None, n_obs=None, n_resamples=None, power=None, ratio=None, use_t=None, **kwargs)</code>","text":"<p>Update the global configuration with specified settings.</p> <p>Parameters:</p> Name Type Description Default <code>alpha</code> <code>float | None</code> <p>Significance level. Default is 0.05.</p> <code>None</code> <code>alternative</code> <code>Literal['two-sided', 'greater', 'less'] | None</code> <p>Alternative hypothesis:</p> <ul> <li><code>\"two-sided\"</code>: the means are unequal,</li> <li><code>\"greater\"</code>: the mean in the treatment variant is greater than the mean     in the control variant,</li> <li><code>\"less\"</code>: the mean in the treatment variant is less than the mean     in the control variant.</li> </ul> <p>Default is <code>\"two-sided\"</code>.</p> <code>None</code> <code>confidence_level</code> <code>float | None</code> <p>Confidence level for the confidence interval. Default is <code>0.95</code>.</p> <code>None</code> <code>equal_var</code> <code>bool | None</code> <p>Defines whether equal variance is assumed. If <code>True</code>, pooled variance is used for the calculation of the standard error of the difference between two means. Default is <code>False</code>.</p> <code>None</code> <code>n_obs</code> <code>int | Sequence[int] | None</code> <p>Number of observations in the control and in the treatment together. Default is <code>None</code>.</p> <code>None</code> <code>n_resamples</code> <code>int | None</code> <p>The number of resamples performed to form the bootstrap distribution of a statistic. Default is <code>10_000</code>.</p> <code>None</code> <code>power</code> <code>float | None</code> <p>Statistical power. Default is 0.8.</p> <code>None</code> <code>ratio</code> <code>float | int | None</code> <p>Ratio of the number of observations in the treatment relative to the control. Default is 1.</p> <code>None</code> <code>use_t</code> <code>bool | None</code> <p>Defines whether to use the Student's t-distribution (<code>True</code>) or the Normal distribution (<code>False</code>) by default. Default is <code>True</code>.</p> <code>None</code> <code>**kwargs</code> <code>object</code> <p>User-defined global parameters.</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; tt.set_config(equal_var=True, use_t=False)\n&gt;&gt;&gt; experiment = tt.Experiment(\n...     sessions_per_user=tt.Mean(\"sessions\"),\n...     orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\"),\n...     orders_per_user=tt.Mean(\"orders\"),\n...     revenue_per_user=tt.Mean(\"revenue\"),\n... )\n&gt;&gt;&gt; tt.set_config(equal_var=False, use_t=True)\n&gt;&gt;&gt; experiment.metrics[\"orders_per_user\"]\nMean(value='orders', covariate=None, alternative='two-sided', confidence_level=0.95, equal_var=True, use_t=False, alpha=0.05, ratio=1, power=0.8, effect_size=None, rel_effect_size=None, n_obs=None)\n</code></pre> Source code in <code>src/tea_tasting/config.py</code> <pre><code>def set_config(\n    *,\n    alpha: float | None = None,\n    alternative: Literal[\"two-sided\", \"greater\", \"less\"] | None = None,\n    confidence_level: float | None = None,\n    equal_var: bool | None = None,\n    n_obs: int | Sequence[int] | None = None,\n    n_resamples: int | None = None,\n    power: float | None = None,\n    ratio: float | int | None = None,\n    use_t: bool | None = None,\n    **kwargs: object,\n) -&gt; None:\n    \"\"\"Update the global configuration with specified settings.\n\n    Args:\n        alpha: Significance level. Default is 0.05.\n        alternative: Alternative hypothesis:\n\n            - `\"two-sided\"`: the means are unequal,\n            - `\"greater\"`: the mean in the treatment variant is greater than the mean\n                in the control variant,\n            - `\"less\"`: the mean in the treatment variant is less than the mean\n                in the control variant.\n\n            Default is `\"two-sided\"`.\n\n        confidence_level: Confidence level for the confidence interval.\n            Default is `0.95`.\n        equal_var: Defines whether equal variance is assumed. If `True`,\n            pooled variance is used for the calculation of the standard error\n            of the difference between two means. Default is `False`.\n        n_obs: Number of observations in the control and in the treatment together.\n            Default is `None`.\n        n_resamples: The number of resamples performed to form the bootstrap\n            distribution of a statistic. Default is `10_000`.\n        power: Statistical power. Default is 0.8.\n        ratio: Ratio of the number of observations in the treatment\n            relative to the control. Default is 1.\n        use_t: Defines whether to use the Student's t-distribution (`True`) or\n            the Normal distribution (`False`) by default. Default is `True`.\n        **kwargs: User-defined global parameters.\n\n    Examples:\n        ```pycon\n        &gt;&gt;&gt; import tea_tasting as tt\n\n        &gt;&gt;&gt; tt.set_config(equal_var=True, use_t=False)\n        &gt;&gt;&gt; experiment = tt.Experiment(\n        ...     sessions_per_user=tt.Mean(\"sessions\"),\n        ...     orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\"),\n        ...     orders_per_user=tt.Mean(\"orders\"),\n        ...     revenue_per_user=tt.Mean(\"revenue\"),\n        ... )\n        &gt;&gt;&gt; tt.set_config(equal_var=False, use_t=True)\n        &gt;&gt;&gt; experiment.metrics[\"orders_per_user\"]\n        Mean(value='orders', covariate=None, alternative='two-sided', confidence_level=0.95, equal_var=True, use_t=False, alpha=0.05, ratio=1, power=0.8, effect_size=None, rel_effect_size=None, n_obs=None)\n\n        ```\n    \"\"\"  # noqa: E501\n    _set_config(**{k: v for k, v in locals().items() if k != \"kwargs\"}, **kwargs)\n</code></pre>"},{"location":"api/datasets/","title":"Datasets","text":""},{"location":"api/datasets/#tea_tasting.datasets","title":"<code>tea_tasting.datasets</code>","text":"<p>Example datasets.</p>"},{"location":"api/datasets/#tea_tasting.datasets.make_users_data","title":"<code>make_users_data(*, covariates=False, seed=None, n_users=4000, ratio=1, sessions_uplift=0.0, orders_uplift=0.1, revenue_uplift=0.1, avg_sessions=2, avg_orders_per_session=0.25, avg_revenue_per_order=10, return_type='arrow')</code>","text":"<p>Generate simulated data for A/B testing scenarios.</p> <p>Data mimics what you might encounter in an A/B test for an online store, with a user-level randomization. Each row represents an individual user with information about:</p> <ul> <li><code>user</code>: User identifier.</li> <li><code>variant</code>: Variant of the test. 0 is control, 1 is treatment.</li> <li><code>sessions</code>: Number of user's sessions.</li> <li><code>orders</code>: Number of user's orders.</li> <li><code>revenue</code>: Revenue generated by the user.</li> </ul> <p>Optionally, pre-experimental data can be generated as well:</p> <ul> <li><code>sessions_covariate</code>: Number of user's sessions     before the experiment.</li> <li><code>orders_covariate</code>: Number of user's orders before the experiment.</li> <li><code>revenue_covariate</code>: Revenue generated by the user     before the experiment.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>covariates</code> <code>bool</code> <p>If <code>True</code>, generates pre-experimental data as the covariates in addition to default columns.</p> <code>False</code> <code>seed</code> <code>int | Generator | SeedSequence | None</code> <p>Random seed.</p> <code>None</code> <code>n_users</code> <code>int</code> <p>Number of users.</p> <code>4000</code> <code>ratio</code> <code>float | int</code> <p>Ratio of the number of users in treatment relative to control.</p> <code>1</code> <code>sessions_uplift</code> <code>float | int</code> <p>Sessions uplift in the treatment variant, relative to control.</p> <code>0.0</code> <code>orders_uplift</code> <code>float</code> <p>Orders uplift in the treatment variant, relative to control.</p> <code>0.1</code> <code>revenue_uplift</code> <code>float</code> <p>Revenue uplift in the treatment variant, relative to control.</p> <code>0.1</code> <code>avg_sessions</code> <code>float | int</code> <p>Average number of sessions per user.</p> <code>2</code> <code>avg_orders_per_session</code> <code>float</code> <p>Average number of orders per session. Should be less than <code>1</code>.</p> <code>0.25</code> <code>avg_revenue_per_order</code> <code>float | int</code> <p>Average revenue per order.</p> <code>10</code> <code>return_type</code> <code>Literal['arrow', 'pandas', 'polars']</code> <p>Return type:</p> <ul> <li><code>\"arrow\"</code>: PyArrow Table.</li> <li><code>\"pandas\"</code>: Pandas DataFrame.</li> <li><code>\"polars\"</code>: Polars DataFrame.</li> </ul> <code>'arrow'</code> <p>Returns:</p> Type Description <code>Table | DataFrame | DataFrame</code> <p>Simulated data for A/B testing scenarios.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; data = tt.make_users_data(seed=42)\n&gt;&gt;&gt; data\npyarrow.Table\nuser: int64\nvariant: int64\nsessions: int64\norders: int64\nrevenue: double\n----\nuser: [[0,1,2,3,4,...,3995,3996,3997,3998,3999]]\nvariant: [[1,0,1,1,0,...,0,0,0,0,0]]\nsessions: [[2,2,2,2,1,...,2,2,3,1,5]]\norders: [[1,1,1,1,1,...,0,0,0,0,2]]\nrevenue: [[9.17,6.43,7.94,15.93,7.14,...,0,0,0,0,17.16]]\n</code></pre> <p>With covariates:</p> <pre><code>&gt;&gt;&gt; data = tt.make_users_data(seed=42, covariates=True)\n&gt;&gt;&gt; data\npyarrow.Table\nuser: int64\nvariant: int64\nsessions: int64\norders: int64\nrevenue: double\nsessions_covariate: int64\norders_covariate: int64\nrevenue_covariate: double\n----\nuser: [[0,1,2,3,4,...,3995,3996,3997,3998,3999]]\nvariant: [[1,0,1,1,0,...,0,0,0,0,0]]\nsessions: [[2,2,2,2,1,...,2,2,3,1,5]]\norders: [[1,1,1,1,1,...,0,0,0,0,2]]\nrevenue: [[9.17,6.43,7.94,15.93,7.14,...,0,0,0,0,17.16]]\nsessions_covariate: [[3,4,4,1,1,...,1,3,2,1,5]]\norders_covariate: [[2,1,2,0,1,...,0,1,0,0,0]]\nrevenue_covariate: [[19.19,2.77,22.57,0,13.68,...,0,13.52,0,0,0]]\n</code></pre> <p>As Pandas DataFrame:</p> <pre><code>&gt;&gt;&gt; data = tt.make_users_data(seed=42, return_type=\"pandas\")\n&gt;&gt;&gt; data\n      user  variant  sessions  orders  revenue\n0        0        1         2       1     9.17\n1        1        0         2       1     6.43\n2        2        1         2       1     7.94\n3        3        1         2       1    15.93\n4        4        0         1       1     7.14\n...    ...      ...       ...     ...      ...\n3995  3995        0         2       0     0.00\n3996  3996        0         2       0     0.00\n3997  3997        0         3       0     0.00\n3998  3998        0         1       0     0.00\n3999  3999        0         5       2    17.16\n\n[4000 rows x 5 columns]\n</code></pre> <p>As Polars DataFrame:</p> <pre><code>&gt;&gt;&gt; data = tt.make_users_data(seed=42, return_type=\"polars\")\n&gt;&gt;&gt; data\nshape: (4_000, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 user \u2506 variant \u2506 sessions \u2506 orders \u2506 revenue \u2502\n\u2502 ---  \u2506 ---     \u2506 ---      \u2506 ---    \u2506 ---     \u2502\n\u2502 i64  \u2506 i64     \u2506 i64      \u2506 i64    \u2506 f64     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0    \u2506 1       \u2506 2        \u2506 1      \u2506 9.17    \u2502\n\u2502 1    \u2506 0       \u2506 2        \u2506 1      \u2506 6.43    \u2502\n\u2502 2    \u2506 1       \u2506 2        \u2506 1      \u2506 7.94    \u2502\n\u2502 3    \u2506 1       \u2506 2        \u2506 1      \u2506 15.93   \u2502\n\u2502 4    \u2506 0       \u2506 1        \u2506 1      \u2506 7.14    \u2502\n\u2502 \u2026    \u2506 \u2026       \u2506 \u2026        \u2506 \u2026      \u2506 \u2026       \u2502\n\u2502 3995 \u2506 0       \u2506 2        \u2506 0      \u2506 0.0     \u2502\n\u2502 3996 \u2506 0       \u2506 2        \u2506 0      \u2506 0.0     \u2502\n\u2502 3997 \u2506 0       \u2506 3        \u2506 0      \u2506 0.0     \u2502\n\u2502 3998 \u2506 0       \u2506 1        \u2506 0      \u2506 0.0     \u2502\n\u2502 3999 \u2506 0       \u2506 5        \u2506 2      \u2506 17.16   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Source code in <code>src/tea_tasting/datasets.py</code> <pre><code>def make_users_data(\n    *,\n    covariates: bool = False,\n    seed: int | np.random.Generator | np.random.SeedSequence | None = None,\n    n_users: int = 4000,\n    ratio: float | int = 1,\n    sessions_uplift: float | int = 0.0,\n    orders_uplift: float = 0.1,\n    revenue_uplift: float = 0.1,\n    avg_sessions: float | int = 2,\n    avg_orders_per_session: float = 0.25,\n    avg_revenue_per_order: float | int = 10,\n    return_type: Literal[\"arrow\", \"pandas\", \"polars\"] = \"arrow\",\n) -&gt; pa.Table | pd.DataFrame | pl.DataFrame:\n    \"\"\"Generate simulated data for A/B testing scenarios.\n\n    Data mimics what you might encounter in an A/B test for an online store,\n    with a user-level randomization. Each row represents an individual user\n    with information about:\n\n    - `user`: User identifier.\n    - `variant`: Variant of the test. 0 is control, 1 is treatment.\n    - `sessions`: Number of user's sessions.\n    - `orders`: Number of user's orders.\n    - `revenue`: Revenue generated by the user.\n\n    Optionally, pre-experimental data can be generated as well:\n\n    - `sessions_covariate`: Number of user's sessions\n        before the experiment.\n    - `orders_covariate`: Number of user's orders before the experiment.\n    - `revenue_covariate`: Revenue generated by the user\n        before the experiment.\n\n    Args:\n        covariates: If `True`, generates pre-experimental data as the covariates\n            in addition to default columns.\n        seed: Random seed.\n        n_users: Number of users.\n        ratio: Ratio of the number of users in treatment relative to control.\n        sessions_uplift: Sessions uplift in the treatment variant, relative to control.\n        orders_uplift: Orders uplift in the treatment variant, relative to control.\n        revenue_uplift: Revenue uplift in the treatment variant, relative to control.\n        avg_sessions: Average number of sessions per user.\n        avg_orders_per_session: Average number of orders per session.\n            Should be less than `1`.\n        avg_revenue_per_order: Average revenue per order.\n        return_type: Return type:\n\n            - `\"arrow\"`: PyArrow Table.\n            - `\"pandas\"`: Pandas DataFrame.\n            - `\"polars\"`: Polars DataFrame.\n\n    Returns:\n        Simulated data for A/B testing scenarios.\n\n    Examples:\n        ```pycon\n        &gt;&gt;&gt; import tea_tasting as tt\n\n        &gt;&gt;&gt; data = tt.make_users_data(seed=42)\n        &gt;&gt;&gt; data\n        pyarrow.Table\n        user: int64\n        variant: int64\n        sessions: int64\n        orders: int64\n        revenue: double\n        ----\n        user: [[0,1,2,3,4,...,3995,3996,3997,3998,3999]]\n        variant: [[1,0,1,1,0,...,0,0,0,0,0]]\n        sessions: [[2,2,2,2,1,...,2,2,3,1,5]]\n        orders: [[1,1,1,1,1,...,0,0,0,0,2]]\n        revenue: [[9.17,6.43,7.94,15.93,7.14,...,0,0,0,0,17.16]]\n\n        ```\n\n        With covariates:\n\n        ```pycon\n        &gt;&gt;&gt; data = tt.make_users_data(seed=42, covariates=True)\n        &gt;&gt;&gt; data\n        pyarrow.Table\n        user: int64\n        variant: int64\n        sessions: int64\n        orders: int64\n        revenue: double\n        sessions_covariate: int64\n        orders_covariate: int64\n        revenue_covariate: double\n        ----\n        user: [[0,1,2,3,4,...,3995,3996,3997,3998,3999]]\n        variant: [[1,0,1,1,0,...,0,0,0,0,0]]\n        sessions: [[2,2,2,2,1,...,2,2,3,1,5]]\n        orders: [[1,1,1,1,1,...,0,0,0,0,2]]\n        revenue: [[9.17,6.43,7.94,15.93,7.14,...,0,0,0,0,17.16]]\n        sessions_covariate: [[3,4,4,1,1,...,1,3,2,1,5]]\n        orders_covariate: [[2,1,2,0,1,...,0,1,0,0,0]]\n        revenue_covariate: [[19.19,2.77,22.57,0,13.68,...,0,13.52,0,0,0]]\n\n        ```\n\n        As Pandas DataFrame:\n\n        ```pycon\n        &gt;&gt;&gt; data = tt.make_users_data(seed=42, return_type=\"pandas\")\n        &gt;&gt;&gt; data\n              user  variant  sessions  orders  revenue\n        0        0        1         2       1     9.17\n        1        1        0         2       1     6.43\n        2        2        1         2       1     7.94\n        3        3        1         2       1    15.93\n        4        4        0         1       1     7.14\n        ...    ...      ...       ...     ...      ...\n        3995  3995        0         2       0     0.00\n        3996  3996        0         2       0     0.00\n        3997  3997        0         3       0     0.00\n        3998  3998        0         1       0     0.00\n        3999  3999        0         5       2    17.16\n        &lt;BLANKLINE&gt;\n        [4000 rows x 5 columns]\n\n        ```\n\n        As Polars DataFrame:\n\n        ```pycon\n        &gt;&gt;&gt; data = tt.make_users_data(seed=42, return_type=\"polars\")\n        &gt;&gt;&gt; data\n        shape: (4_000, 5)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 user \u2506 variant \u2506 sessions \u2506 orders \u2506 revenue \u2502\n        \u2502 ---  \u2506 ---     \u2506 ---      \u2506 ---    \u2506 ---     \u2502\n        \u2502 i64  \u2506 i64     \u2506 i64      \u2506 i64    \u2506 f64     \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 0    \u2506 1       \u2506 2        \u2506 1      \u2506 9.17    \u2502\n        \u2502 1    \u2506 0       \u2506 2        \u2506 1      \u2506 6.43    \u2502\n        \u2502 2    \u2506 1       \u2506 2        \u2506 1      \u2506 7.94    \u2502\n        \u2502 3    \u2506 1       \u2506 2        \u2506 1      \u2506 15.93   \u2502\n        \u2502 4    \u2506 0       \u2506 1        \u2506 1      \u2506 7.14    \u2502\n        \u2502 \u2026    \u2506 \u2026       \u2506 \u2026        \u2506 \u2026      \u2506 \u2026       \u2502\n        \u2502 3995 \u2506 0       \u2506 2        \u2506 0      \u2506 0.0     \u2502\n        \u2502 3996 \u2506 0       \u2506 2        \u2506 0      \u2506 0.0     \u2502\n        \u2502 3997 \u2506 0       \u2506 3        \u2506 0      \u2506 0.0     \u2502\n        \u2502 3998 \u2506 0       \u2506 1        \u2506 0      \u2506 0.0     \u2502\n        \u2502 3999 \u2506 0       \u2506 5        \u2506 2      \u2506 17.16   \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n        ```\n    \"\"\"\n    return _make_data(\n        covariates=covariates,\n        seed=seed,\n        n_users=n_users,\n        ratio=ratio,\n        sessions_uplift=sessions_uplift,\n        orders_uplift=orders_uplift,\n        revenue_uplift=revenue_uplift,\n        avg_sessions=avg_sessions,\n        avg_orders_per_session=avg_orders_per_session,\n        avg_revenue_per_order=avg_revenue_per_order,\n        return_type=return_type,\n        explode_sessions=False,\n    )\n</code></pre>"},{"location":"api/datasets/#tea_tasting.datasets.make_sessions_data","title":"<code>make_sessions_data(*, covariates=False, seed=None, n_users=4000, ratio=1, sessions_uplift=0.0, orders_uplift=0.1, revenue_uplift=0.1, avg_sessions=2, avg_orders_per_session=0.25, avg_revenue_per_order=10, return_type='arrow')</code>","text":"<p>Generate simulated user data for A/B testing scenarios.</p> <p>Data mimics what you might encounter in an A/B test for an online store, with a user-level randomization. Each row represents a user's session with information about:</p> <ul> <li><code>user</code>: User identifier.</li> <li><code>variant</code>: Variant of the test. 0 is control, 1 is treatment.</li> <li><code>sessions</code>: Number of user's sessions.</li> <li><code>orders</code>: Number of user's orders.</li> <li><code>revenue</code>: Revenue generated by the user.</li> </ul> <p>Optionally, pre-experimental data can be generated as well:</p> <ul> <li><code>sessions_covariate</code>: Number of user's sessions     before the experiment.</li> <li><code>orders_covariate</code>: Number of user's orders before the experiment.</li> <li><code>revenue_covariate</code>: Revenue generated by the user     before the experiment.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>covariates</code> <code>bool</code> <p>If <code>True</code>, generates pre-experimental data as the covariates in addition to default columns.</p> <code>False</code> <code>seed</code> <code>int | Generator | SeedSequence | None</code> <p>Random seed.</p> <code>None</code> <code>n_users</code> <code>int</code> <p>Number of users.</p> <code>4000</code> <code>ratio</code> <code>float | int</code> <p>Ratio of the number of users in treatment relative to control.</p> <code>1</code> <code>sessions_uplift</code> <code>float | int</code> <p>Sessions uplift in the treatment variant, relative to control.</p> <code>0.0</code> <code>orders_uplift</code> <code>float</code> <p>Orders uplift in the treatment variant, relative to control.</p> <code>0.1</code> <code>revenue_uplift</code> <code>float</code> <p>Revenue uplift in the treatment variant, relative to control.</p> <code>0.1</code> <code>avg_sessions</code> <code>float | int</code> <p>Average number of sessions per user.</p> <code>2</code> <code>avg_orders_per_session</code> <code>float</code> <p>Average number of orders per session. Should be less than <code>1</code>.</p> <code>0.25</code> <code>avg_revenue_per_order</code> <code>float | int</code> <p>Average revenue per order.</p> <code>10</code> <code>return_type</code> <code>Literal['arrow', 'pandas', 'polars']</code> <p>Return type:</p> <ul> <li><code>\"arrow\"</code>: PyArrow Table.</li> <li><code>\"pandas\"</code>: Pandas DataFrame.</li> <li><code>\"polars\"</code>: Polars DataFrame.</li> </ul> <code>'arrow'</code> <p>Returns:</p> Type Description <code>Table | DataFrame | DataFrame</code> <p>Simulated data for A/B testing scenarios.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; data = tt.make_sessions_data(seed=42)\n&gt;&gt;&gt; data\npyarrow.Table\nuser: int64\nvariant: int64\nsessions: int64\norders: int64\nrevenue: double\n----\nuser: [[0,0,1,1,2,...,3999,3999,3999,3999,3999]]\nvariant: [[1,1,0,0,1,...,0,0,0,0,0]]\nsessions: [[1,1,1,1,1,...,1,1,1,1,1]]\norders: [[1,1,1,1,1,...,1,0,1,1,0]]\nrevenue: [[5.89,6.13,2.61,12.3,11.57,...,23.63,0,2.4,24.54,0]]\n</code></pre> <p>With covariates:</p> <pre><code>&gt;&gt;&gt; data = tt.make_sessions_data(seed=42, covariates=True)\n&gt;&gt;&gt; data\npyarrow.Table\nuser: int64\nvariant: int64\nsessions: int64\norders: int64\nrevenue: double\nsessions_covariate: double\norders_covariate: double\nrevenue_covariate: double\n----\nuser: [[0,0,1,1,2,...,3999,3999,3999,3999,3999]]\nvariant: [[1,1,0,0,1,...,0,0,0,0,0]]\nsessions: [[1,1,1,1,1,...,1,1,1,1,1]]\norders: [[1,1,1,1,1,...,1,0,1,1,0]]\nrevenue: [[5.89,6.13,2.61,12.3,11.57,...,23.63,0,2.4,24.54,0]]\nsessions_covariate: [[1.5,1.5,0,0,1.5,...,0.2,0.2,0.2,0.2,0.2]]\norders_covariate: [[0.5,0.5,0,0,1.5,...,0,0,0,0,0]]\nrevenue_covariate: [[1.24,1.24,0,0,12.32,...,0,0,0,0,0]]\n</code></pre> <p>As Pandas DataFrame:</p> <pre><code>&gt;&gt;&gt; data = tt.make_sessions_data(seed=42, return_type=\"pandas\")\n&gt;&gt;&gt; data\n      user  variant  sessions  orders  revenue\n0        0        1         1       1     5.89\n1        0        1         1       1     6.13\n2        1        0         1       1     2.61\n3        1        0         1       1    12.30\n4        2        1         1       1    11.57\n...    ...      ...       ...     ...      ...\n7953  3999        0         1       1    23.63\n7954  3999        0         1       0     0.00\n7955  3999        0         1       1     2.40\n7956  3999        0         1       1    24.54\n7957  3999        0         1       0     0.00\n\n[7958 rows x 5 columns]\n</code></pre> <p>As Polars DataFrame:</p> <pre><code>&gt;&gt;&gt; data = tt.make_sessions_data(seed=42, return_type=\"polars\")\n&gt;&gt;&gt; data\nshape: (7_958, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 user \u2506 variant \u2506 sessions \u2506 orders \u2506 revenue \u2502\n\u2502 ---  \u2506 ---     \u2506 ---      \u2506 ---    \u2506 ---     \u2502\n\u2502 i64  \u2506 i64     \u2506 i64      \u2506 i64    \u2506 f64     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0    \u2506 1       \u2506 1        \u2506 1      \u2506 5.89    \u2502\n\u2502 0    \u2506 1       \u2506 1        \u2506 1      \u2506 6.13    \u2502\n\u2502 1    \u2506 0       \u2506 1        \u2506 1      \u2506 2.61    \u2502\n\u2502 1    \u2506 0       \u2506 1        \u2506 1      \u2506 12.3    \u2502\n\u2502 2    \u2506 1       \u2506 1        \u2506 1      \u2506 11.57   \u2502\n\u2502 \u2026    \u2506 \u2026       \u2506 \u2026        \u2506 \u2026      \u2506 \u2026       \u2502\n\u2502 3999 \u2506 0       \u2506 1        \u2506 1      \u2506 23.63   \u2502\n\u2502 3999 \u2506 0       \u2506 1        \u2506 0      \u2506 0.0     \u2502\n\u2502 3999 \u2506 0       \u2506 1        \u2506 1      \u2506 2.4     \u2502\n\u2502 3999 \u2506 0       \u2506 1        \u2506 1      \u2506 24.54   \u2502\n\u2502 3999 \u2506 0       \u2506 1        \u2506 0      \u2506 0.0     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> Source code in <code>src/tea_tasting/datasets.py</code> <pre><code>def make_sessions_data(\n    *,\n    covariates: bool = False,\n    seed: int | np.random.Generator | np.random.SeedSequence | None = None,\n    n_users: int = 4000,\n    ratio: float | int = 1,\n    sessions_uplift: float | int = 0.0,\n    orders_uplift: float = 0.1,\n    revenue_uplift: float = 0.1,\n    avg_sessions: float | int = 2,\n    avg_orders_per_session: float = 0.25,\n    avg_revenue_per_order: float | int = 10,\n    return_type: Literal[\"arrow\", \"pandas\", \"polars\"] = \"arrow\",\n) -&gt; pa.Table | pd.DataFrame | pl.DataFrame:\n    \"\"\"Generate simulated user data for A/B testing scenarios.\n\n    Data mimics what you might encounter in an A/B test for an online store,\n    with a user-level randomization. Each row represents a user's session\n    with information about:\n\n    - `user`: User identifier.\n    - `variant`: Variant of the test. 0 is control, 1 is treatment.\n    - `sessions`: Number of user's sessions.\n    - `orders`: Number of user's orders.\n    - `revenue`: Revenue generated by the user.\n\n    Optionally, pre-experimental data can be generated as well:\n\n    - `sessions_covariate`: Number of user's sessions\n        before the experiment.\n    - `orders_covariate`: Number of user's orders before the experiment.\n    - `revenue_covariate`: Revenue generated by the user\n        before the experiment.\n\n    Args:\n        covariates: If `True`, generates pre-experimental data as the covariates\n            in addition to default columns.\n        seed: Random seed.\n        n_users: Number of users.\n        ratio: Ratio of the number of users in treatment relative to control.\n        sessions_uplift: Sessions uplift in the treatment variant, relative to control.\n        orders_uplift: Orders uplift in the treatment variant, relative to control.\n        revenue_uplift: Revenue uplift in the treatment variant, relative to control.\n        avg_sessions: Average number of sessions per user.\n        avg_orders_per_session: Average number of orders per session.\n            Should be less than `1`.\n        avg_revenue_per_order: Average revenue per order.\n        return_type: Return type:\n\n            - `\"arrow\"`: PyArrow Table.\n            - `\"pandas\"`: Pandas DataFrame.\n            - `\"polars\"`: Polars DataFrame.\n\n    Returns:\n        Simulated data for A/B testing scenarios.\n\n    Examples:\n        ```pycon\n        &gt;&gt;&gt; import tea_tasting as tt\n\n        &gt;&gt;&gt; data = tt.make_sessions_data(seed=42)\n        &gt;&gt;&gt; data\n        pyarrow.Table\n        user: int64\n        variant: int64\n        sessions: int64\n        orders: int64\n        revenue: double\n        ----\n        user: [[0,0,1,1,2,...,3999,3999,3999,3999,3999]]\n        variant: [[1,1,0,0,1,...,0,0,0,0,0]]\n        sessions: [[1,1,1,1,1,...,1,1,1,1,1]]\n        orders: [[1,1,1,1,1,...,1,0,1,1,0]]\n        revenue: [[5.89,6.13,2.61,12.3,11.57,...,23.63,0,2.4,24.54,0]]\n\n        ```\n\n        With covariates:\n\n        ```pycon\n        &gt;&gt;&gt; data = tt.make_sessions_data(seed=42, covariates=True)\n        &gt;&gt;&gt; data\n        pyarrow.Table\n        user: int64\n        variant: int64\n        sessions: int64\n        orders: int64\n        revenue: double\n        sessions_covariate: double\n        orders_covariate: double\n        revenue_covariate: double\n        ----\n        user: [[0,0,1,1,2,...,3999,3999,3999,3999,3999]]\n        variant: [[1,1,0,0,1,...,0,0,0,0,0]]\n        sessions: [[1,1,1,1,1,...,1,1,1,1,1]]\n        orders: [[1,1,1,1,1,...,1,0,1,1,0]]\n        revenue: [[5.89,6.13,2.61,12.3,11.57,...,23.63,0,2.4,24.54,0]]\n        sessions_covariate: [[1.5,1.5,0,0,1.5,...,0.2,0.2,0.2,0.2,0.2]]\n        orders_covariate: [[0.5,0.5,0,0,1.5,...,0,0,0,0,0]]\n        revenue_covariate: [[1.24,1.24,0,0,12.32,...,0,0,0,0,0]]\n\n        ```\n\n        As Pandas DataFrame:\n\n        ```pycon\n        &gt;&gt;&gt; data = tt.make_sessions_data(seed=42, return_type=\"pandas\")\n        &gt;&gt;&gt; data\n              user  variant  sessions  orders  revenue\n        0        0        1         1       1     5.89\n        1        0        1         1       1     6.13\n        2        1        0         1       1     2.61\n        3        1        0         1       1    12.30\n        4        2        1         1       1    11.57\n        ...    ...      ...       ...     ...      ...\n        7953  3999        0         1       1    23.63\n        7954  3999        0         1       0     0.00\n        7955  3999        0         1       1     2.40\n        7956  3999        0         1       1    24.54\n        7957  3999        0         1       0     0.00\n        &lt;BLANKLINE&gt;\n        [7958 rows x 5 columns]\n\n        ```\n\n        As Polars DataFrame:\n\n        ```pycon\n        &gt;&gt;&gt; data = tt.make_sessions_data(seed=42, return_type=\"polars\")\n        &gt;&gt;&gt; data\n        shape: (7_958, 5)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 user \u2506 variant \u2506 sessions \u2506 orders \u2506 revenue \u2502\n        \u2502 ---  \u2506 ---     \u2506 ---      \u2506 ---    \u2506 ---     \u2502\n        \u2502 i64  \u2506 i64     \u2506 i64      \u2506 i64    \u2506 f64     \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 0    \u2506 1       \u2506 1        \u2506 1      \u2506 5.89    \u2502\n        \u2502 0    \u2506 1       \u2506 1        \u2506 1      \u2506 6.13    \u2502\n        \u2502 1    \u2506 0       \u2506 1        \u2506 1      \u2506 2.61    \u2502\n        \u2502 1    \u2506 0       \u2506 1        \u2506 1      \u2506 12.3    \u2502\n        \u2502 2    \u2506 1       \u2506 1        \u2506 1      \u2506 11.57   \u2502\n        \u2502 \u2026    \u2506 \u2026       \u2506 \u2026        \u2506 \u2026      \u2506 \u2026       \u2502\n        \u2502 3999 \u2506 0       \u2506 1        \u2506 1      \u2506 23.63   \u2502\n        \u2502 3999 \u2506 0       \u2506 1        \u2506 0      \u2506 0.0     \u2502\n        \u2502 3999 \u2506 0       \u2506 1        \u2506 1      \u2506 2.4     \u2502\n        \u2502 3999 \u2506 0       \u2506 1        \u2506 1      \u2506 24.54   \u2502\n        \u2502 3999 \u2506 0       \u2506 1        \u2506 0      \u2506 0.0     \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n        ```\n    \"\"\"\n    return _make_data(\n        covariates=covariates,\n        seed=seed,\n        n_users=n_users,\n        ratio=ratio,\n        sessions_uplift=sessions_uplift,\n        orders_uplift=orders_uplift,\n        revenue_uplift=revenue_uplift,\n        avg_sessions=avg_sessions,\n        avg_orders_per_session=avg_orders_per_session,\n        avg_revenue_per_order=avg_revenue_per_order,\n        return_type=return_type,\n        explode_sessions=True,\n    )\n</code></pre>"},{"location":"api/experiment/","title":"Experiment","text":""},{"location":"api/experiment/#tea_tasting.experiment","title":"<code>tea_tasting.experiment</code>","text":"<p>Experiment and experiment result.</p>"},{"location":"api/experiment/#tea_tasting.experiment.Experiment","title":"<code>Experiment(metrics=None, variant='variant', **kw_metrics)</code>","text":"<p>               Bases: <code>ReprMixin</code></p> <p>Experiment definition: metrics and variant column.</p> <p>Parameters:</p> Name Type Description Default <code>metrics</code> <code>dict[str, MetricBase[Any]] | None</code> <p>Dictionary of metrics with metric names as keys.</p> <code>None</code> <code>variant</code> <code>str</code> <p>Variant column name.</p> <code>'variant'</code> <code>kw_metrics</code> <code>MetricBase[Any]</code> <p>Metrics with metric names as parameter names.</p> <code>{}</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; experiment = tt.Experiment(\n...     sessions_per_user=tt.Mean(\"sessions\"),\n...     orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\"),\n...     orders_per_user=tt.Mean(\"orders\"),\n...     revenue_per_user=tt.Mean(\"revenue\"),\n... )\n&gt;&gt;&gt; data = tt.make_users_data(seed=42)\n&gt;&gt;&gt; result = experiment.analyze(data)\n&gt;&gt;&gt; result\n            metric control treatment rel_effect_size rel_effect_size_ci pvalue\n sessions_per_user    2.00      1.98          -0.66%      [-3.7%, 2.5%]  0.674\norders_per_session   0.266     0.289            8.8%      [-0.89%, 19%] 0.0762\n   orders_per_user   0.530     0.573            8.0%       [-2.0%, 19%]  0.118\n  revenue_per_user    5.24      5.73            9.3%       [-2.4%, 22%]  0.123\n</code></pre> <p>Using the first argument <code>metrics</code> which accepts metrics in a form of dictionary:</p> <pre><code>&gt;&gt;&gt; experiment = tt.Experiment({\n...     \"sessions per user\": tt.Mean(\"sessions\"),\n...     \"orders per session\": tt.RatioOfMeans(\"orders\", \"sessions\"),\n...     \"orders per user\": tt.Mean(\"orders\"),\n...     \"revenue per user\": tt.Mean(\"revenue\"),\n... })\n&gt;&gt;&gt; data = tt.make_users_data(seed=42)\n&gt;&gt;&gt; result = experiment.analyze(data)\n&gt;&gt;&gt; result\n            metric control treatment rel_effect_size rel_effect_size_ci pvalue\n sessions per user    2.00      1.98          -0.66%      [-3.7%, 2.5%]  0.674\norders per session   0.266     0.289            8.8%      [-0.89%, 19%] 0.0762\n   orders per user   0.530     0.573            8.0%       [-2.0%, 19%]  0.118\n  revenue per user    5.24      5.73            9.3%       [-2.4%, 22%]  0.123\n</code></pre> <p>Power analysis:</p> <pre><code>&gt;&gt;&gt; data = tt.make_users_data(\n...     seed=42,\n...     sessions_uplift=0,\n...     orders_uplift=0,\n...     revenue_uplift=0,\n...     covariates=True,\n... )\n&gt;&gt;&gt; with tt.config_context(n_obs=(10_000, 20_000)):\n...     experiment = tt.Experiment(\n...         sessions_per_user=tt.Mean(\"sessions\", \"sessions_covariate\"),\n...         orders_per_session=tt.RatioOfMeans(\n...             numer=\"orders\",\n...             denom=\"sessions\",\n...             numer_covariate=\"orders_covariate\",\n...             denom_covariate=\"sessions_covariate\",\n...         ),\n...         orders_per_user=tt.Mean(\"orders\", \"orders_covariate\"),\n...         revenue_per_user=tt.Mean(\"revenue\", \"revenue_covariate\"),\n...     )\n&gt;&gt;&gt; power_result = experiment.solve_power(data)\n&gt;&gt;&gt; power_result\n            metric power effect_size rel_effect_size n_obs\n sessions_per_user   80%      0.0458            2.3% 10000\n sessions_per_user   80%      0.0324            1.6% 20000\norders_per_session   80%      0.0177            6.8% 10000\norders_per_session   80%      0.0125            4.8% 20000\n   orders_per_user   80%      0.0374            7.2% 10000\n   orders_per_user   80%      0.0264            5.1% 20000\n  revenue_per_user   80%       0.488            9.2% 10000\n  revenue_per_user   80%       0.345            6.5% 20000\n</code></pre> Source code in <code>src/tea_tasting/experiment.py</code> <pre><code>def __init__(\n    self,\n    metrics: dict[str, tea_tasting.metrics.MetricBase[Any]] | None = None,\n    variant: str = \"variant\",\n    **kw_metrics: tea_tasting.metrics.MetricBase[Any],\n) -&gt; None:\n    \"\"\"Experiment definition: metrics and variant column.\n\n    Args:\n        metrics: Dictionary of metrics with metric names as keys.\n        variant: Variant column name.\n        kw_metrics: Metrics with metric names as parameter names.\n\n    Examples:\n        ```pycon\n        &gt;&gt;&gt; import tea_tasting as tt\n\n        &gt;&gt;&gt; experiment = tt.Experiment(\n        ...     sessions_per_user=tt.Mean(\"sessions\"),\n        ...     orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\"),\n        ...     orders_per_user=tt.Mean(\"orders\"),\n        ...     revenue_per_user=tt.Mean(\"revenue\"),\n        ... )\n        &gt;&gt;&gt; data = tt.make_users_data(seed=42)\n        &gt;&gt;&gt; result = experiment.analyze(data)\n        &gt;&gt;&gt; result\n                    metric control treatment rel_effect_size rel_effect_size_ci pvalue\n         sessions_per_user    2.00      1.98          -0.66%      [-3.7%, 2.5%]  0.674\n        orders_per_session   0.266     0.289            8.8%      [-0.89%, 19%] 0.0762\n           orders_per_user   0.530     0.573            8.0%       [-2.0%, 19%]  0.118\n          revenue_per_user    5.24      5.73            9.3%       [-2.4%, 22%]  0.123\n\n        ```\n\n        Using the first argument `metrics` which accepts metrics in a form of dictionary:\n\n        ```pycon\n        &gt;&gt;&gt; experiment = tt.Experiment({\n        ...     \"sessions per user\": tt.Mean(\"sessions\"),\n        ...     \"orders per session\": tt.RatioOfMeans(\"orders\", \"sessions\"),\n        ...     \"orders per user\": tt.Mean(\"orders\"),\n        ...     \"revenue per user\": tt.Mean(\"revenue\"),\n        ... })\n        &gt;&gt;&gt; data = tt.make_users_data(seed=42)\n        &gt;&gt;&gt; result = experiment.analyze(data)\n        &gt;&gt;&gt; result\n                    metric control treatment rel_effect_size rel_effect_size_ci pvalue\n         sessions per user    2.00      1.98          -0.66%      [-3.7%, 2.5%]  0.674\n        orders per session   0.266     0.289            8.8%      [-0.89%, 19%] 0.0762\n           orders per user   0.530     0.573            8.0%       [-2.0%, 19%]  0.118\n          revenue per user    5.24      5.73            9.3%       [-2.4%, 22%]  0.123\n\n        ```\n\n        Power analysis:\n\n        ```pycon\n        &gt;&gt;&gt; data = tt.make_users_data(\n        ...     seed=42,\n        ...     sessions_uplift=0,\n        ...     orders_uplift=0,\n        ...     revenue_uplift=0,\n        ...     covariates=True,\n        ... )\n        &gt;&gt;&gt; with tt.config_context(n_obs=(10_000, 20_000)):\n        ...     experiment = tt.Experiment(\n        ...         sessions_per_user=tt.Mean(\"sessions\", \"sessions_covariate\"),\n        ...         orders_per_session=tt.RatioOfMeans(\n        ...             numer=\"orders\",\n        ...             denom=\"sessions\",\n        ...             numer_covariate=\"orders_covariate\",\n        ...             denom_covariate=\"sessions_covariate\",\n        ...         ),\n        ...         orders_per_user=tt.Mean(\"orders\", \"orders_covariate\"),\n        ...         revenue_per_user=tt.Mean(\"revenue\", \"revenue_covariate\"),\n        ...     )\n        &gt;&gt;&gt; power_result = experiment.solve_power(data)\n        &gt;&gt;&gt; power_result\n                    metric power effect_size rel_effect_size n_obs\n         sessions_per_user   80%      0.0458            2.3% 10000\n         sessions_per_user   80%      0.0324            1.6% 20000\n        orders_per_session   80%      0.0177            6.8% 10000\n        orders_per_session   80%      0.0125            4.8% 20000\n           orders_per_user   80%      0.0374            7.2% 10000\n           orders_per_user   80%      0.0264            5.1% 20000\n          revenue_per_user   80%       0.488            9.2% 10000\n          revenue_per_user   80%       0.345            6.5% 20000\n\n        ```\n    \"\"\"  # noqa: E501\n    if metrics is None:\n        metrics = {}\n    metrics = metrics | kw_metrics\n\n    tea_tasting.utils.check_scalar(metrics, \"metrics\", typ=dict)\n    tea_tasting.utils.check_scalar(len(metrics), \"len(metrics)\", gt=0)\n    for name, metric in metrics.items():\n        tea_tasting.utils.check_scalar(name, \"metric_name\", typ=str)\n        tea_tasting.utils.check_scalar(\n            metric, name, typ=tea_tasting.metrics.MetricBase)\n\n    self.metrics = metrics\n    self.variant = tea_tasting.utils.check_scalar(\n        variant, \"variant\", typ=str)\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.Experiment.analyze","title":"<code>analyze(data, control=None, *, all_variants=False)</code>","text":"<p>Analyze the experiment.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IntoFrame | Table</code> <p>Experimental data.</p> required <code>control</code> <code>object</code> <p>Control variant. If <code>None</code>, the variant with the minimal ID is used as a control.</p> <code>None</code> <code>all_variants</code> <code>bool</code> <p>If <code>True</code>, analyze all pairs of variants. Otherwise, analyze only one pair of variants.</p> <code>False</code> <p>Returns:</p> Type Description <code>ExperimentResult | ExperimentResults</code> <p>Experiment result.</p> Source code in <code>src/tea_tasting/experiment.py</code> <pre><code>def analyze(\n    self,\n    data: narwhals.typing.IntoFrame | ibis.expr.types.Table,\n    control: object = None,\n    *,\n    all_variants: bool = False,\n) -&gt; ExperimentResult | ExperimentResults:\n    \"\"\"Analyze the experiment.\n\n    Args:\n        data: Experimental data.\n        control: Control variant. If `None`, the variant with the minimal ID\n            is used as a control.\n        all_variants: If `True`, analyze all pairs of variants. Otherwise,\n            analyze only one pair of variants.\n\n    Returns:\n        Experiment result.\n    \"\"\"\n    tea_tasting.utils.check_scalar(all_variants, \"all_variants\", typ=bool)\n    aggregated_data, granular_data = self._read_data(data)\n\n    if aggregated_data is not None:\n        variants = aggregated_data.keys()\n    elif granular_data is not None:\n        variants = granular_data.keys()\n    else:\n        variants = self._read_variants(data)\n    variants = sorted(variants)  # type: ignore\n\n    if control is not None:\n        variant_pairs = tuple(\n            (control, treatment)\n            for treatment in variants\n            if treatment != control\n        )\n    else:\n        variant_pairs = tuple(\n            (control, treatment)\n            for control in variants\n            for treatment in variants\n            if control &lt; treatment\n        )\n\n    if len(variant_pairs) != 1 and not all_variants:\n        raise ValueError(\n            \"all_variants is False, but there are more than one pair of variants.\")\n\n    results = ExperimentResults()\n    for contr, treat in variant_pairs:\n        result = ExperimentResult()\n        for name, metric in self.metrics.items():\n            result |= {name: self._analyze_metric(\n                metric=metric,\n                data=data,\n                aggregated_data=aggregated_data,\n                granular_data=granular_data,\n                control=contr,\n                treatment=treat,\n            )}\n\n        if not all_variants:\n            return result\n\n        results |= {(contr, treat): result}\n\n    return results\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.Experiment.simulate","title":"<code>simulate(data, n_simulations=10000, *, seed=None, ratio=1, treat=None, map_=map, progress=None)</code>","text":"<p>Simulate the experiment analysis multiple times.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IntoFrame | Table | DataGenerator</code> <p>Experimental data or a callable that generates the data.</p> required <code>n_simulations</code> <code>int</code> <p>Number of simulations.</p> <code>10000</code> <code>seed</code> <code>int | Generator | SeedSequence | None</code> <p>Random seed.</p> <code>None</code> <code>ratio</code> <code>float | int</code> <p>Ratio of the number of users in treatment relative to control.</p> <code>1</code> <code>treat</code> <code>Callable[[Table], Table] | None</code> <p>Treatment function that takes a PyArrow Table as an input and returns an updated PyArrow Table.</p> <code>None</code> <code>map_</code> <code>MapLike[Any]</code> <p>Map-like function to run simulations.</p> <code>map</code> <code>progress</code> <code>ProgressFn[Any] | type[Iterable[Any]] | None</code> <p>tqdm-like class or function to show the progress of simulations.</p> <code>None</code> <p>Returns:</p> Type Description <code>SimulationResults</code> <p>Simulation results.</p> Source code in <code>src/tea_tasting/experiment.py</code> <pre><code>def simulate(\n    self,\n    data: narwhals.typing.IntoFrame | ibis.expr.types.Table | DataGenerator,  # type: ignore\n    n_simulations: int = 10_000,\n    *,\n    seed: int | np.random.Generator | np.random.SeedSequence | None = None,\n    ratio: float | int = 1,\n    treat: Callable[[pa.Table], pa.Table] | None = None,\n    map_: MapLike[Any] = map,\n    progress: ProgressFn[Any] | type[Iterable[Any]] | None = None,\n) -&gt; SimulationResults:\n    \"\"\"Simulate the experiment analysis multiple times.\n\n    Args:\n        data: Experimental data or a callable that generates the data.\n        n_simulations: Number of simulations.\n        seed: Random seed.\n        ratio: Ratio of the number of users in treatment relative to control.\n        treat: Treatment function that takes a PyArrow Table as an input\n            and returns an updated PyArrow Table.\n        map_: Map-like function to run simulations.\n        progress: tqdm-like class or function to show the progress of simulations.\n\n    Returns:\n        Simulation results.\n    \"\"\"\n    tea_tasting.utils.check_scalar(n_simulations, \"n_simulations\", typ=int, gt=0)\n    tea_tasting.utils.auto_check(ratio, \"ratio\")\n\n    if not callable(data):\n        gran_cols: set[str] = set()\n        for metric in self.metrics.values():\n            if isinstance(metric, tea_tasting.metrics.MetricBaseAggregated):\n                aggr_cols = metric.aggr_cols\n                gran_cols |= (\n                    set(aggr_cols.mean_cols) |\n                    set(aggr_cols.var_cols) |\n                    set(itertools.chain.from_iterable(aggr_cols.cov_cols))\n                )\n            elif isinstance(metric, tea_tasting.metrics.MetricBaseGranular):\n                gran_cols |= set(metric.cols)\n            else:\n                gran_cols = set()\n                break\n        cols = tuple(gran_cols)\n        data: pa.Table = tea_tasting.metrics.read_granular(data, cols)\n        if self.variant in data.column_names:\n            data = data.drop_columns(self.variant)\n\n    sim = functools.partial(\n        _simulate_once,\n        experiment=self,\n        data=data,\n        ratio=ratio,\n        treat=treat,\n    )\n\n    results = map_(sim, np.random.default_rng(seed).spawn(n_simulations))\n    if progress is not None:\n        try:\n            results = progress(results, total=n_simulations)  # type: ignore\n        except TypeError:\n            results = progress(results)  # type: ignore\n    return SimulationResults(results)\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.Experiment.solve_power","title":"<code>solve_power(data, parameter='rel_effect_size')</code>","text":"<p>Solve for a parameter of the power of a test.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IntoFrame | Table</code> <p>Sample data.</p> required <code>parameter</code> <code>Literal['power', 'effect_size', 'rel_effect_size', 'n_obs']</code> <p>Parameter name.</p> <code>'rel_effect_size'</code> <p>Returns:</p> Type Description <code>ExperimentPowerResult</code> <p>Power analysis result.</p> Source code in <code>src/tea_tasting/experiment.py</code> <pre><code>def solve_power(\n    self,\n    data: narwhals.typing.IntoFrame | ibis.expr.types.Table,\n    parameter: Literal[\n        \"power\", \"effect_size\", \"rel_effect_size\", \"n_obs\"] = \"rel_effect_size\",\n) -&gt; ExperimentPowerResult:\n    \"\"\"Solve for a parameter of the power of a test.\n\n    Args:\n        data: Sample data.\n        parameter: Parameter name.\n\n    Returns:\n        Power analysis result.\n    \"\"\"\n    tea_tasting.utils.check_scalar(\n        parameter,\n        \"parameter\",\n        in_={\"power\", \"effect_size\", \"rel_effect_size\", \"n_obs\"},\n    )\n    aggr_cols = tea_tasting.metrics.AggrCols()\n    for metric in self.metrics.values():\n        if isinstance(metric, tea_tasting.metrics.PowerBaseAggregated):\n            aggr_cols |= metric.aggr_cols\n\n    aggr_data = tea_tasting.aggr.read_aggregates(\n        data,\n        group_col=None,\n        **aggr_cols._asdict(),\n    ) if len(aggr_cols) &gt; 0 else tea_tasting.aggr.Aggregates()\n\n    result = ExperimentPowerResult()\n    for name, metric in self.metrics.items():\n        if isinstance(metric, tea_tasting.metrics.PowerBaseAggregated):\n            result |= {name: metric.solve_power(aggr_data, parameter=parameter)}\n        elif isinstance(metric, tea_tasting.metrics.PowerBase):\n            result |= {name: metric.solve_power(data, parameter=parameter)}\n\n    return result\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentPowerResult","title":"<code>ExperimentPowerResult</code>","text":"<p>               Bases: <code>DictsReprMixin</code>, <code>UserDict[str, MetricPowerResults[Any]]</code></p> <p>Result of the analysis of power in a experiment.</p>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentPowerResult.to_arrow","title":"<code>to_arrow()</code>","text":"<p>Convert the object to a PyArrow Table.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_arrow(self) -&gt; pa.Table:\n    \"\"\"Convert the object to a PyArrow Table.\"\"\"\n    return pa.Table.from_pylist(self.to_dicts())\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentPowerResult.to_dicts","title":"<code>to_dicts()</code>","text":"<p>Convert the result to a sequence of dictionaries.</p> Source code in <code>src/tea_tasting/experiment.py</code> <pre><code>@tea_tasting.utils._cache_method\ndef to_dicts(self) -&gt; tuple[dict[str, object], ...]:\n    \"\"\"Convert the result to a sequence of dictionaries.\"\"\"\n    dicts = ()\n    for metric, results in self.items():\n        dicts = (*dicts, *({\"metric\": metric} | d for d in results.to_dicts()))\n    return dicts\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentPowerResult.to_html","title":"<code>to_html(keys=None, formatter=get_and_format_num, *, max_rows=None, indent=None)</code>","text":"<p>Convert the object to HTML.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <code>indent</code> <code>str | None</code> <p>Whitespace to insert for each indentation level. If <code>None</code>, do not indent.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>A table with results rendered as HTML.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_html(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n    indent: str | None = None,\n) -&gt; str:\n    \"\"\"Convert the object to HTML.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n        indent: Whitespace to insert for each indentation level. If `None`,\n            do not indent.\n\n    Returns:\n        A table with results rendered as HTML.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    table = ET.Element(\n        \"table\",\n        {\"class\": \"dataframe\", \"style\": \"text-align: right;\"},\n    )\n    thead = ET.SubElement(table, \"thead\")\n    thead_tr = ET.SubElement(thead, \"tr\")\n    for key in keys:\n        th = ET.SubElement(thead_tr, \"th\")\n        th.text = key\n    tbody = ET.SubElement(table, \"tbody\")\n    for pretty_dict in self.to_pretty_dicts(keys, formatter, max_rows=max_rows):\n        tr = ET.SubElement(tbody, \"tr\")\n        for key in keys:\n            td = ET.SubElement(tr, \"td\")\n            td.text = pretty_dict[key]\n    if indent is not None:\n        ET.indent(table, space=indent)\n    return ET.tostring(table, encoding=\"unicode\", method=\"html\")\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentPowerResult.to_pandas","title":"<code>to_pandas()</code>","text":"<p>Convert the object to a Pandas DataFrame.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_pandas(self) -&gt; pd.DataFrame:\n    \"\"\"Convert the object to a Pandas DataFrame.\"\"\"\n    import pandas as pd  # noqa: PLC0415\n    return pd.DataFrame.from_records(self.to_dicts())\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentPowerResult.to_polars","title":"<code>to_polars()</code>","text":"<p>Convert the object to a Polars DataFrame.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_polars(self) -&gt; pl.DataFrame:\n    \"\"\"Convert the object to a Polars DataFrame.\"\"\"\n    import polars as pl  # noqa: PLC0415\n    return pl.from_dicts(self.to_dicts())\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentPowerResult.to_pretty_dicts","title":"<code>to_pretty_dicts(keys=None, formatter=get_and_format_num, *, max_rows=None)</code>","text":"<p>Convert the object to a list of dictionaries with formatted values.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[dict[str, str]]</code> <p>List of dictionaries with formatted values.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_pretty_dicts(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n) -&gt; list[dict[str, str]]:\n    \"\"\"Convert the object to a list of dictionaries with formatted values.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n\n    Returns:\n        List of dictionaries with formatted values.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    dicts = self.to_dicts()\n    if max_rows &lt;= 0 or len(dicts) &lt;= max_rows:\n        return [{key: formatter(data, key) for key in keys} for data in dicts]\n\n    bottom = max_rows // 2\n    top = max_rows - bottom\n    return (\n        [{key: formatter(data, key) for key in keys} for data in dicts[:top]] +\n        [dict.fromkeys(keys, \"\u2026\")] +\n        [{key: formatter(data, key) for key in keys} for data in dicts[-bottom:]]\n    )\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentPowerResult.to_string","title":"<code>to_string(keys=None, formatter=get_and_format_num, *, max_rows=None)</code>","text":"<p>Convert the object to a string.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>A table with results rendered as string.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_string(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n) -&gt; str:\n    \"\"\"Convert the object to a string.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n\n    Returns:\n        A table with results rendered as string.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    pretty_dicts = self.to_pretty_dicts(keys, formatter, max_rows=max_rows)\n    widths = {key: len(key) for key in keys}\n    for pretty_dict in pretty_dicts:\n        for key in keys:\n            widths[key] = max(widths[key], len(pretty_dict[key]))\n\n    sep = \" \"\n    rows = [sep.join(key.rjust(widths[key]) for key in keys)]\n    rows.extend(\n        sep.join(pretty_dict[key].rjust(widths[key]) for key in keys)\n        for pretty_dict in pretty_dicts\n    )\n    return \"\\n\".join(rows)\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentPowerResult.with_defaults","title":"<code>with_defaults(*, keys=None, max_rows=None)</code>","text":"<p>Copies the object and sets the new default parameters.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>New default <code>keys</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> <code>None</code> <code>max_rows</code> <code>int | None</code> <p>New default <code>max_rows</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default keys.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_defaults(\n    self: DictsReprMixinT,\n    *,\n    keys: Sequence[str] | None = None,\n    max_rows: int | None = None,\n) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default parameters.\n\n    Args:\n        keys: New default `keys` for the methods `to_pretty_dicts`, `to_string`,\n            and `to_html`.\n        max_rows: New default `max_rows` for the methods `to_pretty_dicts`,\n            `to_string`, and `to_html`.\n\n    Returns:\n        A copy of the object with the new default keys.\n    \"\"\"\n    new_instance = self.__class__.__new__(self.__class__)\n    new_instance.__dict__.update(self.__dict__)\n    new_instance._cache = None\n    if keys is not None:\n        new_instance.default_keys = keys\n    if max_rows is not None:\n        new_instance.default_max_rows = max_rows\n    return new_instance\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentPowerResult.with_keys","title":"<code>with_keys(keys)</code>","text":"<p>Copies the object and sets the new default <code>keys</code>.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str]</code> <p>New default <code>keys</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> required <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default <code>keys</code>.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_keys(self: DictsReprMixinT, keys: Sequence[str]) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default `keys`.\n\n    Args:\n        keys: New default `keys` for the methods `to_pretty_dicts`, `to_string`,\n            and `to_html`.\n\n    Returns:\n        A copy of the object with the new default `keys`.\n    \"\"\"\n    return self.with_defaults(keys=keys)\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentPowerResult.with_max_rows","title":"<code>with_max_rows(max_rows)</code>","text":"<p>Copies the object and sets the new default <code>max_rows</code>.</p> <p>Parameters:</p> Name Type Description Default <code>max_rows</code> <code>int</code> <p>New default <code>max_rows</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> required <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default <code>max_rows</code>.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_max_rows(self: DictsReprMixinT, max_rows: int) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default `max_rows`.\n\n    Args:\n        max_rows: New default `max_rows` for the methods `to_pretty_dicts`,\n            `to_string`, and `to_html`.\n\n    Returns:\n        A copy of the object with the new default `max_rows`.\n    \"\"\"\n    return self.with_defaults(max_rows=max_rows)\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResult","title":"<code>ExperimentResult</code>","text":"<p>               Bases: <code>DictsReprMixin</code>, <code>UserDict[str, MetricResult]</code></p> <p>Experiment result for a pair of variants.</p>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResult.to_arrow","title":"<code>to_arrow()</code>","text":"<p>Convert the object to a PyArrow Table.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_arrow(self) -&gt; pa.Table:\n    \"\"\"Convert the object to a PyArrow Table.\"\"\"\n    return pa.Table.from_pylist(self.to_dicts())\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResult.to_dicts","title":"<code>to_dicts()</code>","text":"<p>Convert the result to a sequence of dictionaries.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pprint\n&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; experiment = tt.Experiment(\n...     orders_per_user=tt.Mean(\"orders\"),\n...     revenue_per_user=tt.Mean(\"revenue\"),\n... )\n&gt;&gt;&gt; data = tt.make_users_data(seed=42)\n&gt;&gt;&gt; result = experiment.analyze(data)\n&gt;&gt;&gt; pprint.pprint(result.to_dicts())\n({'control': 0.5304003954522986,\n  'effect_size': 0.04269014577177832,\n  'effect_size_ci_lower': -0.010800201598205515,\n  'effect_size_ci_upper': 0.09618049314176216,\n  'metric': 'orders_per_user',\n  'pvalue': np.float64(0.11773177998716214),\n  'rel_effect_size': 0.08048664016431273,\n  'rel_effect_size_ci_lower': -0.019515294044061937,\n  'rel_effect_size_ci_upper': 0.1906880061278886,\n  'statistic': 1.5647028839586707,\n  'treatment': 0.5730905412240769},\n {'control': 5.241028175976273,\n  'effect_size': 0.4890831037404775,\n  'effect_size_ci_lower': -0.13261881482742033,\n  'effect_size_ci_upper': 1.1107850223083753,\n  'metric': 'revenue_per_user',\n  'pvalue': np.float64(0.1230698855425058),\n  'rel_effect_size': 0.09331815958981626,\n  'rel_effect_size_ci_lower': -0.02373770894855798,\n  'rel_effect_size_ci_upper': 0.22440926894909308,\n  'statistic': 1.5423440700784083,\n  'treatment': 5.73011127971675})\n</code></pre> Source code in <code>src/tea_tasting/experiment.py</code> <pre><code>@tea_tasting.utils._cache_method\ndef to_dicts(self) -&gt; tuple[dict[str, object], ...]:\n    \"\"\"Convert the result to a sequence of dictionaries.\n\n    Examples:\n        ```pycon\n        &gt;&gt;&gt; import pprint\n        &gt;&gt;&gt; import tea_tasting as tt\n\n        &gt;&gt;&gt; experiment = tt.Experiment(\n        ...     orders_per_user=tt.Mean(\"orders\"),\n        ...     revenue_per_user=tt.Mean(\"revenue\"),\n        ... )\n        &gt;&gt;&gt; data = tt.make_users_data(seed=42)\n        &gt;&gt;&gt; result = experiment.analyze(data)\n        &gt;&gt;&gt; pprint.pprint(result.to_dicts())\n        ({'control': 0.5304003954522986,\n          'effect_size': 0.04269014577177832,\n          'effect_size_ci_lower': -0.010800201598205515,\n          'effect_size_ci_upper': 0.09618049314176216,\n          'metric': 'orders_per_user',\n          'pvalue': np.float64(0.11773177998716214),\n          'rel_effect_size': 0.08048664016431273,\n          'rel_effect_size_ci_lower': -0.019515294044061937,\n          'rel_effect_size_ci_upper': 0.1906880061278886,\n          'statistic': 1.5647028839586707,\n          'treatment': 0.5730905412240769},\n         {'control': 5.241028175976273,\n          'effect_size': 0.4890831037404775,\n          'effect_size_ci_lower': -0.13261881482742033,\n          'effect_size_ci_upper': 1.1107850223083753,\n          'metric': 'revenue_per_user',\n          'pvalue': np.float64(0.1230698855425058),\n          'rel_effect_size': 0.09331815958981626,\n          'rel_effect_size_ci_lower': -0.02373770894855798,\n          'rel_effect_size_ci_upper': 0.22440926894909308,\n          'statistic': 1.5423440700784083,\n          'treatment': 5.73011127971675})\n\n        ```\n    \"\"\"\n    return tuple(\n        {\"metric\": k} | (v if isinstance(v, dict) else v._asdict())\n        for k, v in self.items()\n    )  # type: ignore\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResult.to_html","title":"<code>to_html(keys=None, formatter=get_and_format_num, *, max_rows=None, indent=None)</code>","text":"<p>Convert the object to HTML.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <code>indent</code> <code>str | None</code> <p>Whitespace to insert for each indentation level. If <code>None</code>, do not indent.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>A table with results rendered as HTML.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_html(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n    indent: str | None = None,\n) -&gt; str:\n    \"\"\"Convert the object to HTML.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n        indent: Whitespace to insert for each indentation level. If `None`,\n            do not indent.\n\n    Returns:\n        A table with results rendered as HTML.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    table = ET.Element(\n        \"table\",\n        {\"class\": \"dataframe\", \"style\": \"text-align: right;\"},\n    )\n    thead = ET.SubElement(table, \"thead\")\n    thead_tr = ET.SubElement(thead, \"tr\")\n    for key in keys:\n        th = ET.SubElement(thead_tr, \"th\")\n        th.text = key\n    tbody = ET.SubElement(table, \"tbody\")\n    for pretty_dict in self.to_pretty_dicts(keys, formatter, max_rows=max_rows):\n        tr = ET.SubElement(tbody, \"tr\")\n        for key in keys:\n            td = ET.SubElement(tr, \"td\")\n            td.text = pretty_dict[key]\n    if indent is not None:\n        ET.indent(table, space=indent)\n    return ET.tostring(table, encoding=\"unicode\", method=\"html\")\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResult.to_pandas","title":"<code>to_pandas()</code>","text":"<p>Convert the object to a Pandas DataFrame.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_pandas(self) -&gt; pd.DataFrame:\n    \"\"\"Convert the object to a Pandas DataFrame.\"\"\"\n    import pandas as pd  # noqa: PLC0415\n    return pd.DataFrame.from_records(self.to_dicts())\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResult.to_polars","title":"<code>to_polars()</code>","text":"<p>Convert the object to a Polars DataFrame.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_polars(self) -&gt; pl.DataFrame:\n    \"\"\"Convert the object to a Polars DataFrame.\"\"\"\n    import polars as pl  # noqa: PLC0415\n    return pl.from_dicts(self.to_dicts())\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResult.to_pretty_dicts","title":"<code>to_pretty_dicts(keys=None, formatter=get_and_format_num, *, max_rows=None)</code>","text":"<p>Convert the object to a list of dictionaries with formatted values.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[dict[str, str]]</code> <p>List of dictionaries with formatted values.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_pretty_dicts(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n) -&gt; list[dict[str, str]]:\n    \"\"\"Convert the object to a list of dictionaries with formatted values.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n\n    Returns:\n        List of dictionaries with formatted values.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    dicts = self.to_dicts()\n    if max_rows &lt;= 0 or len(dicts) &lt;= max_rows:\n        return [{key: formatter(data, key) for key in keys} for data in dicts]\n\n    bottom = max_rows // 2\n    top = max_rows - bottom\n    return (\n        [{key: formatter(data, key) for key in keys} for data in dicts[:top]] +\n        [dict.fromkeys(keys, \"\u2026\")] +\n        [{key: formatter(data, key) for key in keys} for data in dicts[-bottom:]]\n    )\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResult.to_string","title":"<code>to_string(keys=None, formatter=get_and_format_num, *, max_rows=None)</code>","text":"<p>Convert the object to a string.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>A table with results rendered as string.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_string(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n) -&gt; str:\n    \"\"\"Convert the object to a string.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n\n    Returns:\n        A table with results rendered as string.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    pretty_dicts = self.to_pretty_dicts(keys, formatter, max_rows=max_rows)\n    widths = {key: len(key) for key in keys}\n    for pretty_dict in pretty_dicts:\n        for key in keys:\n            widths[key] = max(widths[key], len(pretty_dict[key]))\n\n    sep = \" \"\n    rows = [sep.join(key.rjust(widths[key]) for key in keys)]\n    rows.extend(\n        sep.join(pretty_dict[key].rjust(widths[key]) for key in keys)\n        for pretty_dict in pretty_dicts\n    )\n    return \"\\n\".join(rows)\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResult.with_defaults","title":"<code>with_defaults(*, keys=None, max_rows=None)</code>","text":"<p>Copies the object and sets the new default parameters.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>New default <code>keys</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> <code>None</code> <code>max_rows</code> <code>int | None</code> <p>New default <code>max_rows</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default keys.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_defaults(\n    self: DictsReprMixinT,\n    *,\n    keys: Sequence[str] | None = None,\n    max_rows: int | None = None,\n) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default parameters.\n\n    Args:\n        keys: New default `keys` for the methods `to_pretty_dicts`, `to_string`,\n            and `to_html`.\n        max_rows: New default `max_rows` for the methods `to_pretty_dicts`,\n            `to_string`, and `to_html`.\n\n    Returns:\n        A copy of the object with the new default keys.\n    \"\"\"\n    new_instance = self.__class__.__new__(self.__class__)\n    new_instance.__dict__.update(self.__dict__)\n    new_instance._cache = None\n    if keys is not None:\n        new_instance.default_keys = keys\n    if max_rows is not None:\n        new_instance.default_max_rows = max_rows\n    return new_instance\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResult.with_keys","title":"<code>with_keys(keys)</code>","text":"<p>Copies the object and sets the new default <code>keys</code>.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str]</code> <p>New default <code>keys</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> required <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default <code>keys</code>.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_keys(self: DictsReprMixinT, keys: Sequence[str]) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default `keys`.\n\n    Args:\n        keys: New default `keys` for the methods `to_pretty_dicts`, `to_string`,\n            and `to_html`.\n\n    Returns:\n        A copy of the object with the new default `keys`.\n    \"\"\"\n    return self.with_defaults(keys=keys)\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResult.with_max_rows","title":"<code>with_max_rows(max_rows)</code>","text":"<p>Copies the object and sets the new default <code>max_rows</code>.</p> <p>Parameters:</p> Name Type Description Default <code>max_rows</code> <code>int</code> <p>New default <code>max_rows</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> required <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default <code>max_rows</code>.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_max_rows(self: DictsReprMixinT, max_rows: int) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default `max_rows`.\n\n    Args:\n        max_rows: New default `max_rows` for the methods `to_pretty_dicts`,\n            `to_string`, and `to_html`.\n\n    Returns:\n        A copy of the object with the new default `max_rows`.\n    \"\"\"\n    return self.with_defaults(max_rows=max_rows)\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResults","title":"<code>ExperimentResults</code>","text":"<p>               Bases: <code>DictsReprMixin</code>, <code>UserDict[tuple[object, object], ExperimentResult]</code></p> <p>Experiment results for multiple pairs of variants.</p>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResults.to_arrow","title":"<code>to_arrow()</code>","text":"<p>Convert the object to a PyArrow Table.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_arrow(self) -&gt; pa.Table:\n    \"\"\"Convert the object to a PyArrow Table.\"\"\"\n    return pa.Table.from_pylist(self.to_dicts())\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResults.to_dicts","title":"<code>to_dicts()</code>","text":"<p>Convert the results to a sequence of dictionaries.</p> Source code in <code>src/tea_tasting/experiment.py</code> <pre><code>@tea_tasting.utils._cache_method\ndef to_dicts(self) -&gt; tuple[dict[str, object], ...]:\n    \"\"\"Convert the results to a sequence of dictionaries.\"\"\"\n    return tuple(\n        {\"variants\": str(variants)} | metric_result\n        for variants, experiment_result in self.items()\n        for metric_result in experiment_result.to_dicts()\n    )\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResults.to_html","title":"<code>to_html(keys=None, formatter=get_and_format_num, *, max_rows=None, indent=None)</code>","text":"<p>Convert the object to HTML.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <code>indent</code> <code>str | None</code> <p>Whitespace to insert for each indentation level. If <code>None</code>, do not indent.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>A table with results rendered as HTML.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_html(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n    indent: str | None = None,\n) -&gt; str:\n    \"\"\"Convert the object to HTML.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n        indent: Whitespace to insert for each indentation level. If `None`,\n            do not indent.\n\n    Returns:\n        A table with results rendered as HTML.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    table = ET.Element(\n        \"table\",\n        {\"class\": \"dataframe\", \"style\": \"text-align: right;\"},\n    )\n    thead = ET.SubElement(table, \"thead\")\n    thead_tr = ET.SubElement(thead, \"tr\")\n    for key in keys:\n        th = ET.SubElement(thead_tr, \"th\")\n        th.text = key\n    tbody = ET.SubElement(table, \"tbody\")\n    for pretty_dict in self.to_pretty_dicts(keys, formatter, max_rows=max_rows):\n        tr = ET.SubElement(tbody, \"tr\")\n        for key in keys:\n            td = ET.SubElement(tr, \"td\")\n            td.text = pretty_dict[key]\n    if indent is not None:\n        ET.indent(table, space=indent)\n    return ET.tostring(table, encoding=\"unicode\", method=\"html\")\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResults.to_pandas","title":"<code>to_pandas()</code>","text":"<p>Convert the object to a Pandas DataFrame.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_pandas(self) -&gt; pd.DataFrame:\n    \"\"\"Convert the object to a Pandas DataFrame.\"\"\"\n    import pandas as pd  # noqa: PLC0415\n    return pd.DataFrame.from_records(self.to_dicts())\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResults.to_polars","title":"<code>to_polars()</code>","text":"<p>Convert the object to a Polars DataFrame.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_polars(self) -&gt; pl.DataFrame:\n    \"\"\"Convert the object to a Polars DataFrame.\"\"\"\n    import polars as pl  # noqa: PLC0415\n    return pl.from_dicts(self.to_dicts())\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResults.to_pretty_dicts","title":"<code>to_pretty_dicts(keys=None, formatter=get_and_format_num, *, max_rows=None)</code>","text":"<p>Convert the object to a list of dictionaries with formatted values.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[dict[str, str]]</code> <p>List of dictionaries with formatted values.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_pretty_dicts(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n) -&gt; list[dict[str, str]]:\n    \"\"\"Convert the object to a list of dictionaries with formatted values.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n\n    Returns:\n        List of dictionaries with formatted values.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    dicts = self.to_dicts()\n    if max_rows &lt;= 0 or len(dicts) &lt;= max_rows:\n        return [{key: formatter(data, key) for key in keys} for data in dicts]\n\n    bottom = max_rows // 2\n    top = max_rows - bottom\n    return (\n        [{key: formatter(data, key) for key in keys} for data in dicts[:top]] +\n        [dict.fromkeys(keys, \"\u2026\")] +\n        [{key: formatter(data, key) for key in keys} for data in dicts[-bottom:]]\n    )\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResults.to_string","title":"<code>to_string(keys=None, formatter=get_and_format_num, *, max_rows=None)</code>","text":"<p>Convert the object to a string.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>A table with results rendered as string.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_string(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n) -&gt; str:\n    \"\"\"Convert the object to a string.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n\n    Returns:\n        A table with results rendered as string.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    pretty_dicts = self.to_pretty_dicts(keys, formatter, max_rows=max_rows)\n    widths = {key: len(key) for key in keys}\n    for pretty_dict in pretty_dicts:\n        for key in keys:\n            widths[key] = max(widths[key], len(pretty_dict[key]))\n\n    sep = \" \"\n    rows = [sep.join(key.rjust(widths[key]) for key in keys)]\n    rows.extend(\n        sep.join(pretty_dict[key].rjust(widths[key]) for key in keys)\n        for pretty_dict in pretty_dicts\n    )\n    return \"\\n\".join(rows)\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResults.with_defaults","title":"<code>with_defaults(*, keys=None, max_rows=None)</code>","text":"<p>Copies the object and sets the new default parameters.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>New default <code>keys</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> <code>None</code> <code>max_rows</code> <code>int | None</code> <p>New default <code>max_rows</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default keys.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_defaults(\n    self: DictsReprMixinT,\n    *,\n    keys: Sequence[str] | None = None,\n    max_rows: int | None = None,\n) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default parameters.\n\n    Args:\n        keys: New default `keys` for the methods `to_pretty_dicts`, `to_string`,\n            and `to_html`.\n        max_rows: New default `max_rows` for the methods `to_pretty_dicts`,\n            `to_string`, and `to_html`.\n\n    Returns:\n        A copy of the object with the new default keys.\n    \"\"\"\n    new_instance = self.__class__.__new__(self.__class__)\n    new_instance.__dict__.update(self.__dict__)\n    new_instance._cache = None\n    if keys is not None:\n        new_instance.default_keys = keys\n    if max_rows is not None:\n        new_instance.default_max_rows = max_rows\n    return new_instance\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResults.with_keys","title":"<code>with_keys(keys)</code>","text":"<p>Copies the object and sets the new default <code>keys</code>.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str]</code> <p>New default <code>keys</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> required <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default <code>keys</code>.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_keys(self: DictsReprMixinT, keys: Sequence[str]) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default `keys`.\n\n    Args:\n        keys: New default `keys` for the methods `to_pretty_dicts`, `to_string`,\n            and `to_html`.\n\n    Returns:\n        A copy of the object with the new default `keys`.\n    \"\"\"\n    return self.with_defaults(keys=keys)\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.ExperimentResults.with_max_rows","title":"<code>with_max_rows(max_rows)</code>","text":"<p>Copies the object and sets the new default <code>max_rows</code>.</p> <p>Parameters:</p> Name Type Description Default <code>max_rows</code> <code>int</code> <p>New default <code>max_rows</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> required <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default <code>max_rows</code>.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_max_rows(self: DictsReprMixinT, max_rows: int) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default `max_rows`.\n\n    Args:\n        max_rows: New default `max_rows` for the methods `to_pretty_dicts`,\n            `to_string`, and `to_html`.\n\n    Returns:\n        A copy of the object with the new default `max_rows`.\n    \"\"\"\n    return self.with_defaults(max_rows=max_rows)\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.SimulationResults","title":"<code>SimulationResults</code>","text":"<p>               Bases: <code>DictsReprMixin</code>, <code>UserList[ExperimentResult]</code></p> <p>Simulation results.</p> <p>Simulations are not enumerated for better performance.</p>"},{"location":"api/experiment/#tea_tasting.experiment.SimulationResults.to_arrow","title":"<code>to_arrow()</code>","text":"<p>Convert the object to a PyArrow Table.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_arrow(self) -&gt; pa.Table:\n    \"\"\"Convert the object to a PyArrow Table.\"\"\"\n    return pa.Table.from_pylist(self.to_dicts())\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.SimulationResults.to_dicts","title":"<code>to_dicts()</code>","text":"<p>Convert the results to a sequence of dictionaries.</p> Source code in <code>src/tea_tasting/experiment.py</code> <pre><code>@tea_tasting.utils._cache_method\ndef to_dicts(self) -&gt; tuple[dict[str, object], ...]:\n    \"\"\"Convert the results to a sequence of dictionaries.\"\"\"\n    return tuple(itertools.chain.from_iterable(\n        experiment_result.to_dicts()\n        for experiment_result in self\n    ))\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.SimulationResults.to_html","title":"<code>to_html(keys=None, formatter=get_and_format_num, *, max_rows=None, indent=None)</code>","text":"<p>Convert the object to HTML.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <code>indent</code> <code>str | None</code> <p>Whitespace to insert for each indentation level. If <code>None</code>, do not indent.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>A table with results rendered as HTML.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_html(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n    indent: str | None = None,\n) -&gt; str:\n    \"\"\"Convert the object to HTML.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n        indent: Whitespace to insert for each indentation level. If `None`,\n            do not indent.\n\n    Returns:\n        A table with results rendered as HTML.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    table = ET.Element(\n        \"table\",\n        {\"class\": \"dataframe\", \"style\": \"text-align: right;\"},\n    )\n    thead = ET.SubElement(table, \"thead\")\n    thead_tr = ET.SubElement(thead, \"tr\")\n    for key in keys:\n        th = ET.SubElement(thead_tr, \"th\")\n        th.text = key\n    tbody = ET.SubElement(table, \"tbody\")\n    for pretty_dict in self.to_pretty_dicts(keys, formatter, max_rows=max_rows):\n        tr = ET.SubElement(tbody, \"tr\")\n        for key in keys:\n            td = ET.SubElement(tr, \"td\")\n            td.text = pretty_dict[key]\n    if indent is not None:\n        ET.indent(table, space=indent)\n    return ET.tostring(table, encoding=\"unicode\", method=\"html\")\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.SimulationResults.to_pandas","title":"<code>to_pandas()</code>","text":"<p>Convert the object to a Pandas DataFrame.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_pandas(self) -&gt; pd.DataFrame:\n    \"\"\"Convert the object to a Pandas DataFrame.\"\"\"\n    import pandas as pd  # noqa: PLC0415\n    return pd.DataFrame.from_records(self.to_dicts())\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.SimulationResults.to_polars","title":"<code>to_polars()</code>","text":"<p>Convert the object to a Polars DataFrame.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_polars(self) -&gt; pl.DataFrame:\n    \"\"\"Convert the object to a Polars DataFrame.\"\"\"\n    import polars as pl  # noqa: PLC0415\n    return pl.from_dicts(self.to_dicts())\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.SimulationResults.to_pretty_dicts","title":"<code>to_pretty_dicts(keys=None, formatter=get_and_format_num, *, max_rows=None)</code>","text":"<p>Convert the object to a list of dictionaries with formatted values.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[dict[str, str]]</code> <p>List of dictionaries with formatted values.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_pretty_dicts(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n) -&gt; list[dict[str, str]]:\n    \"\"\"Convert the object to a list of dictionaries with formatted values.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n\n    Returns:\n        List of dictionaries with formatted values.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    dicts = self.to_dicts()\n    if max_rows &lt;= 0 or len(dicts) &lt;= max_rows:\n        return [{key: formatter(data, key) for key in keys} for data in dicts]\n\n    bottom = max_rows // 2\n    top = max_rows - bottom\n    return (\n        [{key: formatter(data, key) for key in keys} for data in dicts[:top]] +\n        [dict.fromkeys(keys, \"\u2026\")] +\n        [{key: formatter(data, key) for key in keys} for data in dicts[-bottom:]]\n    )\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.SimulationResults.to_string","title":"<code>to_string(keys=None, formatter=get_and_format_num, *, max_rows=None)</code>","text":"<p>Convert the object to a string.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>A table with results rendered as string.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_string(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n) -&gt; str:\n    \"\"\"Convert the object to a string.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n\n    Returns:\n        A table with results rendered as string.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    pretty_dicts = self.to_pretty_dicts(keys, formatter, max_rows=max_rows)\n    widths = {key: len(key) for key in keys}\n    for pretty_dict in pretty_dicts:\n        for key in keys:\n            widths[key] = max(widths[key], len(pretty_dict[key]))\n\n    sep = \" \"\n    rows = [sep.join(key.rjust(widths[key]) for key in keys)]\n    rows.extend(\n        sep.join(pretty_dict[key].rjust(widths[key]) for key in keys)\n        for pretty_dict in pretty_dicts\n    )\n    return \"\\n\".join(rows)\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.SimulationResults.with_defaults","title":"<code>with_defaults(*, keys=None, max_rows=None)</code>","text":"<p>Copies the object and sets the new default parameters.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>New default <code>keys</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> <code>None</code> <code>max_rows</code> <code>int | None</code> <p>New default <code>max_rows</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default keys.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_defaults(\n    self: DictsReprMixinT,\n    *,\n    keys: Sequence[str] | None = None,\n    max_rows: int | None = None,\n) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default parameters.\n\n    Args:\n        keys: New default `keys` for the methods `to_pretty_dicts`, `to_string`,\n            and `to_html`.\n        max_rows: New default `max_rows` for the methods `to_pretty_dicts`,\n            `to_string`, and `to_html`.\n\n    Returns:\n        A copy of the object with the new default keys.\n    \"\"\"\n    new_instance = self.__class__.__new__(self.__class__)\n    new_instance.__dict__.update(self.__dict__)\n    new_instance._cache = None\n    if keys is not None:\n        new_instance.default_keys = keys\n    if max_rows is not None:\n        new_instance.default_max_rows = max_rows\n    return new_instance\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.SimulationResults.with_keys","title":"<code>with_keys(keys)</code>","text":"<p>Copies the object and sets the new default <code>keys</code>.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str]</code> <p>New default <code>keys</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> required <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default <code>keys</code>.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_keys(self: DictsReprMixinT, keys: Sequence[str]) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default `keys`.\n\n    Args:\n        keys: New default `keys` for the methods `to_pretty_dicts`, `to_string`,\n            and `to_html`.\n\n    Returns:\n        A copy of the object with the new default `keys`.\n    \"\"\"\n    return self.with_defaults(keys=keys)\n</code></pre>"},{"location":"api/experiment/#tea_tasting.experiment.SimulationResults.with_max_rows","title":"<code>with_max_rows(max_rows)</code>","text":"<p>Copies the object and sets the new default <code>max_rows</code>.</p> <p>Parameters:</p> Name Type Description Default <code>max_rows</code> <code>int</code> <p>New default <code>max_rows</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> required <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default <code>max_rows</code>.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_max_rows(self: DictsReprMixinT, max_rows: int) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default `max_rows`.\n\n    Args:\n        max_rows: New default `max_rows` for the methods `to_pretty_dicts`,\n            `to_string`, and `to_html`.\n\n    Returns:\n        A copy of the object with the new default `max_rows`.\n    \"\"\"\n    return self.with_defaults(max_rows=max_rows)\n</code></pre>"},{"location":"api/multiplicity/","title":"Multiplicity","text":""},{"location":"api/multiplicity/#tea_tasting.multiplicity","title":"<code>tea_tasting.multiplicity</code>","text":"<p>Multiple hypothesis testing.</p>"},{"location":"api/multiplicity/#tea_tasting.multiplicity.MultipleComparisonsResults","title":"<code>MultipleComparisonsResults</code>","text":"<p>               Bases: <code>DictsReprMixin</code>, <code>UserDict[object, ExperimentResult]</code></p> <p>Multiple comparisons result.</p>"},{"location":"api/multiplicity/#tea_tasting.multiplicity.MultipleComparisonsResults.to_arrow","title":"<code>to_arrow()</code>","text":"<p>Convert the object to a PyArrow Table.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_arrow(self) -&gt; pa.Table:\n    \"\"\"Convert the object to a PyArrow Table.\"\"\"\n    return pa.Table.from_pylist(self.to_dicts())\n</code></pre>"},{"location":"api/multiplicity/#tea_tasting.multiplicity.MultipleComparisonsResults.to_dicts","title":"<code>to_dicts()</code>","text":"<p>Convert the result to a sequence of dictionaries.</p> Source code in <code>src/tea_tasting/multiplicity.py</code> <pre><code>@tea_tasting.utils._cache_method\ndef to_dicts(self) -&gt; tuple[dict[str, object], ...]:\n    \"\"\"Convert the result to a sequence of dictionaries.\"\"\"\n    return tuple(\n        {\"comparison\": str(comparison)} | metric_result\n        for comparison, experiment_result in self.items()\n        for metric_result in experiment_result.to_dicts()\n    )\n</code></pre>"},{"location":"api/multiplicity/#tea_tasting.multiplicity.MultipleComparisonsResults.to_html","title":"<code>to_html(keys=None, formatter=get_and_format_num, *, max_rows=None, indent=None)</code>","text":"<p>Convert the object to HTML.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <code>indent</code> <code>str | None</code> <p>Whitespace to insert for each indentation level. If <code>None</code>, do not indent.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>A table with results rendered as HTML.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_html(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n    indent: str | None = None,\n) -&gt; str:\n    \"\"\"Convert the object to HTML.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n        indent: Whitespace to insert for each indentation level. If `None`,\n            do not indent.\n\n    Returns:\n        A table with results rendered as HTML.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    table = ET.Element(\n        \"table\",\n        {\"class\": \"dataframe\", \"style\": \"text-align: right;\"},\n    )\n    thead = ET.SubElement(table, \"thead\")\n    thead_tr = ET.SubElement(thead, \"tr\")\n    for key in keys:\n        th = ET.SubElement(thead_tr, \"th\")\n        th.text = key\n    tbody = ET.SubElement(table, \"tbody\")\n    for pretty_dict in self.to_pretty_dicts(keys, formatter, max_rows=max_rows):\n        tr = ET.SubElement(tbody, \"tr\")\n        for key in keys:\n            td = ET.SubElement(tr, \"td\")\n            td.text = pretty_dict[key]\n    if indent is not None:\n        ET.indent(table, space=indent)\n    return ET.tostring(table, encoding=\"unicode\", method=\"html\")\n</code></pre>"},{"location":"api/multiplicity/#tea_tasting.multiplicity.MultipleComparisonsResults.to_pandas","title":"<code>to_pandas()</code>","text":"<p>Convert the object to a Pandas DataFrame.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_pandas(self) -&gt; pd.DataFrame:\n    \"\"\"Convert the object to a Pandas DataFrame.\"\"\"\n    import pandas as pd  # noqa: PLC0415\n    return pd.DataFrame.from_records(self.to_dicts())\n</code></pre>"},{"location":"api/multiplicity/#tea_tasting.multiplicity.MultipleComparisonsResults.to_polars","title":"<code>to_polars()</code>","text":"<p>Convert the object to a Polars DataFrame.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_polars(self) -&gt; pl.DataFrame:\n    \"\"\"Convert the object to a Polars DataFrame.\"\"\"\n    import polars as pl  # noqa: PLC0415\n    return pl.from_dicts(self.to_dicts())\n</code></pre>"},{"location":"api/multiplicity/#tea_tasting.multiplicity.MultipleComparisonsResults.to_pretty_dicts","title":"<code>to_pretty_dicts(keys=None, formatter=get_and_format_num, *, max_rows=None)</code>","text":"<p>Convert the object to a list of dictionaries with formatted values.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[dict[str, str]]</code> <p>List of dictionaries with formatted values.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_pretty_dicts(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n) -&gt; list[dict[str, str]]:\n    \"\"\"Convert the object to a list of dictionaries with formatted values.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n\n    Returns:\n        List of dictionaries with formatted values.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    dicts = self.to_dicts()\n    if max_rows &lt;= 0 or len(dicts) &lt;= max_rows:\n        return [{key: formatter(data, key) for key in keys} for data in dicts]\n\n    bottom = max_rows // 2\n    top = max_rows - bottom\n    return (\n        [{key: formatter(data, key) for key in keys} for data in dicts[:top]] +\n        [dict.fromkeys(keys, \"\u2026\")] +\n        [{key: formatter(data, key) for key in keys} for data in dicts[-bottom:]]\n    )\n</code></pre>"},{"location":"api/multiplicity/#tea_tasting.multiplicity.MultipleComparisonsResults.to_string","title":"<code>to_string(keys=None, formatter=get_and_format_num, *, max_rows=None)</code>","text":"<p>Convert the object to a string.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>A table with results rendered as string.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_string(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n) -&gt; str:\n    \"\"\"Convert the object to a string.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n\n    Returns:\n        A table with results rendered as string.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    pretty_dicts = self.to_pretty_dicts(keys, formatter, max_rows=max_rows)\n    widths = {key: len(key) for key in keys}\n    for pretty_dict in pretty_dicts:\n        for key in keys:\n            widths[key] = max(widths[key], len(pretty_dict[key]))\n\n    sep = \" \"\n    rows = [sep.join(key.rjust(widths[key]) for key in keys)]\n    rows.extend(\n        sep.join(pretty_dict[key].rjust(widths[key]) for key in keys)\n        for pretty_dict in pretty_dicts\n    )\n    return \"\\n\".join(rows)\n</code></pre>"},{"location":"api/multiplicity/#tea_tasting.multiplicity.MultipleComparisonsResults.with_defaults","title":"<code>with_defaults(*, keys=None, max_rows=None)</code>","text":"<p>Copies the object and sets the new default parameters.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>New default <code>keys</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> <code>None</code> <code>max_rows</code> <code>int | None</code> <p>New default <code>max_rows</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default keys.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_defaults(\n    self: DictsReprMixinT,\n    *,\n    keys: Sequence[str] | None = None,\n    max_rows: int | None = None,\n) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default parameters.\n\n    Args:\n        keys: New default `keys` for the methods `to_pretty_dicts`, `to_string`,\n            and `to_html`.\n        max_rows: New default `max_rows` for the methods `to_pretty_dicts`,\n            `to_string`, and `to_html`.\n\n    Returns:\n        A copy of the object with the new default keys.\n    \"\"\"\n    new_instance = self.__class__.__new__(self.__class__)\n    new_instance.__dict__.update(self.__dict__)\n    new_instance._cache = None\n    if keys is not None:\n        new_instance.default_keys = keys\n    if max_rows is not None:\n        new_instance.default_max_rows = max_rows\n    return new_instance\n</code></pre>"},{"location":"api/multiplicity/#tea_tasting.multiplicity.MultipleComparisonsResults.with_keys","title":"<code>with_keys(keys)</code>","text":"<p>Copies the object and sets the new default <code>keys</code>.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str]</code> <p>New default <code>keys</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> required <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default <code>keys</code>.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_keys(self: DictsReprMixinT, keys: Sequence[str]) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default `keys`.\n\n    Args:\n        keys: New default `keys` for the methods `to_pretty_dicts`, `to_string`,\n            and `to_html`.\n\n    Returns:\n        A copy of the object with the new default `keys`.\n    \"\"\"\n    return self.with_defaults(keys=keys)\n</code></pre>"},{"location":"api/multiplicity/#tea_tasting.multiplicity.MultipleComparisonsResults.with_max_rows","title":"<code>with_max_rows(max_rows)</code>","text":"<p>Copies the object and sets the new default <code>max_rows</code>.</p> <p>Parameters:</p> Name Type Description Default <code>max_rows</code> <code>int</code> <p>New default <code>max_rows</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> required <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default <code>max_rows</code>.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_max_rows(self: DictsReprMixinT, max_rows: int) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default `max_rows`.\n\n    Args:\n        max_rows: New default `max_rows` for the methods `to_pretty_dicts`,\n            `to_string`, and `to_html`.\n\n    Returns:\n        A copy of the object with the new default `max_rows`.\n    \"\"\"\n    return self.with_defaults(max_rows=max_rows)\n</code></pre>"},{"location":"api/multiplicity/#tea_tasting.multiplicity.adjust_fdr","title":"<code>adjust_fdr(experiment_results, metrics=None, *, alpha=None, arbitrary_dependence=False)</code>","text":"<p>Adjust p-value and alpha to control the false discovery rate (FDR).</p> <p>The number of hypotheses tested is the total number of metrics included in the comparison in all experiment results. For example, if there are 3 experiments with 2 metrics in each, the number of hypotheses is 6.</p> <p>The function performs one of the following corrections, depending on parameters:</p> <ul> <li>Benjamini-Hochberg procedure, assuming non-negative correlation between     hypotheses (<code>arbitrary_dependence=False</code>).</li> <li>Benjamini-Yekutieli procedure, assuming arbitrary dependence between     hypotheses (<code>arbitrary_dependence=True</code>).</li> </ul> <p>The function adds the following attributes to the results:</p> <ul> <li><code>pvalue_adj</code>: The adjusted p-value, which should be compared with     the unadjusted FDR (<code>alpha</code>).</li> <li><code>alpha_adj</code>: The adjusted FDR, which should be compared with the unadjusted     p-value (<code>pvalue</code>).</li> <li><code>null_rejected</code>: A binary indicator (<code>0</code> or <code>1</code>) that shows whether     the null hypothesis is rejected.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>experiment_results</code> <code>ExperimentResult | Mapping[object, ExperimentResult]</code> <p>Experiment results.</p> required <code>metrics</code> <code>str | set[str] | Sequence[str] | None</code> <p>Metrics included in the comparison. If <code>None</code>, all metrics are included.</p> <code>None</code> <code>alpha</code> <code>float | None</code> <p>Significance level. If <code>None</code>, the value from global settings is used.</p> <code>None</code> <code>arbitrary_dependence</code> <code>bool</code> <p>If <code>True</code>, arbitrary dependence between hypotheses is assumed and Benjamini-Yekutieli procedure is performed. If <code>False</code>, non-negative correlation between hypotheses is assumed and Benjamini-Hochberg procedure is performed.</p> <code>False</code> <p>Returns:</p> Type Description <code>MultipleComparisonsResults</code> <p>The experiments results with adjusted p-values and alphas.</p> Parameter defaults <p>Default for parameter <code>alpha</code> can be changed using the <code>config_context</code> and <code>set_context</code> functions. See the Global configuration reference for details.</p> References <ul> <li>Multiple comparisons problem.</li> <li>False discovery rate.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; data = pl.concat((\n...     tt.make_users_data(\n...         seed=42,\n...         orders_uplift=0.10,\n...         revenue_uplift=0.15,\n...         return_type=\"polars\",\n...     ),\n...     tt.make_users_data(\n...         seed=21,\n...         orders_uplift=0.15,\n...         revenue_uplift=0.20,\n...         return_type=\"polars\",\n...     )\n...         .filter(pl.col(\"variant\").eq(1))\n...         .with_columns(variant=pl.lit(2, pl.Int64)),\n... ))\n&gt;&gt;&gt; data\nshape: (6_046, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 user \u2506 variant \u2506 sessions \u2506 orders \u2506 revenue \u2502\n\u2502 ---  \u2506 ---     \u2506 ---      \u2506 ---    \u2506 ---     \u2502\n\u2502 i64  \u2506 i64     \u2506 i64      \u2506 i64    \u2506 f64     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0    \u2506 1       \u2506 2        \u2506 1      \u2506 9.58    \u2502\n\u2502 1    \u2506 0       \u2506 2        \u2506 1      \u2506 6.43    \u2502\n\u2502 2    \u2506 1       \u2506 2        \u2506 1      \u2506 8.3     \u2502\n\u2502 3    \u2506 1       \u2506 2        \u2506 1      \u2506 16.65   \u2502\n\u2502 4    \u2506 0       \u2506 1        \u2506 1      \u2506 7.14    \u2502\n\u2502 \u2026    \u2506 \u2026       \u2506 \u2026        \u2506 \u2026      \u2506 \u2026       \u2502\n\u2502 3989 \u2506 2       \u2506 4        \u2506 4      \u2506 34.93   \u2502\n\u2502 3991 \u2506 2       \u2506 1        \u2506 0      \u2506 0.0     \u2502\n\u2502 3992 \u2506 2       \u2506 3        \u2506 3      \u2506 27.96   \u2502\n\u2502 3994 \u2506 2       \u2506 2        \u2506 1      \u2506 17.22   \u2502\n\u2502 3998 \u2506 2       \u2506 3        \u2506 0      \u2506 0.0     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n&gt;&gt;&gt; experiment = tt.Experiment(\n...     sessions_per_user=tt.Mean(\"sessions\"),\n...     orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\"),\n...     orders_per_user=tt.Mean(\"orders\"),\n...     revenue_per_user=tt.Mean(\"revenue\"),\n... )\n\n&gt;&gt;&gt; # Results without correction.\n&gt;&gt;&gt; results = experiment.analyze(data, control=0, all_variants=True)\n&gt;&gt;&gt; results\nvariants             metric control treatment rel_effect_size rel_effect_size_ci  pvalue\n  (0, 1)  sessions_per_user    2.00      1.98          -0.66%      [-3.7%, 2.5%]   0.674\n  (0, 1) orders_per_session   0.266     0.289            8.8%      [-0.89%, 19%]  0.0762\n  (0, 1)    orders_per_user   0.530     0.573            8.0%       [-2.0%, 19%]   0.118\n  (0, 1)   revenue_per_user    5.24      5.99             14%        [2.1%, 28%]  0.0211\n  (0, 2)  sessions_per_user    2.00      2.02           0.98%      [-2.1%, 4.1%]   0.532\n  (0, 2) orders_per_session   0.266     0.295             11%        [1.2%, 22%]  0.0273\n  (0, 2)    orders_per_user   0.530     0.594             12%        [1.7%, 23%]  0.0213\n  (0, 2)   revenue_per_user    5.24      6.25             19%        [6.6%, 33%] 0.00218\n\n&gt;&gt;&gt; # Success metrics.\n&gt;&gt;&gt; metrics = {\"orders_per_user\", \"revenue_per_user\"}\n\n&gt;&gt;&gt; # Benjamini-Hochberg procedure,\n&gt;&gt;&gt; # assuming non-negative correlation between hypotheses.\n&gt;&gt;&gt; adjusted_results_fdr = tt.adjust_fdr(results, metrics)\n&gt;&gt;&gt; adjusted_results_fdr\ncomparison           metric control treatment rel_effect_size  pvalue pvalue_adj\n    (0, 1)  orders_per_user   0.530     0.573            8.0%   0.118      0.118\n    (0, 1) revenue_per_user    5.24      5.99             14%  0.0211     0.0284\n    (0, 2)  orders_per_user   0.530     0.594             12%  0.0213     0.0284\n    (0, 2) revenue_per_user    5.24      6.25             19% 0.00218    0.00872\n\n&gt;&gt;&gt; # The adjusted confidence level alpha.\n&gt;&gt;&gt; adjusted_results_fdr.with_keys((\n...     \"comparison\",\n...     \"metric\",\n...     \"control\",\n...     \"treatment\",\n...     \"rel_effect_size\",\n...     \"pvalue\",\n...     \"alpha_adj\",\n... ))\ncomparison           metric control treatment rel_effect_size  pvalue alpha_adj\n    (0, 1)  orders_per_user   0.530     0.573            8.0%   0.118    0.0500\n    (0, 1) revenue_per_user    5.24      5.99             14%  0.0211    0.0375\n    (0, 2)  orders_per_user   0.530     0.594             12%  0.0213    0.0375\n    (0, 2) revenue_per_user    5.24      6.25             19% 0.00218    0.0375\n\n&gt;&gt;&gt; # Benjamini-Yekutieli procedure,\n&gt;&gt;&gt; # assuming arbitrary dependence between hypotheses.\n&gt;&gt;&gt; tt.adjust_fdr(results, metrics, arbitrary_dependence=True)\ncomparison           metric control treatment rel_effect_size  pvalue pvalue_adj\n    (0, 1)  orders_per_user   0.530     0.573            8.0%   0.118      0.245\n    (0, 1) revenue_per_user    5.24      5.99             14%  0.0211     0.0592\n    (0, 2)  orders_per_user   0.530     0.594             12%  0.0213     0.0592\n    (0, 2) revenue_per_user    5.24      6.25             19% 0.00218     0.0182\n</code></pre> Source code in <code>src/tea_tasting/multiplicity.py</code> <pre><code>def adjust_fdr(\n    experiment_results: tea_tasting.experiment.ExperimentResult | Mapping[\n        object, tea_tasting.experiment.ExperimentResult],\n    metrics: str | set[str] | Sequence[str] | None = None,\n    *,\n    alpha: float | None = None,\n    arbitrary_dependence: bool = False,\n) -&gt; MultipleComparisonsResults:\n    \"\"\"Adjust p-value and alpha to control the false discovery rate (FDR).\n\n    The number of hypotheses tested is the total number of metrics included in\n    the comparison in all experiment results. For example, if there are\n    3 experiments with 2 metrics in each, the number of hypotheses is 6.\n\n    The function performs one of the following corrections, depending on parameters:\n\n    - Benjamini-Hochberg procedure, assuming non-negative correlation between\n        hypotheses (`arbitrary_dependence=False`).\n    - Benjamini-Yekutieli procedure, assuming arbitrary dependence between\n        hypotheses (`arbitrary_dependence=True`).\n\n    The function adds the following attributes to the results:\n\n    - `pvalue_adj`: The adjusted p-value, which should be compared with\n        the unadjusted FDR (`alpha`).\n    - `alpha_adj`: The adjusted FDR, which should be compared with the unadjusted\n        p-value (`pvalue`).\n    - `null_rejected`: A binary indicator (`0` or `1`) that shows whether\n        the null hypothesis is rejected.\n\n    Args:\n        experiment_results: Experiment results.\n        metrics: Metrics included in the comparison.\n            If `None`, all metrics are included.\n        alpha: Significance level. If `None`, the value from global settings is used.\n        arbitrary_dependence: If `True`, arbitrary dependence between hypotheses\n            is assumed and Benjamini-Yekutieli procedure is performed.\n            If `False`, non-negative correlation between hypotheses is assumed\n            and Benjamini-Hochberg procedure is performed.\n\n    Returns:\n        The experiments results with adjusted p-values and alphas.\n\n    Parameter defaults:\n        Default for parameter `alpha` can be changed using the `config_context`\n        and `set_context` functions.\n        See the [Global configuration](https://tea-tasting.e10v.me/api/config/)\n        reference for details.\n\n    References:\n        - [Multiple comparisons problem](https://en.wikipedia.org/wiki/Multiple_comparisons_problem).\n        - [False discovery rate](https://en.wikipedia.org/wiki/False_discovery_rate).\n\n    Examples:\n        ```pycon\n        &gt;&gt;&gt; import polars as pl\n        &gt;&gt;&gt; import tea_tasting as tt\n\n        &gt;&gt;&gt; data = pl.concat((\n        ...     tt.make_users_data(\n        ...         seed=42,\n        ...         orders_uplift=0.10,\n        ...         revenue_uplift=0.15,\n        ...         return_type=\"polars\",\n        ...     ),\n        ...     tt.make_users_data(\n        ...         seed=21,\n        ...         orders_uplift=0.15,\n        ...         revenue_uplift=0.20,\n        ...         return_type=\"polars\",\n        ...     )\n        ...         .filter(pl.col(\"variant\").eq(1))\n        ...         .with_columns(variant=pl.lit(2, pl.Int64)),\n        ... ))\n        &gt;&gt;&gt; data\n        shape: (6_046, 5)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 user \u2506 variant \u2506 sessions \u2506 orders \u2506 revenue \u2502\n        \u2502 ---  \u2506 ---     \u2506 ---      \u2506 ---    \u2506 ---     \u2502\n        \u2502 i64  \u2506 i64     \u2506 i64      \u2506 i64    \u2506 f64     \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 0    \u2506 1       \u2506 2        \u2506 1      \u2506 9.58    \u2502\n        \u2502 1    \u2506 0       \u2506 2        \u2506 1      \u2506 6.43    \u2502\n        \u2502 2    \u2506 1       \u2506 2        \u2506 1      \u2506 8.3     \u2502\n        \u2502 3    \u2506 1       \u2506 2        \u2506 1      \u2506 16.65   \u2502\n        \u2502 4    \u2506 0       \u2506 1        \u2506 1      \u2506 7.14    \u2502\n        \u2502 \u2026    \u2506 \u2026       \u2506 \u2026        \u2506 \u2026      \u2506 \u2026       \u2502\n        \u2502 3989 \u2506 2       \u2506 4        \u2506 4      \u2506 34.93   \u2502\n        \u2502 3991 \u2506 2       \u2506 1        \u2506 0      \u2506 0.0     \u2502\n        \u2502 3992 \u2506 2       \u2506 3        \u2506 3      \u2506 27.96   \u2502\n        \u2502 3994 \u2506 2       \u2506 2        \u2506 1      \u2506 17.22   \u2502\n        \u2502 3998 \u2506 2       \u2506 3        \u2506 0      \u2506 0.0     \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n        &gt;&gt;&gt; experiment = tt.Experiment(\n        ...     sessions_per_user=tt.Mean(\"sessions\"),\n        ...     orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\"),\n        ...     orders_per_user=tt.Mean(\"orders\"),\n        ...     revenue_per_user=tt.Mean(\"revenue\"),\n        ... )\n\n        &gt;&gt;&gt; # Results without correction.\n        &gt;&gt;&gt; results = experiment.analyze(data, control=0, all_variants=True)\n        &gt;&gt;&gt; results\n        variants             metric control treatment rel_effect_size rel_effect_size_ci  pvalue\n          (0, 1)  sessions_per_user    2.00      1.98          -0.66%      [-3.7%, 2.5%]   0.674\n          (0, 1) orders_per_session   0.266     0.289            8.8%      [-0.89%, 19%]  0.0762\n          (0, 1)    orders_per_user   0.530     0.573            8.0%       [-2.0%, 19%]   0.118\n          (0, 1)   revenue_per_user    5.24      5.99             14%        [2.1%, 28%]  0.0211\n          (0, 2)  sessions_per_user    2.00      2.02           0.98%      [-2.1%, 4.1%]   0.532\n          (0, 2) orders_per_session   0.266     0.295             11%        [1.2%, 22%]  0.0273\n          (0, 2)    orders_per_user   0.530     0.594             12%        [1.7%, 23%]  0.0213\n          (0, 2)   revenue_per_user    5.24      6.25             19%        [6.6%, 33%] 0.00218\n\n        &gt;&gt;&gt; # Success metrics.\n        &gt;&gt;&gt; metrics = {\"orders_per_user\", \"revenue_per_user\"}\n\n        &gt;&gt;&gt; # Benjamini-Hochberg procedure,\n        &gt;&gt;&gt; # assuming non-negative correlation between hypotheses.\n        &gt;&gt;&gt; adjusted_results_fdr = tt.adjust_fdr(results, metrics)\n        &gt;&gt;&gt; adjusted_results_fdr\n        comparison           metric control treatment rel_effect_size  pvalue pvalue_adj\n            (0, 1)  orders_per_user   0.530     0.573            8.0%   0.118      0.118\n            (0, 1) revenue_per_user    5.24      5.99             14%  0.0211     0.0284\n            (0, 2)  orders_per_user   0.530     0.594             12%  0.0213     0.0284\n            (0, 2) revenue_per_user    5.24      6.25             19% 0.00218    0.00872\n\n        &gt;&gt;&gt; # The adjusted confidence level alpha.\n        &gt;&gt;&gt; adjusted_results_fdr.with_keys((\n        ...     \"comparison\",\n        ...     \"metric\",\n        ...     \"control\",\n        ...     \"treatment\",\n        ...     \"rel_effect_size\",\n        ...     \"pvalue\",\n        ...     \"alpha_adj\",\n        ... ))\n        comparison           metric control treatment rel_effect_size  pvalue alpha_adj\n            (0, 1)  orders_per_user   0.530     0.573            8.0%   0.118    0.0500\n            (0, 1) revenue_per_user    5.24      5.99             14%  0.0211    0.0375\n            (0, 2)  orders_per_user   0.530     0.594             12%  0.0213    0.0375\n            (0, 2) revenue_per_user    5.24      6.25             19% 0.00218    0.0375\n\n        &gt;&gt;&gt; # Benjamini-Yekutieli procedure,\n        &gt;&gt;&gt; # assuming arbitrary dependence between hypotheses.\n        &gt;&gt;&gt; tt.adjust_fdr(results, metrics, arbitrary_dependence=True)\n        comparison           metric control treatment rel_effect_size  pvalue pvalue_adj\n            (0, 1)  orders_per_user   0.530     0.573            8.0%   0.118      0.245\n            (0, 1) revenue_per_user    5.24      5.99             14%  0.0211     0.0592\n            (0, 2)  orders_per_user   0.530     0.594             12%  0.0213     0.0592\n            (0, 2) revenue_per_user    5.24      6.25             19% 0.00218     0.0182\n\n        ```\n    \"\"\"  # noqa: E501\n    alpha = (\n        tea_tasting.utils.auto_check(alpha, \"alpha\")\n        if alpha is not None\n        else tea_tasting.config.get_config(\"alpha\")\n    )\n    arbitrary_dependence = tea_tasting.utils.check_scalar(\n        arbitrary_dependence, \"arbitrary_dependence\", typ=bool)\n\n    # results and metric_results refer to the same dicts.\n    results, metric_results = _copy_results(experiment_results, metrics)\n    method = _Benjamini(\n        alpha=alpha,  # type: ignore\n        m=len(metric_results),\n        arbitrary_dependence=arbitrary_dependence,\n    )\n    # In-place update.\n    _hochberg_stepup(metric_results, method.adjust)\n\n    return MultipleComparisonsResults(results)\n</code></pre>"},{"location":"api/multiplicity/#tea_tasting.multiplicity.adjust_fwer","title":"<code>adjust_fwer(experiment_results, metrics=None, *, alpha=None, arbitrary_dependence=False, method='sidak')</code>","text":"<p>Adjust p-value and alpha to control the family-wise error rate (FWER).</p> <p>The number of hypotheses tested is the total number of metrics included in the comparison in all experiment results. For example, if there are 3 experiments with 2 metrics in each, the number of hypotheses is 6.</p> <p>The function performs one of the following procedures, depending on parameters:</p> <ul> <li>Hochberg's step-up procedure, assuming non-negative correlation between     hypotheses (<code>arbitrary_dependence=False</code>).</li> <li>Holm's step-down procedure, assuming arbitrary dependence between     hypotheses (<code>arbitrary_dependence=True</code>).</li> </ul> <p>The function adds the following attributes to the results:</p> <ul> <li><code>pvalue_adj</code>: The adjusted p-value, which should be compared with     the unadjusted FDR (<code>alpha</code>).</li> <li><code>alpha_adj</code>: The adjusted FWER, which should be compared with the unadjusted     p-value (<code>pvalue</code>).</li> <li><code>null_rejected</code>: A binary indicator (<code>0</code> or <code>1</code>) that shows whether     the null hypothesis is rejected.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>experiment_results</code> <code>ExperimentResult | Mapping[object, ExperimentResult]</code> <p>Experiment results.</p> required <code>metrics</code> <code>str | set[str] | Sequence[str] | None</code> <p>Metrics included in the comparison. If <code>None</code>, all metrics are included.</p> <code>None</code> <code>alpha</code> <code>float | None</code> <p>Significance level. If <code>None</code>, the value from global settings is used.</p> <code>None</code> <code>arbitrary_dependence</code> <code>bool</code> <p>If <code>True</code>, arbitrary dependence between hypotheses is assumed and Holm's step-down procedure is performed. If <code>False</code>, non-negative correlation between hypotheses is assumed and Hochberg's step-up procedure is performed.</p> <code>False</code> <code>method</code> <code>Literal['bonferroni', 'sidak']</code> <p>Correction method, Bonferroni (<code>\"bonferroni\"</code>) or \u0160id\u00e1k (<code>\"sidak\"</code>).</p> <code>'sidak'</code> <p>Returns:</p> Type Description <code>MultipleComparisonsResults</code> <p>The experiments results with adjusted p-values and alphas.</p> Parameter defaults <p>Default for parameter <code>alpha</code> can be changed using the <code>config_context</code> and <code>set_context</code> functions. See the Global configuration reference for details.</p> References <ul> <li>Multiple comparisons problem.</li> <li>Family-wise error rate.</li> <li>Holm\u2013Bonferroni method.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; data = pl.concat((\n...     tt.make_users_data(\n...         seed=42,\n...         orders_uplift=0.10,\n...         revenue_uplift=0.15,\n...         return_type=\"polars\",\n...     ),\n...     tt.make_users_data(\n...         seed=21,\n...         orders_uplift=0.15,\n...         revenue_uplift=0.20,\n...         return_type=\"polars\",\n...     )\n...         .filter(pl.col(\"variant\").eq(1))\n...         .with_columns(variant=pl.lit(2, pl.Int64)),\n... ))\n&gt;&gt;&gt; data\nshape: (6_046, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 user \u2506 variant \u2506 sessions \u2506 orders \u2506 revenue \u2502\n\u2502 ---  \u2506 ---     \u2506 ---      \u2506 ---    \u2506 ---     \u2502\n\u2502 i64  \u2506 i64     \u2506 i64      \u2506 i64    \u2506 f64     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0    \u2506 1       \u2506 2        \u2506 1      \u2506 9.58    \u2502\n\u2502 1    \u2506 0       \u2506 2        \u2506 1      \u2506 6.43    \u2502\n\u2502 2    \u2506 1       \u2506 2        \u2506 1      \u2506 8.3     \u2502\n\u2502 3    \u2506 1       \u2506 2        \u2506 1      \u2506 16.65   \u2502\n\u2502 4    \u2506 0       \u2506 1        \u2506 1      \u2506 7.14    \u2502\n\u2502 \u2026    \u2506 \u2026       \u2506 \u2026        \u2506 \u2026      \u2506 \u2026       \u2502\n\u2502 3989 \u2506 2       \u2506 4        \u2506 4      \u2506 34.93   \u2502\n\u2502 3991 \u2506 2       \u2506 1        \u2506 0      \u2506 0.0     \u2502\n\u2502 3992 \u2506 2       \u2506 3        \u2506 3      \u2506 27.96   \u2502\n\u2502 3994 \u2506 2       \u2506 2        \u2506 1      \u2506 17.22   \u2502\n\u2502 3998 \u2506 2       \u2506 3        \u2506 0      \u2506 0.0     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n&gt;&gt;&gt; experiment = tt.Experiment(\n...     sessions_per_user=tt.Mean(\"sessions\"),\n...     orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\"),\n...     orders_per_user=tt.Mean(\"orders\"),\n...     revenue_per_user=tt.Mean(\"revenue\"),\n... )\n\n&gt;&gt;&gt; # Results without correction.\n&gt;&gt;&gt; results = experiment.analyze(data, control=0, all_variants=True)\n&gt;&gt;&gt; results\nvariants             metric control treatment rel_effect_size rel_effect_size_ci  pvalue\n  (0, 1)  sessions_per_user    2.00      1.98          -0.66%      [-3.7%, 2.5%]   0.674\n  (0, 1) orders_per_session   0.266     0.289            8.8%      [-0.89%, 19%]  0.0762\n  (0, 1)    orders_per_user   0.530     0.573            8.0%       [-2.0%, 19%]   0.118\n  (0, 1)   revenue_per_user    5.24      5.99             14%        [2.1%, 28%]  0.0211\n  (0, 2)  sessions_per_user    2.00      2.02           0.98%      [-2.1%, 4.1%]   0.532\n  (0, 2) orders_per_session   0.266     0.295             11%        [1.2%, 22%]  0.0273\n  (0, 2)    orders_per_user   0.530     0.594             12%        [1.7%, 23%]  0.0213\n  (0, 2)   revenue_per_user    5.24      6.25             19%        [6.6%, 33%] 0.00218\n\n&gt;&gt;&gt; # Success metrics.\n&gt;&gt;&gt; metrics = {\"orders_per_user\", \"revenue_per_user\"}\n\n&gt;&gt;&gt; # Hochberg's step-up procedure with \u0160id\u00e1k correction,\n&gt;&gt;&gt; # assuming non-negative correlation between hypotheses.\n&gt;&gt;&gt; adjusted_results_fwer = tt.adjust_fwer(results, metrics)\n&gt;&gt;&gt; adjusted_results_fwer\ncomparison           metric control treatment rel_effect_size  pvalue pvalue_adj\n    (0, 1)  orders_per_user   0.530     0.573            8.0%   0.118      0.118\n    (0, 1) revenue_per_user    5.24      5.99             14%  0.0211     0.0422\n    (0, 2)  orders_per_user   0.530     0.594             12%  0.0213     0.0422\n    (0, 2) revenue_per_user    5.24      6.25             19% 0.00218    0.00869\n\n&gt;&gt;&gt; # The adjusted confidence level alpha.\n&gt;&gt;&gt; adjusted_results_fwer.with_keys((\n...     \"comparison\",\n...     \"metric\",\n...     \"control\",\n...     \"treatment\",\n...     \"rel_effect_size\",\n...     \"pvalue\",\n...     \"alpha_adj\",\n... ))\ncomparison           metric control treatment rel_effect_size  pvalue alpha_adj\n    (0, 1)  orders_per_user   0.530     0.573            8.0%   0.118    0.0500\n    (0, 1) revenue_per_user    5.24      5.99             14%  0.0211    0.0253\n    (0, 2)  orders_per_user   0.530     0.594             12%  0.0213    0.0253\n    (0, 2) revenue_per_user    5.24      6.25             19% 0.00218    0.0253\n\n&gt;&gt;&gt; # Holm's step-down procedure with Bonferroni correction,\n&gt;&gt;&gt; # assuming arbitrary dependence between hypotheses.\n&gt;&gt;&gt; tt.adjust_fwer(\n...     results,\n...     metrics,\n...     arbitrary_dependence=True,\n...     method=\"bonferroni\",\n... )\ncomparison           metric control treatment rel_effect_size  pvalue pvalue_adj\n    (0, 1)  orders_per_user   0.530     0.573            8.0%   0.118      0.118\n    (0, 1) revenue_per_user    5.24      5.99             14%  0.0211     0.0634\n    (0, 2)  orders_per_user   0.530     0.594             12%  0.0213     0.0634\n    (0, 2) revenue_per_user    5.24      6.25             19% 0.00218    0.00872\n</code></pre> Source code in <code>src/tea_tasting/multiplicity.py</code> <pre><code>def adjust_fwer(\n    experiment_results: tea_tasting.experiment.ExperimentResult | Mapping[\n        object, tea_tasting.experiment.ExperimentResult],\n    metrics: str | set[str] | Sequence[str] | None = None,\n    *,\n    alpha: float | None = None,\n    arbitrary_dependence: bool = False,\n    method: Literal[\"bonferroni\", \"sidak\"] = \"sidak\",\n) -&gt; MultipleComparisonsResults:\n    \"\"\"Adjust p-value and alpha to control the family-wise error rate (FWER).\n\n    The number of hypotheses tested is the total number of metrics included in\n    the comparison in all experiment results. For example, if there are\n    3 experiments with 2 metrics in each, the number of hypotheses is 6.\n\n    The function performs one of the following procedures, depending on parameters:\n\n    - Hochberg's step-up procedure, assuming non-negative correlation between\n        hypotheses (`arbitrary_dependence=False`).\n    - Holm's step-down procedure, assuming arbitrary dependence between\n        hypotheses (`arbitrary_dependence=True`).\n\n    The function adds the following attributes to the results:\n\n    - `pvalue_adj`: The adjusted p-value, which should be compared with\n        the unadjusted FDR (`alpha`).\n    - `alpha_adj`: The adjusted FWER, which should be compared with the unadjusted\n        p-value (`pvalue`).\n    - `null_rejected`: A binary indicator (`0` or `1`) that shows whether\n        the null hypothesis is rejected.\n\n    Args:\n        experiment_results: Experiment results.\n        metrics: Metrics included in the comparison.\n            If `None`, all metrics are included.\n        alpha: Significance level. If `None`, the value from global settings is used.\n        arbitrary_dependence: If `True`, arbitrary dependence between hypotheses\n            is assumed and Holm's step-down procedure is performed.\n            If `False`, non-negative correlation between hypotheses is assumed\n            and Hochberg's step-up procedure is performed.\n        method: Correction method, Bonferroni (`\"bonferroni\"`) or \u0160id\u00e1k (`\"sidak\"`).\n\n    Returns:\n        The experiments results with adjusted p-values and alphas.\n\n    Parameter defaults:\n        Default for parameter `alpha` can be changed using the `config_context`\n        and `set_context` functions.\n        See the [Global configuration](https://tea-tasting.e10v.me/api/config/)\n        reference for details.\n\n    References:\n        - [Multiple comparisons problem](https://en.wikipedia.org/wiki/Multiple_comparisons_problem).\n        - [Family-wise error rate](https://en.wikipedia.org/wiki/Family-wise_error_rate).\n        - [Holm\u2013Bonferroni method](https://en.wikipedia.org/wiki/Holm%E2%80%93Bonferroni_method).\n\n    Examples:\n        ```pycon\n        &gt;&gt;&gt; import polars as pl\n        &gt;&gt;&gt; import tea_tasting as tt\n\n        &gt;&gt;&gt; data = pl.concat((\n        ...     tt.make_users_data(\n        ...         seed=42,\n        ...         orders_uplift=0.10,\n        ...         revenue_uplift=0.15,\n        ...         return_type=\"polars\",\n        ...     ),\n        ...     tt.make_users_data(\n        ...         seed=21,\n        ...         orders_uplift=0.15,\n        ...         revenue_uplift=0.20,\n        ...         return_type=\"polars\",\n        ...     )\n        ...         .filter(pl.col(\"variant\").eq(1))\n        ...         .with_columns(variant=pl.lit(2, pl.Int64)),\n        ... ))\n        &gt;&gt;&gt; data\n        shape: (6_046, 5)\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 user \u2506 variant \u2506 sessions \u2506 orders \u2506 revenue \u2502\n        \u2502 ---  \u2506 ---     \u2506 ---      \u2506 ---    \u2506 ---     \u2502\n        \u2502 i64  \u2506 i64     \u2506 i64      \u2506 i64    \u2506 f64     \u2502\n        \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n        \u2502 0    \u2506 1       \u2506 2        \u2506 1      \u2506 9.58    \u2502\n        \u2502 1    \u2506 0       \u2506 2        \u2506 1      \u2506 6.43    \u2502\n        \u2502 2    \u2506 1       \u2506 2        \u2506 1      \u2506 8.3     \u2502\n        \u2502 3    \u2506 1       \u2506 2        \u2506 1      \u2506 16.65   \u2502\n        \u2502 4    \u2506 0       \u2506 1        \u2506 1      \u2506 7.14    \u2502\n        \u2502 \u2026    \u2506 \u2026       \u2506 \u2026        \u2506 \u2026      \u2506 \u2026       \u2502\n        \u2502 3989 \u2506 2       \u2506 4        \u2506 4      \u2506 34.93   \u2502\n        \u2502 3991 \u2506 2       \u2506 1        \u2506 0      \u2506 0.0     \u2502\n        \u2502 3992 \u2506 2       \u2506 3        \u2506 3      \u2506 27.96   \u2502\n        \u2502 3994 \u2506 2       \u2506 2        \u2506 1      \u2506 17.22   \u2502\n        \u2502 3998 \u2506 2       \u2506 3        \u2506 0      \u2506 0.0     \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n        &gt;&gt;&gt; experiment = tt.Experiment(\n        ...     sessions_per_user=tt.Mean(\"sessions\"),\n        ...     orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\"),\n        ...     orders_per_user=tt.Mean(\"orders\"),\n        ...     revenue_per_user=tt.Mean(\"revenue\"),\n        ... )\n\n        &gt;&gt;&gt; # Results without correction.\n        &gt;&gt;&gt; results = experiment.analyze(data, control=0, all_variants=True)\n        &gt;&gt;&gt; results\n        variants             metric control treatment rel_effect_size rel_effect_size_ci  pvalue\n          (0, 1)  sessions_per_user    2.00      1.98          -0.66%      [-3.7%, 2.5%]   0.674\n          (0, 1) orders_per_session   0.266     0.289            8.8%      [-0.89%, 19%]  0.0762\n          (0, 1)    orders_per_user   0.530     0.573            8.0%       [-2.0%, 19%]   0.118\n          (0, 1)   revenue_per_user    5.24      5.99             14%        [2.1%, 28%]  0.0211\n          (0, 2)  sessions_per_user    2.00      2.02           0.98%      [-2.1%, 4.1%]   0.532\n          (0, 2) orders_per_session   0.266     0.295             11%        [1.2%, 22%]  0.0273\n          (0, 2)    orders_per_user   0.530     0.594             12%        [1.7%, 23%]  0.0213\n          (0, 2)   revenue_per_user    5.24      6.25             19%        [6.6%, 33%] 0.00218\n\n        &gt;&gt;&gt; # Success metrics.\n        &gt;&gt;&gt; metrics = {\"orders_per_user\", \"revenue_per_user\"}\n\n        &gt;&gt;&gt; # Hochberg's step-up procedure with \u0160id\u00e1k correction,\n        &gt;&gt;&gt; # assuming non-negative correlation between hypotheses.\n        &gt;&gt;&gt; adjusted_results_fwer = tt.adjust_fwer(results, metrics)\n        &gt;&gt;&gt; adjusted_results_fwer\n        comparison           metric control treatment rel_effect_size  pvalue pvalue_adj\n            (0, 1)  orders_per_user   0.530     0.573            8.0%   0.118      0.118\n            (0, 1) revenue_per_user    5.24      5.99             14%  0.0211     0.0422\n            (0, 2)  orders_per_user   0.530     0.594             12%  0.0213     0.0422\n            (0, 2) revenue_per_user    5.24      6.25             19% 0.00218    0.00869\n\n        &gt;&gt;&gt; # The adjusted confidence level alpha.\n        &gt;&gt;&gt; adjusted_results_fwer.with_keys((\n        ...     \"comparison\",\n        ...     \"metric\",\n        ...     \"control\",\n        ...     \"treatment\",\n        ...     \"rel_effect_size\",\n        ...     \"pvalue\",\n        ...     \"alpha_adj\",\n        ... ))\n        comparison           metric control treatment rel_effect_size  pvalue alpha_adj\n            (0, 1)  orders_per_user   0.530     0.573            8.0%   0.118    0.0500\n            (0, 1) revenue_per_user    5.24      5.99             14%  0.0211    0.0253\n            (0, 2)  orders_per_user   0.530     0.594             12%  0.0213    0.0253\n            (0, 2) revenue_per_user    5.24      6.25             19% 0.00218    0.0253\n\n        &gt;&gt;&gt; # Holm's step-down procedure with Bonferroni correction,\n        &gt;&gt;&gt; # assuming arbitrary dependence between hypotheses.\n        &gt;&gt;&gt; tt.adjust_fwer(\n        ...     results,\n        ...     metrics,\n        ...     arbitrary_dependence=True,\n        ...     method=\"bonferroni\",\n        ... )\n        comparison           metric control treatment rel_effect_size  pvalue pvalue_adj\n            (0, 1)  orders_per_user   0.530     0.573            8.0%   0.118      0.118\n            (0, 1) revenue_per_user    5.24      5.99             14%  0.0211     0.0634\n            (0, 2)  orders_per_user   0.530     0.594             12%  0.0213     0.0634\n            (0, 2) revenue_per_user    5.24      6.25             19% 0.00218    0.00872\n\n        ```\n    \"\"\"  # noqa: E501, RUF002\n    alpha = (\n        tea_tasting.utils.auto_check(alpha, \"alpha\")\n        if alpha is not None\n        else tea_tasting.config.get_config(\"alpha\")\n    )\n    method = tea_tasting.utils.check_scalar(\n        method, \"method\", typ=str, in_={\"sidak\", \"bonferroni\"})\n    arbitrary_dependence = tea_tasting.utils.check_scalar(\n        arbitrary_dependence, \"arbitrary_dependence\", typ=bool)\n\n    # results and metric_results refer to the same dicts.\n    results, metric_results = _copy_results(experiment_results, metrics)\n    method_cls = _Sidak if method == \"sidak\" else _Bonferroni\n    method_ = method_cls(alpha=alpha, m=len(metric_results))  # type: ignore\n    procedure = _holm_stepdown if arbitrary_dependence else _hochberg_stepup\n    # In-place update.\n    procedure(metric_results, method_.adjust)\n\n    return MultipleComparisonsResults(results)\n</code></pre>"},{"location":"api/utils/","title":"Utilities","text":""},{"location":"api/utils/#tea_tasting.utils","title":"<code>tea_tasting.utils</code>","text":"<p>Useful functions and classes.</p>"},{"location":"api/utils/#tea_tasting.utils.check_scalar","title":"<code>check_scalar(value, name='value', *, typ=None, ge=None, gt=None, le=None, lt=None, ne=None, in_=None)</code>","text":"<p>Check if a scalar parameter meets specified type and value constraints.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>R</code> <p>Parameter value.</p> required <code>name</code> <code>str</code> <p>Parameter name.</p> <code>'value'</code> <code>typ</code> <code>object</code> <p>Acceptable data types.</p> <code>None</code> <code>ge</code> <code>object</code> <p>If not <code>None</code>, check that parameter value is greater than or equal to <code>ge</code>.</p> <code>None</code> <code>gt</code> <code>object</code> <p>If not <code>None</code>, check that parameter value is greater than <code>gt</code>.</p> <code>None</code> <code>le</code> <code>object</code> <p>If not <code>None</code>, check that parameter value is less than or equal to <code>le</code>.</p> <code>None</code> <code>lt</code> <code>object</code> <p>If not <code>None</code>, check that parameter value is less than <code>lt</code>.</p> <code>None</code> <code>ne</code> <code>object</code> <p>If not <code>None</code>, check that parameter value is not equal to <code>ne</code>.</p> <code>None</code> <code>in_</code> <code>object</code> <p>If not <code>None</code>, check that parameter value is in <code>in_</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>R</code> <p>Parameter value.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def check_scalar(  # noqa: PLR0913\n    value: R,\n    name: str = \"value\",\n    *,\n    typ: object = None,\n    ge: object = None,\n    gt: object = None,\n    le: object = None,\n    lt: object = None,\n    ne: object = None,\n    in_: object = None,\n) -&gt; R:\n    \"\"\"Check if a scalar parameter meets specified type and value constraints.\n\n    Args:\n        value: Parameter value.\n        name: Parameter name.\n        typ: Acceptable data types.\n        ge: If not `None`, check that parameter value is greater than\n            or equal to `ge`.\n        gt: If not `None`, check that parameter value is greater than `gt`.\n        le: If not `None`, check that parameter value is less than or equal to `le`.\n        lt: If not `None`, check that parameter value is less than `lt`.\n        ne: If not `None`, check that parameter value is not equal to `ne`.\n        in_: If not `None`, check that parameter value is in `in_`.\n\n    Returns:\n        Parameter value.\n    \"\"\"\n    if typ is not None and not isinstance(value, typ):  # type: ignore\n        raise TypeError(f\"{name} must be an instance of {typ}.\")\n    if ge is not None and value &lt; ge:\n        raise ValueError(f\"{name} == {value}, must be &gt;= {ge}.\")\n    if gt is not None and value &lt;= gt:\n        raise ValueError(f\"{name} == {value}, must be &gt; {gt}.\")\n    if le is not None and value &gt; le:\n        raise ValueError(f\"{name} == {value}, must be &lt;= {le}.\")\n    if lt is not None and value &gt;= lt:\n        raise ValueError(f\"{name} == {value}, must be &lt; {lt}.\")\n    if ne is not None and value == ne:\n        raise ValueError(f\"{name} == {value}, must be != {ne}.\")\n    if in_ is not None and value not in in_:\n        raise ValueError(f\"{name} == {value}, must be in {in_}.\")\n    return value\n</code></pre>"},{"location":"api/utils/#tea_tasting.utils.auto_check","title":"<code>auto_check(value, name)</code>","text":"<p>Automatically check a parameter's type and value based on its name.</p> <p>The following parameter names are supported: <code>\"alpha\"</code>, <code>\"alternative\"</code>, <code>\"confidence_level\"</code>, <code>\"correction\"</code>, <code>\"equal_var\"</code>, <code>\"n_obs\"</code>, <code>\"n_resamples\"</code>, <code>\"power\"</code>, <code>\"ratio\"</code>, <code>\"use_t\"</code>.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>R</code> <p>Parameter value.</p> required <code>name</code> <code>str</code> <p>Parameter name.</p> required <p>Returns:</p> Type Description <code>R</code> <p>Parameter value.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def auto_check(value: R, name: str) -&gt; R:  # noqa: C901, PLR0912\n    \"\"\"Automatically check a parameter's type and value based on its name.\n\n    The following parameter names are supported: `\"alpha\"`, `\"alternative\"`,\n    `\"confidence_level\"`, `\"correction\"`, `\"equal_var\"`, `\"n_obs\"`,\n    `\"n_resamples\"`, `\"power\"`, `\"ratio\"`, `\"use_t\"`.\n\n    Args:\n        value: Parameter value.\n        name: Parameter name.\n\n    Returns:\n        Parameter value.\n    \"\"\"\n    if name == \"alpha\":\n        check_scalar(value, name, typ=float, gt=0, lt=1)\n    if name == \"alternative\":\n        check_scalar(value, name, typ=str, in_={\"two-sided\", \"greater\", \"less\"})\n    elif name == \"confidence_level\":\n        check_scalar(value, name, typ=float, gt=0, lt=1)\n    elif name == \"correction\":\n        check_scalar(value, name, typ=bool)\n    elif name == \"equal_var\":\n        check_scalar(value, name, typ=bool)\n    elif name == \"n_obs\":\n        check_scalar(value, name, typ=int | Sequence | None)\n        if isinstance(value, int):\n            check_scalar(value, name, gt=1)\n        if isinstance(value, Sequence):\n            for val in value:\n                check_scalar(val, name, typ=int, gt=1)\n    elif name == \"n_resamples\":\n        check_scalar(value, name, typ=int, gt=0)\n    elif name == \"power\":\n        check_scalar(value, name, typ=float, gt=0, lt=1)\n    elif name == \"ratio\":\n        check_scalar(value, name, typ=float | int, gt=0)\n    elif name == \"use_t\":\n        check_scalar(value, name, typ=bool)\n    return value\n</code></pre>"},{"location":"api/utils/#tea_tasting.utils.format_num","title":"<code>format_num(val, sig=3, *, pct=False, nan='-', inf='\u221e', fixed_point_range=(0.001, 10000000), thousands_sep=None, decimal_point=None)</code>","text":"<p>Format a number according to specified formatting rules.</p> <p>Parameters:</p> Name Type Description Default <code>val</code> <code>float | int | None</code> <p>Number to format.</p> required <code>sig</code> <code>int</code> <p>Number of significant digits.</p> <code>3</code> <code>pct</code> <code>bool</code> <p>If <code>True</code>, format as a percentage.</p> <code>False</code> <code>nan</code> <code>str</code> <p>Replacement for <code>None</code> and <code>nan</code> values.</p> <code>'-'</code> <code>inf</code> <code>str</code> <p>Replacement for infinite values.</p> <code>'\u221e'</code> <code>fixed_point_range</code> <code>tuple[float | None, float | None]</code> <p>The range within which the number is formatted as fixed point. Number outside of the range is formatted as exponential. <code>None</code> means no boundary.</p> <code>(0.001, 10000000)</code> <code>thousands_sep</code> <code>str | None</code> <p>Thousands separator. If <code>None</code>, the value from locales is used.</p> <code>None</code> <code>decimal_point</code> <code>str | None</code> <p>Decimal point symbol. If <code>None</code>, the value from locales is used.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>Formatted number.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def format_num(\n    val: float | int | None,\n    sig: int = 3,\n    *,\n    pct: bool = False,\n    nan: str = \"-\",\n    inf: str = \"\u221e\",\n    fixed_point_range: tuple[float | None, float | None] = (0.001, 10_000_000),\n    thousands_sep: str | None = None,\n    decimal_point: str | None = None,\n) -&gt; str:\n    \"\"\"Format a number according to specified formatting rules.\n\n    Args:\n        val: Number to format.\n        sig: Number of significant digits.\n        pct: If `True`, format as a percentage.\n        nan: Replacement for `None` and `nan` values.\n        inf: Replacement for infinite values.\n        fixed_point_range: The range within which the number is formatted\n            as fixed point.\n            Number outside of the range is formatted as exponential.\n            `None` means no boundary.\n        thousands_sep: Thousands separator. If `None`, the value from locales is used.\n        decimal_point: Decimal point symbol. If `None`, the value from locales is used.\n\n    Returns:\n        Formatted number.\n    \"\"\"\n    if val is None or math.isnan(val):\n        return nan\n\n    if math.isinf(val):\n        return inf if val &gt; 0 else \"-\" + inf\n\n    if pct:\n        val = val * 100\n\n    if (\n        (fixed_point_range[0] is not None and abs(val) &lt; fixed_point_range[0]) or\n        (fixed_point_range[1] is not None and abs(val) &gt;= fixed_point_range[1])\n    ):\n        precision = max(0, sig - 1)\n        typ = \"e\" if val != 0 else \"f\"\n    else:\n        precision = max(0, sig - 1 - math.floor(math.log10(abs(val))))\n        val = round(val, precision)\n        # Repeat in order to format 99.999 as \"100\", not \"100.0\".\n        precision = max(0, sig - 1 - math.floor(math.log10(abs(val))))\n        typ = \"f\"\n\n    result = format(val, f\"_.{precision}{typ}\")\n\n    if thousands_sep is None:\n        thousands_sep = locale.localeconv().get(\"thousands_sep\", \"_\")  # type: ignore\n    if thousands_sep != \"_\":\n        result = result.replace(\"_\", thousands_sep)\n\n    if decimal_point is None:\n        decimal_point = locale.localeconv().get(\"decimal_point\", \".\")  # type: ignore\n    if decimal_point != \".\":\n        result = result.replace(\".\", decimal_point)\n\n    if pct:\n        return result + \"%\"\n\n    return result\n</code></pre>"},{"location":"api/utils/#tea_tasting.utils.get_and_format_num","title":"<code>get_and_format_num(data, key)</code>","text":"<p>Get and format dictionary value.</p> <p>Formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict[str, object]</code> <p>Dictionary.</p> required <code>key</code> <code>str</code> <p>Key.</p> required <p>Returns:</p> Type Description <code>str</code> <p>Formatted value.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def get_and_format_num(data: dict[str, object], key: str) -&gt; str:\n    \"\"\"Get and format dictionary value.\n\n    Formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        data: Dictionary.\n        key: Key.\n\n    Returns:\n        Formatted value.\n    \"\"\"\n    if key.endswith(\"_ci\"):\n        ci_lower = get_and_format_num(data, key + \"_lower\")\n        ci_upper = get_and_format_num(data, key + \"_upper\")\n        return f\"[{ci_lower}, {ci_upper}]\"\n\n    val = data.get(key)\n    if not isinstance(val, float | int | None):\n        return str(val)\n\n    sig, pct = (2, True) if key.startswith(\"rel_\") or key == \"power\" else (3, False)\n    return format_num(val, sig=sig, pct=pct)\n</code></pre>"},{"location":"api/utils/#tea_tasting.utils.DictsReprMixin","title":"<code>DictsReprMixin</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Representation and conversion of a sequence of dictionaries.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul>"},{"location":"api/utils/#tea_tasting.utils.DictsReprMixin.to_dicts","title":"<code>to_dicts()</code>  <code>abstractmethod</code>","text":"<p>Convert the object to a sequence of dictionaries.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@abc.abstractmethod\ndef to_dicts(self) -&gt; Sequence[dict[str, object]]:\n    \"\"\"Convert the object to a sequence of dictionaries.\"\"\"\n</code></pre>"},{"location":"api/utils/#tea_tasting.utils.DictsReprMixin.to_arrow","title":"<code>to_arrow()</code>","text":"<p>Convert the object to a PyArrow Table.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_arrow(self) -&gt; pa.Table:\n    \"\"\"Convert the object to a PyArrow Table.\"\"\"\n    return pa.Table.from_pylist(self.to_dicts())\n</code></pre>"},{"location":"api/utils/#tea_tasting.utils.DictsReprMixin.to_pandas","title":"<code>to_pandas()</code>","text":"<p>Convert the object to a Pandas DataFrame.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_pandas(self) -&gt; pd.DataFrame:\n    \"\"\"Convert the object to a Pandas DataFrame.\"\"\"\n    import pandas as pd  # noqa: PLC0415\n    return pd.DataFrame.from_records(self.to_dicts())\n</code></pre>"},{"location":"api/utils/#tea_tasting.utils.DictsReprMixin.to_polars","title":"<code>to_polars()</code>","text":"<p>Convert the object to a Polars DataFrame.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_polars(self) -&gt; pl.DataFrame:\n    \"\"\"Convert the object to a Polars DataFrame.\"\"\"\n    import polars as pl  # noqa: PLC0415\n    return pl.from_dicts(self.to_dicts())\n</code></pre>"},{"location":"api/utils/#tea_tasting.utils.DictsReprMixin.to_pretty_dicts","title":"<code>to_pretty_dicts(keys=None, formatter=get_and_format_num, *, max_rows=None)</code>","text":"<p>Convert the object to a list of dictionaries with formatted values.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[dict[str, str]]</code> <p>List of dictionaries with formatted values.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_pretty_dicts(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n) -&gt; list[dict[str, str]]:\n    \"\"\"Convert the object to a list of dictionaries with formatted values.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n\n    Returns:\n        List of dictionaries with formatted values.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    dicts = self.to_dicts()\n    if max_rows &lt;= 0 or len(dicts) &lt;= max_rows:\n        return [{key: formatter(data, key) for key in keys} for data in dicts]\n\n    bottom = max_rows // 2\n    top = max_rows - bottom\n    return (\n        [{key: formatter(data, key) for key in keys} for data in dicts[:top]] +\n        [dict.fromkeys(keys, \"\u2026\")] +\n        [{key: formatter(data, key) for key in keys} for data in dicts[-bottom:]]\n    )\n</code></pre>"},{"location":"api/utils/#tea_tasting.utils.DictsReprMixin.to_string","title":"<code>to_string(keys=None, formatter=get_and_format_num, *, max_rows=None)</code>","text":"<p>Convert the object to a string.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>A table with results rendered as string.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_string(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n) -&gt; str:\n    \"\"\"Convert the object to a string.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n\n    Returns:\n        A table with results rendered as string.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    pretty_dicts = self.to_pretty_dicts(keys, formatter, max_rows=max_rows)\n    widths = {key: len(key) for key in keys}\n    for pretty_dict in pretty_dicts:\n        for key in keys:\n            widths[key] = max(widths[key], len(pretty_dict[key]))\n\n    sep = \" \"\n    rows = [sep.join(key.rjust(widths[key]) for key in keys)]\n    rows.extend(\n        sep.join(pretty_dict[key].rjust(widths[key]) for key in keys)\n        for pretty_dict in pretty_dicts\n    )\n    return \"\\n\".join(rows)\n</code></pre>"},{"location":"api/utils/#tea_tasting.utils.DictsReprMixin.to_html","title":"<code>to_html(keys=None, formatter=get_and_format_num, *, max_rows=None, indent=None)</code>","text":"<p>Convert the object to HTML.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <code>indent</code> <code>str | None</code> <p>Whitespace to insert for each indentation level. If <code>None</code>, do not indent.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>A table with results rendered as HTML.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_html(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n    indent: str | None = None,\n) -&gt; str:\n    \"\"\"Convert the object to HTML.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n        indent: Whitespace to insert for each indentation level. If `None`,\n            do not indent.\n\n    Returns:\n        A table with results rendered as HTML.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    table = ET.Element(\n        \"table\",\n        {\"class\": \"dataframe\", \"style\": \"text-align: right;\"},\n    )\n    thead = ET.SubElement(table, \"thead\")\n    thead_tr = ET.SubElement(thead, \"tr\")\n    for key in keys:\n        th = ET.SubElement(thead_tr, \"th\")\n        th.text = key\n    tbody = ET.SubElement(table, \"tbody\")\n    for pretty_dict in self.to_pretty_dicts(keys, formatter, max_rows=max_rows):\n        tr = ET.SubElement(tbody, \"tr\")\n        for key in keys:\n            td = ET.SubElement(tr, \"td\")\n            td.text = pretty_dict[key]\n    if indent is not None:\n        ET.indent(table, space=indent)\n    return ET.tostring(table, encoding=\"unicode\", method=\"html\")\n</code></pre>"},{"location":"api/utils/#tea_tasting.utils.DictsReprMixin.with_defaults","title":"<code>with_defaults(*, keys=None, max_rows=None)</code>","text":"<p>Copies the object and sets the new default parameters.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>New default <code>keys</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> <code>None</code> <code>max_rows</code> <code>int | None</code> <p>New default <code>max_rows</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default keys.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_defaults(\n    self: DictsReprMixinT,\n    *,\n    keys: Sequence[str] | None = None,\n    max_rows: int | None = None,\n) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default parameters.\n\n    Args:\n        keys: New default `keys` for the methods `to_pretty_dicts`, `to_string`,\n            and `to_html`.\n        max_rows: New default `max_rows` for the methods `to_pretty_dicts`,\n            `to_string`, and `to_html`.\n\n    Returns:\n        A copy of the object with the new default keys.\n    \"\"\"\n    new_instance = self.__class__.__new__(self.__class__)\n    new_instance.__dict__.update(self.__dict__)\n    new_instance._cache = None\n    if keys is not None:\n        new_instance.default_keys = keys\n    if max_rows is not None:\n        new_instance.default_max_rows = max_rows\n    return new_instance\n</code></pre>"},{"location":"api/utils/#tea_tasting.utils.DictsReprMixin.with_keys","title":"<code>with_keys(keys)</code>","text":"<p>Copies the object and sets the new default <code>keys</code>.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str]</code> <p>New default <code>keys</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> required <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default <code>keys</code>.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_keys(self: DictsReprMixinT, keys: Sequence[str]) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default `keys`.\n\n    Args:\n        keys: New default `keys` for the methods `to_pretty_dicts`, `to_string`,\n            and `to_html`.\n\n    Returns:\n        A copy of the object with the new default `keys`.\n    \"\"\"\n    return self.with_defaults(keys=keys)\n</code></pre>"},{"location":"api/utils/#tea_tasting.utils.DictsReprMixin.with_max_rows","title":"<code>with_max_rows(max_rows)</code>","text":"<p>Copies the object and sets the new default <code>max_rows</code>.</p> <p>Parameters:</p> Name Type Description Default <code>max_rows</code> <code>int</code> <p>New default <code>max_rows</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> required <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default <code>max_rows</code>.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_max_rows(self: DictsReprMixinT, max_rows: int) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default `max_rows`.\n\n    Args:\n        max_rows: New default `max_rows` for the methods `to_pretty_dicts`,\n            `to_string`, and `to_html`.\n\n    Returns:\n        A copy of the object with the new default `max_rows`.\n    \"\"\"\n    return self.with_defaults(max_rows=max_rows)\n</code></pre>"},{"location":"api/utils/#tea_tasting.utils.ReprMixin","title":"<code>ReprMixin</code>","text":"<p>A mixin class that provides a method for generating a string representation.</p> <p>Representation string is generated based on parameters values saved in attributes.</p>"},{"location":"api/utils/#tea_tasting.utils.div","title":"<code>div(numer, denom, fill_zero_div='auto')</code>","text":"<p>Perform division, providing specified results for cases of division by zero.</p> <p>Parameters:</p> Name Type Description Default <code>numer</code> <code>float | int</code> <p>Numerator.</p> required <code>denom</code> <code>float | int</code> <p>Denominator.</p> required <code>fill_zero_div</code> <code>float | int | Literal['auto']</code> <p>Result if denominator is zero.</p> <code>'auto'</code> <p>Returns:</p> Type Description <code>float | int</code> <p>Result of the division.</p> <p>If <code>fill_zero_div</code> is equal <code>\"auto\"</code>, return:</p> <ul> <li><code>inf</code> if numerator is greater than <code>0</code>,</li> <li><code>nan</code> if numerator is equal to or less than <code>0</code>.</li> </ul> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def div(\n    numer: float | int,\n    denom: float | int,\n    fill_zero_div: float | int | Literal[\"auto\"] = \"auto\",\n) -&gt; float |int:\n    \"\"\"Perform division, providing specified results for cases of division by zero.\n\n    Args:\n        numer: Numerator.\n        denom: Denominator.\n        fill_zero_div: Result if denominator is zero.\n\n    Returns:\n        Result of the division.\n\n    If `fill_zero_div` is equal `\"auto\"`, return:\n\n    - `inf` if numerator is greater than `0`,\n    - `nan` if numerator is equal to or less than `0`.\n    \"\"\"\n    if denom != 0:\n        return numer / denom\n    if fill_zero_div != \"auto\":\n        return fill_zero_div\n    return float(\"inf\") if numer &gt; 0 else float(\"nan\")\n</code></pre>"},{"location":"api/utils/#tea_tasting.utils.Float","title":"<code>Float</code>","text":"<p>               Bases: <code>_NumericBase</code>, <code>float</code></p> <p>Float that gracefully handles division by zero errors.</p>"},{"location":"api/utils/#tea_tasting.utils.Int","title":"<code>Int</code>","text":"<p>               Bases: <code>_NumericBase</code>, <code>int</code></p> <p>Integer that gracefully handles division by zero errors.</p>"},{"location":"api/utils/#tea_tasting.utils.numeric","title":"<code>numeric(value, fill_zero_div='auto')</code>","text":"<p>Convert an object to numeric that gracefully handles division by zero errors.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>object</code> <p>Object to convert.</p> required <code>fill_zero_div</code> <code>float | int | Literal['auto']</code> <p>Result if denominator is zero.</p> <code>'auto'</code> <p>If <code>fill_zero_div</code> is equal <code>\"auto\"</code>, division by zero will return:</p> <ul> <li><code>inf</code> if numerator is greater than <code>0</code>,</li> <li><code>nan</code> if numerator is equal to or less than <code>0</code>.</li> </ul> <p>Returns:</p> Type Description <code>Numeric</code> <p>Float or integer that gracefully handles division by zero errors.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def numeric(\n    value: object,\n    fill_zero_div: float | int | Literal[\"auto\"] = \"auto\",\n) -&gt; Numeric:\n    \"\"\"Convert an object to numeric that gracefully handles division by zero errors.\n\n    Args:\n        value: Object to convert.\n        fill_zero_div: Result if denominator is zero.\n\n    If `fill_zero_div` is equal `\"auto\"`, division by zero will return:\n\n    - `inf` if numerator is greater than `0`,\n    - `nan` if numerator is equal to or less than `0`.\n\n    Returns:\n        Float or integer that gracefully handles division by zero errors.\n    \"\"\"\n    if isinstance(value, int):\n        return Int(value, fill_zero_div)\n    if isinstance(value, float):\n        return Float(value, fill_zero_div)\n    try:\n        return Int(value, fill_zero_div)\n    except ValueError:\n        return Float(value, fill_zero_div)\n</code></pre>"},{"location":"api/metrics/","title":"Metrics","text":""},{"location":"api/metrics/#tea_tasting.metrics","title":"<code>tea_tasting.metrics</code>","text":"<p>This module provides built-in metrics used to analyze experimental data.</p> <p>All metric classes can be imported from <code>tea_tasting.metrics</code> module. For convenience, the API reference is provided by submodules of <code>tea_tasting.metrics</code>:</p> <ul> <li><code>tea_tasting.metrics.base</code>: Base classes for metrics.</li> <li><code>tea_tasting.metrics.mean</code>: Metrics for the analysis of means.</li> <li><code>tea_tasting.metrics.proportion</code>: Metrics for the analysis of proportions.</li> <li><code>tea_tasting.metrics.resampling</code>: Metrics analyzed using resampling methods.</li> </ul>"},{"location":"api/metrics/base/","title":"Base","text":""},{"location":"api/metrics/base/#tea_tasting.metrics.base","title":"<code>tea_tasting.metrics.base</code>","text":"<p>Base classes for metrics.</p>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.AggrCols","title":"<code>AggrCols</code>","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Columns to be aggregated for a metric analysis.</p> <p>Attributes:</p> Name Type Description <code>has_count</code> <code>bool</code> <p>If <code>True</code>, include the sample size.</p> <code>mean_cols</code> <code>Sequence[str]</code> <p>Column names for calculation of sample means.</p> <code>var_cols</code> <code>Sequence[str]</code> <p>Column names for calculation of sample variances.</p> <code>cov_cols</code> <code>Sequence[tuple[str, str]]</code> <p>Pairs of column names for calculation of sample covariances.</p>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricBase","title":"<code>MetricBase</code>","text":"<p>               Bases: <code>ABC</code>, <code>Generic[R]</code>, <code>ReprMixin</code></p> <p>Base class for metrics.</p>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricBase.analyze","title":"<code>analyze(data, control, treatment, variant)</code>  <code>abstractmethod</code>","text":"<p>Analyze a metric in an experiment.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IntoFrame | Table</code> <p>Experimental data.</p> required <code>control</code> <code>object</code> <p>Control variant.</p> required <code>treatment</code> <code>object</code> <p>Treatment variant.</p> required <code>variant</code> <code>str</code> <p>Variant column name.</p> required <p>Returns:</p> Type Description <code>R</code> <p>Analysis result.</p> Source code in <code>src/tea_tasting/metrics/base.py</code> <pre><code>@abc.abstractmethod\ndef analyze(\n    self,\n    data: narwhals.typing.IntoFrame | ibis.expr.types.Table,\n    control: object,\n    treatment: object,\n    variant: str,\n) -&gt; R:\n    \"\"\"Analyze a metric in an experiment.\n\n    Args:\n        data: Experimental data.\n        control: Control variant.\n        treatment: Treatment variant.\n        variant: Variant column name.\n\n    Returns:\n        Analysis result.\n    \"\"\"\n</code></pre>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricBaseAggregated","title":"<code>MetricBaseAggregated</code>","text":"<p>               Bases: <code>MetricBase[R]</code>, <code>_HasAggrCols</code></p> <p>Base class for metrics, which are analyzed using aggregated statistics.</p>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricBaseAggregated.aggr_cols","title":"<code>aggr_cols</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Columns to be aggregated for an analysis.</p>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricBaseAggregated.analyze","title":"<code>analyze(data, control, treatment, variant=None)</code>","text":"<p>Analyze a metric in an experiment.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IntoFrame | Table | dict[object, Aggregates]</code> <p>Experimental data.</p> required <code>control</code> <code>object</code> <p>Control variant.</p> required <code>treatment</code> <code>object</code> <p>Treatment variant.</p> required <code>variant</code> <code>str | None</code> <p>Variant column name.</p> <code>None</code> <p>Returns:</p> Type Description <code>R</code> <p>Analysis result.</p> Source code in <code>src/tea_tasting/metrics/base.py</code> <pre><code>def analyze(\n    self,\n    data: narwhals.typing.IntoFrame | ibis.expr.types.Table | dict[\n        object, tea_tasting.aggr.Aggregates],\n    control: object,\n    treatment: object,\n    variant: str | None = None,\n) -&gt; R:\n    \"\"\"Analyze a metric in an experiment.\n\n    Args:\n        data: Experimental data.\n        control: Control variant.\n        treatment: Treatment variant.\n        variant: Variant column name.\n\n    Returns:\n        Analysis result.\n    \"\"\"\n    tea_tasting.utils.check_scalar(variant, \"variant\", typ=str | None)\n    aggr = aggregate_by_variants(\n        data,\n        aggr_cols=self.aggr_cols,\n        variant=variant,\n    )\n    return self.analyze_aggregates(\n        control=aggr[control],\n        treatment=aggr[treatment],\n    )\n</code></pre>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricBaseAggregated.analyze_aggregates","title":"<code>analyze_aggregates(control, treatment)</code>  <code>abstractmethod</code>","text":"<p>Analyze metric in an experiment using aggregated statistics.</p> <p>Parameters:</p> Name Type Description Default <code>control</code> <code>Aggregates</code> <p>Control data.</p> required <code>treatment</code> <code>Aggregates</code> <p>Treatment data.</p> required <p>Returns:</p> Type Description <code>R</code> <p>Analysis result.</p> Source code in <code>src/tea_tasting/metrics/base.py</code> <pre><code>@abc.abstractmethod\ndef analyze_aggregates(\n    self,\n    control: tea_tasting.aggr.Aggregates,\n    treatment: tea_tasting.aggr.Aggregates,\n) -&gt; R:\n    \"\"\"Analyze metric in an experiment using aggregated statistics.\n\n    Args:\n        control: Control data.\n        treatment: Treatment data.\n\n    Returns:\n        Analysis result.\n    \"\"\"\n</code></pre>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricBaseGranular","title":"<code>MetricBaseGranular</code>","text":"<p>               Bases: <code>MetricBase[R]</code>, <code>_HasCols</code></p> <p>Base class for metrics, which are analyzed using granular data.</p>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricBaseGranular.cols","title":"<code>cols</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Columns to be fetched for an analysis.</p>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricBaseGranular.analyze","title":"<code>analyze(data, control, treatment, variant=None)</code>","text":"<p>Analyze a metric in an experiment.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IntoFrame | Table | dict[object, Table]</code> <p>Experimental data.</p> required <code>control</code> <code>object</code> <p>Control variant.</p> required <code>treatment</code> <code>object</code> <p>Treatment variant.</p> required <code>variant</code> <code>str | None</code> <p>Variant column name.</p> <code>None</code> <p>Returns:</p> Type Description <code>R</code> <p>Analysis result.</p> Source code in <code>src/tea_tasting/metrics/base.py</code> <pre><code>def analyze(\n    self,\n    data: (\n        narwhals.typing.IntoFrame |\n        ibis.expr.types.Table |\n        dict[object, pa.Table]\n    ),\n    control: object,\n    treatment: object,\n    variant: str | None = None,\n) -&gt; R:\n    \"\"\"Analyze a metric in an experiment.\n\n    Args:\n        data: Experimental data.\n        control: Control variant.\n        treatment: Treatment variant.\n        variant: Variant column name.\n\n    Returns:\n        Analysis result.\n    \"\"\"\n    tea_tasting.utils.check_scalar(variant, \"variant\", typ=str | None)\n    dfs = read_granular(\n        data,\n        cols=self.cols,\n        variant=variant,\n    )\n    return self.analyze_granular(\n        control=dfs[control],\n        treatment=dfs[treatment],\n    )\n</code></pre>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricBaseGranular.analyze_granular","title":"<code>analyze_granular(control, treatment)</code>  <code>abstractmethod</code>","text":"<p>Analyze metric in an experiment using granular data.</p> <p>Parameters:</p> Name Type Description Default <code>control</code> <code>Table</code> <p>Control data.</p> required <code>treatment</code> <code>Table</code> <p>Treatment data.</p> required <p>Returns:</p> Type Description <code>R</code> <p>Analysis result.</p> Source code in <code>src/tea_tasting/metrics/base.py</code> <pre><code>@abc.abstractmethod\ndef analyze_granular(\n    self,\n    control: pa.Table,\n    treatment: pa.Table,\n) -&gt; R:\n    \"\"\"Analyze metric in an experiment using granular data.\n\n    Args:\n        control: Control data.\n        treatment: Treatment data.\n\n    Returns:\n        Analysis result.\n    \"\"\"\n</code></pre>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricPowerResults","title":"<code>MetricPowerResults</code>","text":"<p>               Bases: <code>DictsReprMixin</code>, <code>UserList[P]</code></p> <p>Power analysis results.</p>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricPowerResults.to_arrow","title":"<code>to_arrow()</code>","text":"<p>Convert the object to a PyArrow Table.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_arrow(self) -&gt; pa.Table:\n    \"\"\"Convert the object to a PyArrow Table.\"\"\"\n    return pa.Table.from_pylist(self.to_dicts())\n</code></pre>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricPowerResults.to_dicts","title":"<code>to_dicts()</code>","text":"<p>\"Convert the results to a sequence of dictionaries.</p> Source code in <code>src/tea_tasting/metrics/base.py</code> <pre><code>@tea_tasting.utils._cache_method\ndef to_dicts(self) -&gt; tuple[dict[str, object], ...]:\n    \"\"\"\"Convert the results to a sequence of dictionaries.\"\"\"\n    return tuple((v if isinstance(v, dict) else v._asdict()) for v in self)\n</code></pre>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricPowerResults.to_html","title":"<code>to_html(keys=None, formatter=get_and_format_num, *, max_rows=None, indent=None)</code>","text":"<p>Convert the object to HTML.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <code>indent</code> <code>str | None</code> <p>Whitespace to insert for each indentation level. If <code>None</code>, do not indent.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>A table with results rendered as HTML.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_html(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n    indent: str | None = None,\n) -&gt; str:\n    \"\"\"Convert the object to HTML.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n        indent: Whitespace to insert for each indentation level. If `None`,\n            do not indent.\n\n    Returns:\n        A table with results rendered as HTML.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    table = ET.Element(\n        \"table\",\n        {\"class\": \"dataframe\", \"style\": \"text-align: right;\"},\n    )\n    thead = ET.SubElement(table, \"thead\")\n    thead_tr = ET.SubElement(thead, \"tr\")\n    for key in keys:\n        th = ET.SubElement(thead_tr, \"th\")\n        th.text = key\n    tbody = ET.SubElement(table, \"tbody\")\n    for pretty_dict in self.to_pretty_dicts(keys, formatter, max_rows=max_rows):\n        tr = ET.SubElement(tbody, \"tr\")\n        for key in keys:\n            td = ET.SubElement(tr, \"td\")\n            td.text = pretty_dict[key]\n    if indent is not None:\n        ET.indent(table, space=indent)\n    return ET.tostring(table, encoding=\"unicode\", method=\"html\")\n</code></pre>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricPowerResults.to_pandas","title":"<code>to_pandas()</code>","text":"<p>Convert the object to a Pandas DataFrame.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_pandas(self) -&gt; pd.DataFrame:\n    \"\"\"Convert the object to a Pandas DataFrame.\"\"\"\n    import pandas as pd  # noqa: PLC0415\n    return pd.DataFrame.from_records(self.to_dicts())\n</code></pre>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricPowerResults.to_polars","title":"<code>to_polars()</code>","text":"<p>Convert the object to a Polars DataFrame.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>@_cache_method\ndef to_polars(self) -&gt; pl.DataFrame:\n    \"\"\"Convert the object to a Polars DataFrame.\"\"\"\n    import polars as pl  # noqa: PLC0415\n    return pl.from_dicts(self.to_dicts())\n</code></pre>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricPowerResults.to_pretty_dicts","title":"<code>to_pretty_dicts(keys=None, formatter=get_and_format_num, *, max_rows=None)</code>","text":"<p>Convert the object to a list of dictionaries with formatted values.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <p>Returns:</p> Type Description <code>list[dict[str, str]]</code> <p>List of dictionaries with formatted values.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_pretty_dicts(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n) -&gt; list[dict[str, str]]:\n    \"\"\"Convert the object to a list of dictionaries with formatted values.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n\n    Returns:\n        List of dictionaries with formatted values.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    dicts = self.to_dicts()\n    if max_rows &lt;= 0 or len(dicts) &lt;= max_rows:\n        return [{key: formatter(data, key) for key in keys} for data in dicts]\n\n    bottom = max_rows // 2\n    top = max_rows - bottom\n    return (\n        [{key: formatter(data, key) for key in keys} for data in dicts[:top]] +\n        [dict.fromkeys(keys, \"\u2026\")] +\n        [{key: formatter(data, key) for key in keys} for data in dicts[-bottom:]]\n    )\n</code></pre>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricPowerResults.to_string","title":"<code>to_string(keys=None, formatter=get_and_format_num, *, max_rows=None)</code>","text":"<p>Convert the object to a string.</p> <p>Default formatting rules:</p> <ul> <li>If a name starts with <code>\"rel_\"</code> or equals to <code>\"power\"</code> consider it     a percentage value. Round percentage values to 2 significant digits,     multiply by <code>100</code> and add <code>\"%\"</code>.</li> <li>Round other values to 3 significant values.</li> <li>If value is less than <code>0.001</code> or is greater than or equal to <code>10_000_000</code>,     format it in exponential presentation.</li> <li>If a name ends with <code>\"_ci\"</code>, consider it a confidence interval.     Look up for attributes <code>\"{name}_lower\"</code> and <code>\"{name}_upper\"</code>,     and format the interval as <code>\"[{lower_bound}, {upper_bound}]\"</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>Keys to convert. If a key is not defined in the dictionary it's assumed to be <code>None</code>.</p> <code>None</code> <code>formatter</code> <code>Callable[[dict[str, object], str], str]</code> <p>Custom formatter function. It should accept a dictionary of metric result attributes and an attribute name, and return a formatted attribute value.</p> <code>get_and_format_num</code> <code>max_rows</code> <code>int | None</code> <p>Maximum number of rows to convert. If <code>None</code>, the default value will be used. If <code>0</code> or less, all rows will be converted.</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>A table with results rendered as string.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def to_string(\n    self,\n    keys: Sequence[str] | None = None,\n    formatter: Callable[[dict[str, object], str], str] = get_and_format_num,\n    *,\n    max_rows: int | None = None,\n) -&gt; str:\n    \"\"\"Convert the object to a string.\n\n    Default formatting rules:\n\n    - If a name starts with `\"rel_\"` or equals to `\"power\"` consider it\n        a percentage value. Round percentage values to 2 significant digits,\n        multiply by `100` and add `\"%\"`.\n    - Round other values to 3 significant values.\n    - If value is less than `0.001` or is greater than or equal to `10_000_000`,\n        format it in exponential presentation.\n    - If a name ends with `\"_ci\"`, consider it a confidence interval.\n        Look up for attributes `\"{name}_lower\"` and `\"{name}_upper\"`,\n        and format the interval as `\"[{lower_bound}, {upper_bound}]\"`.\n\n    Args:\n        keys: Keys to convert. If a key is not defined in the dictionary\n            it's assumed to be `None`.\n        formatter: Custom formatter function. It should accept a dictionary\n            of metric result attributes and an attribute name, and return\n            a formatted attribute value.\n        max_rows: Maximum number of rows to convert.\n            If `None`, the default value will be used.\n            If `0` or less, all rows will be converted.\n\n    Returns:\n        A table with results rendered as string.\n    \"\"\"\n    if keys is None:\n        keys = self.default_keys\n    if max_rows is None:\n        max_rows = self.default_max_rows\n\n    pretty_dicts = self.to_pretty_dicts(keys, formatter, max_rows=max_rows)\n    widths = {key: len(key) for key in keys}\n    for pretty_dict in pretty_dicts:\n        for key in keys:\n            widths[key] = max(widths[key], len(pretty_dict[key]))\n\n    sep = \" \"\n    rows = [sep.join(key.rjust(widths[key]) for key in keys)]\n    rows.extend(\n        sep.join(pretty_dict[key].rjust(widths[key]) for key in keys)\n        for pretty_dict in pretty_dicts\n    )\n    return \"\\n\".join(rows)\n</code></pre>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricPowerResults.with_defaults","title":"<code>with_defaults(*, keys=None, max_rows=None)</code>","text":"<p>Copies the object and sets the new default parameters.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str] | None</code> <p>New default <code>keys</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> <code>None</code> <code>max_rows</code> <code>int | None</code> <p>New default <code>max_rows</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default keys.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_defaults(\n    self: DictsReprMixinT,\n    *,\n    keys: Sequence[str] | None = None,\n    max_rows: int | None = None,\n) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default parameters.\n\n    Args:\n        keys: New default `keys` for the methods `to_pretty_dicts`, `to_string`,\n            and `to_html`.\n        max_rows: New default `max_rows` for the methods `to_pretty_dicts`,\n            `to_string`, and `to_html`.\n\n    Returns:\n        A copy of the object with the new default keys.\n    \"\"\"\n    new_instance = self.__class__.__new__(self.__class__)\n    new_instance.__dict__.update(self.__dict__)\n    new_instance._cache = None\n    if keys is not None:\n        new_instance.default_keys = keys\n    if max_rows is not None:\n        new_instance.default_max_rows = max_rows\n    return new_instance\n</code></pre>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricPowerResults.with_keys","title":"<code>with_keys(keys)</code>","text":"<p>Copies the object and sets the new default <code>keys</code>.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Sequence[str]</code> <p>New default <code>keys</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> required <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default <code>keys</code>.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_keys(self: DictsReprMixinT, keys: Sequence[str]) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default `keys`.\n\n    Args:\n        keys: New default `keys` for the methods `to_pretty_dicts`, `to_string`,\n            and `to_html`.\n\n    Returns:\n        A copy of the object with the new default `keys`.\n    \"\"\"\n    return self.with_defaults(keys=keys)\n</code></pre>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.MetricPowerResults.with_max_rows","title":"<code>with_max_rows(max_rows)</code>","text":"<p>Copies the object and sets the new default <code>max_rows</code>.</p> <p>Parameters:</p> Name Type Description Default <code>max_rows</code> <code>int</code> <p>New default <code>max_rows</code> for the methods <code>to_pretty_dicts</code>, <code>to_string</code>, and <code>to_html</code>.</p> required <p>Returns:</p> Type Description <code>DictsReprMixinT</code> <p>A copy of the object with the new default <code>max_rows</code>.</p> Source code in <code>src/tea_tasting/utils.py</code> <pre><code>def with_max_rows(self: DictsReprMixinT, max_rows: int) -&gt; DictsReprMixinT:\n    \"\"\"Copies the object and sets the new default `max_rows`.\n\n    Args:\n        max_rows: New default `max_rows` for the methods `to_pretty_dicts`,\n            `to_string`, and `to_html`.\n\n    Returns:\n        A copy of the object with the new default `max_rows`.\n    \"\"\"\n    return self.with_defaults(max_rows=max_rows)\n</code></pre>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.PowerBase","title":"<code>PowerBase</code>","text":"<p>               Bases: <code>ABC</code>, <code>Generic[S]</code>, <code>ReprMixin</code></p> <p>Base class for the analysis of power.</p>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.PowerBase.solve_power","title":"<code>solve_power(data, parameter='rel_effect_size')</code>  <code>abstractmethod</code>","text":"<p>Solve for a parameter of the power of a test.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IntoFrame | Table</code> <p>Sample data.</p> required <code>parameter</code> <code>Literal['power', 'effect_size', 'rel_effect_size', 'n_obs']</code> <p>Parameter name.</p> <code>'rel_effect_size'</code> <p>Returns:</p> Type Description <code>S</code> <p>Power analysis result.</p> Source code in <code>src/tea_tasting/metrics/base.py</code> <pre><code>@abc.abstractmethod\ndef solve_power(\n    self,\n    data: narwhals.typing.IntoFrame | ibis.expr.types.Table,\n    parameter: Literal[\n        \"power\", \"effect_size\", \"rel_effect_size\", \"n_obs\"] = \"rel_effect_size\",\n) -&gt; S:\n    \"\"\"Solve for a parameter of the power of a test.\n\n    Args:\n        data: Sample data.\n        parameter: Parameter name.\n\n    Returns:\n        Power analysis result.\n    \"\"\"\n</code></pre>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.PowerBaseAggregated","title":"<code>PowerBaseAggregated</code>","text":"<p>               Bases: <code>PowerBase[S]</code>, <code>_HasAggrCols</code></p> <p>Base class for the analysis of power using aggregated statistics.</p>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.PowerBaseAggregated.aggr_cols","title":"<code>aggr_cols</code>  <code>abstractmethod</code> <code>property</code>","text":"<p>Columns to be aggregated for an analysis.</p>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.PowerBaseAggregated.solve_power","title":"<code>solve_power(data, parameter='rel_effect_size')</code>","text":"<p>Solve for a parameter of the power of a test.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IntoFrame | Table | Aggregates</code> <p>Sample data.</p> required <code>parameter</code> <code>Literal['power', 'effect_size', 'rel_effect_size', 'n_obs']</code> <p>Parameter name.</p> <code>'rel_effect_size'</code> <p>Returns:</p> Type Description <code>S</code> <p>Power analysis result.</p> Source code in <code>src/tea_tasting/metrics/base.py</code> <pre><code>def solve_power(\n    self,\n    data: (\n        narwhals.typing.IntoFrame |\n        ibis.expr.types.Table |\n        tea_tasting.aggr.Aggregates\n    ),\n    parameter: Literal[\n        \"power\", \"effect_size\", \"rel_effect_size\", \"n_obs\"] = \"rel_effect_size\",\n) -&gt; S:\n    \"\"\"Solve for a parameter of the power of a test.\n\n    Args:\n        data: Sample data.\n        parameter: Parameter name.\n\n    Returns:\n        Power analysis result.\n    \"\"\"\n    tea_tasting.utils.check_scalar(\n        parameter,\n        \"parameter\",\n        in_={\"power\", \"effect_size\", \"rel_effect_size\", \"n_obs\"},\n    )\n    if not isinstance(data, tea_tasting.aggr.Aggregates):\n        data = tea_tasting.aggr.read_aggregates(\n            data=data,\n            group_col=None,\n            **self.aggr_cols._asdict(),\n        )\n    return self.solve_power_from_aggregates(data=data, parameter=parameter)\n</code></pre>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.PowerBaseAggregated.solve_power_from_aggregates","title":"<code>solve_power_from_aggregates(data, parameter='rel_effect_size')</code>  <code>abstractmethod</code>","text":"<p>Solve for a parameter of the power of a test.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Aggregates</code> <p>Sample data.</p> required <code>parameter</code> <code>Literal['power', 'effect_size', 'rel_effect_size', 'n_obs']</code> <p>Parameter name.</p> <code>'rel_effect_size'</code> <p>Returns:</p> Type Description <code>S</code> <p>Power analysis result.</p> Source code in <code>src/tea_tasting/metrics/base.py</code> <pre><code>@abc.abstractmethod\ndef solve_power_from_aggregates(\n    self,\n    data: tea_tasting.aggr.Aggregates,\n    parameter: Literal[\n        \"power\", \"effect_size\", \"rel_effect_size\", \"n_obs\"] = \"rel_effect_size\",\n) -&gt; S:\n    \"\"\"Solve for a parameter of the power of a test.\n\n    Args:\n        data: Sample data.\n        parameter: Parameter name.\n\n    Returns:\n        Power analysis result.\n    \"\"\"\n</code></pre>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.aggregate_by_variants","title":"<code>aggregate_by_variants(data, aggr_cols, variant=None)</code>","text":"<p>Aggregate experimental data by variants.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IntoFrame | Table | dict[object, Aggregates]</code> <p>Experimental data.</p> required <code>aggr_cols</code> <code>AggrCols</code> <p>Columns to be aggregated.</p> required <code>variant</code> <code>str | None</code> <p>Variant column name.</p> <code>None</code> <p>Returns:</p> Type Description <code>dict[object, Aggregates]</code> <p>Experimental data as a dictionary of Aggregates.</p> Source code in <code>src/tea_tasting/metrics/base.py</code> <pre><code>def aggregate_by_variants(\n    data: (\n        narwhals.typing.IntoFrame |\n        ibis.expr.types.Table |\n        dict[object, tea_tasting.aggr.Aggregates]\n    ),\n    aggr_cols: AggrCols,\n    variant: str | None = None,\n) -&gt;  dict[object, tea_tasting.aggr.Aggregates]:\n    \"\"\"Aggregate experimental data by variants.\n\n    Args:\n        data: Experimental data.\n        aggr_cols: Columns to be aggregated.\n        variant: Variant column name.\n\n    Returns:\n        Experimental data as a dictionary of Aggregates.\n    \"\"\"\n    if isinstance(data, dict):\n        return data\n\n    if variant is None:\n        raise ValueError(\"The variant parameter is required but was not provided.\")\n\n    return tea_tasting.aggr.read_aggregates(\n        data=data,\n        group_col=variant,\n        **aggr_cols._asdict(),\n    )\n</code></pre>"},{"location":"api/metrics/base/#tea_tasting.metrics.base.read_granular","title":"<code>read_granular(data, cols=(), variant=None)</code>","text":"<p>Read granular experimental data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IntoFrame | Frame | Table | dict[object, Table]</code> <p>Experimental data.</p> required <code>cols</code> <code>Sequence[str]</code> <p>Columns to read.</p> <code>()</code> <code>variant</code> <code>str | None</code> <p>Variant column name.</p> <code>None</code> <p>Returns:</p> Type Description <code>Table | dict[object, Table]</code> <p>Experimental data as a dictionary of PyArrow Tables.</p> Source code in <code>src/tea_tasting/metrics/base.py</code> <pre><code>def read_granular(\n    data: (\n        narwhals.typing.IntoFrame |\n        narwhals.typing.Frame |\n        ibis.expr.types.Table |\n        dict[object, pa.Table]\n    ),\n    cols: Sequence[str] = (),\n    variant: str | None = None,\n) -&gt; pa.Table | dict[object, pa.Table]:\n    \"\"\"Read granular experimental data.\n\n    Args:\n        data: Experimental data.\n        cols: Columns to read.\n        variant: Variant column name.\n\n    Returns:\n        Experimental data as a dictionary of PyArrow Tables.\n    \"\"\"\n    if isinstance(data, dict):\n        return data\n\n    variant_cols = () if variant is None else (variant,)\n    if isinstance(data, ibis.expr.types.Table):\n        if len(cols) + len(variant_cols) &gt; 0:\n            data = data.select(*cols, *variant_cols)\n        table = data.to_pyarrow()\n    else:\n        data = nw.from_native(data)\n        if isinstance(data, nw.LazyFrame): # type: ignore\n            data = data.collect()\n        if len(cols) + len(variant_cols) &gt; 0:\n            data = data.select(*cols, *variant_cols)\n        table = data.to_arrow()\n\n    if variant is None:\n        return table\n\n    variant_array = table[variant]\n    if len(cols) &gt; 0:\n        table = table.select(cols)\n    return {\n        var: table.filter(pc.equal(variant_array, pa.scalar(var)))  # type: ignore\n        for var in variant_array.unique().to_pylist()\n    }\n</code></pre>"},{"location":"api/metrics/mean/","title":"Mean","text":""},{"location":"api/metrics/mean/#tea_tasting.metrics.mean","title":"<code>tea_tasting.metrics.mean</code>","text":"<p>Metrics for the analysis of means.</p>"},{"location":"api/metrics/mean/#tea_tasting.metrics.mean.Mean","title":"<code>Mean(value, covariate=None, *, alternative=None, confidence_level=None, equal_var=None, use_t=None, alpha=None, ratio=None, power=None, effect_size=None, rel_effect_size=None, n_obs=None)</code>","text":"<p>               Bases: <code>RatioOfMeans</code></p> <p>Metric for the analysis of means.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>str</code> <p>Metric value column name.</p> required <code>covariate</code> <code>str | None</code> <p>Metric covariate column name.</p> <code>None</code> <code>alternative</code> <code>Literal['two-sided', 'greater', 'less'] | None</code> <p>Alternative hypothesis:</p> <ul> <li><code>\"two-sided\"</code>: the means are unequal,</li> <li><code>\"greater\"</code>: the mean in the treatment variant is greater than the mean     in the control variant,</li> <li><code>\"less\"</code>: the mean in the treatment variant is less than the mean     in the control variant.</li> </ul> <code>None</code> <code>confidence_level</code> <code>float | None</code> <p>Confidence level for the confidence interval.</p> <code>None</code> <code>equal_var</code> <code>bool | None</code> <p>Defines whether equal variance is assumed. If <code>True</code>, pooled variance is used for the calculation of the standard error of the difference between two means.</p> <code>None</code> <code>use_t</code> <code>bool | None</code> <p>Defines whether to use the Student's t-distribution (<code>True</code>) or the Normal distribution (<code>False</code>).</p> <code>None</code> <code>alpha</code> <code>float | None</code> <p>Significance level. Only for the analysis of power.</p> <code>None</code> <code>ratio</code> <code>float | int | None</code> <p>Ratio of the number of observations in the treatment relative to the control. Only for the analysis of power.</p> <code>None</code> <code>power</code> <code>float | None</code> <p>Statistical power. Only for the analysis of power.</p> <code>None</code> <code>effect_size</code> <code>float | int | Sequence[float | int] | None</code> <p>Absolute effect size. Difference between the two means. Only for the analysis of power.</p> <code>None</code> <code>rel_effect_size</code> <code>float | Sequence[float] | None</code> <p>Relative effect size. Difference between the two means, divided by the control mean. Only for the analysis of power.</p> <code>None</code> <code>n_obs</code> <code>int | Sequence[int] | None</code> <p>Number of observations in the control and in the treatment together. Only for the analysis of power.</p> <code>None</code> Parameter defaults <p>Defaults for parameters <code>alpha</code>, <code>alternative</code>, <code>confidence_level</code>, <code>equal_var</code>, <code>n_obs</code>, <code>power</code>, <code>ratio</code>, and <code>use_t</code> can be changed using the <code>config_context</code> and <code>set_context</code> functions. See the Global configuration reference for details.</p> References <ul> <li>Deng, A., Knoblich, U., &amp; Lu, J. (2018). Applying the Delta Method in Metric Analytics: A Practical Guide with Novel Ideas.</li> <li>Deng, A., Xu, Y., Kohavi, R., &amp; Walker, T. (2013). Improving the Sensitivity of Online Controlled Experiments by Utilizing Pre-Experiment Data.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; experiment = tt.Experiment(\n...     orders_per_user=tt.Mean(\"orders\"),\n...     revenue_per_user=tt.Mean(\"revenue\"),\n... )\n&gt;&gt;&gt; data = tt.make_users_data(seed=42)\n&gt;&gt;&gt; result = experiment.analyze(data)\n&gt;&gt;&gt; result\n          metric control treatment rel_effect_size rel_effect_size_ci pvalue\n orders_per_user   0.530     0.573            8.0%       [-2.0%, 19%]  0.118\nrevenue_per_user    5.24      5.73            9.3%       [-2.4%, 22%]  0.123\n</code></pre> <p>With CUPED:</p> <pre><code>&gt;&gt;&gt; experiment = tt.Experiment(\n...     orders_per_user=tt.Mean(\"orders\", \"orders_covariate\"),\n...     revenue_per_user=tt.Mean(\"revenue\", \"revenue_covariate\"),\n... )\n&gt;&gt;&gt; data = tt.make_users_data(seed=42, covariates=True)\n&gt;&gt;&gt; result = experiment.analyze(data)\n&gt;&gt;&gt; result\n          metric control treatment rel_effect_size rel_effect_size_ci  pvalue\n orders_per_user   0.523     0.581             11%        [2.9%, 20%] 0.00733\nrevenue_per_user    5.12      5.85             14%        [3.8%, 26%] 0.00674\n</code></pre> <p>Power analysis:</p> <pre><code>&gt;&gt;&gt; data = tt.make_users_data(\n...     seed=42,\n...     sessions_uplift=0,\n...     orders_uplift=0,\n...     revenue_uplift=0,\n...     covariates=True,\n... )\n&gt;&gt;&gt; orders_per_user = tt.Mean(\n...     \"orders\",\n...     \"orders_covariate\",\n...     n_obs=(10_000, 20_000),\n... )\n&gt;&gt;&gt; # Solve for effect size.\n&gt;&gt;&gt; orders_per_user.solve_power(data)\npower effect_size rel_effect_size n_obs\n  80%      0.0374            7.2% 10000\n  80%      0.0264            5.1% 20000\n\n&gt;&gt;&gt; orders_per_user = tt.Mean(\n...     \"orders\",\n...     \"orders_covariate\",\n...     rel_effect_size=0.05,\n... )\n&gt;&gt;&gt; # Solve for the total number of observations.\n&gt;&gt;&gt; orders_per_user.solve_power(data, \"n_obs\")\npower effect_size rel_effect_size n_obs\n  80%      0.0260            5.0% 20733\n\n&gt;&gt;&gt; orders_per_user = tt.Mean(\n...     \"orders\",\n...     \"orders_covariate\",\n...     rel_effect_size=0.1,\n... )\n&gt;&gt;&gt; # Solve for power. Infer number of observations from the sample.\n&gt;&gt;&gt; orders_per_user.solve_power(data, \"power\")\npower effect_size rel_effect_size n_obs\n  69%      0.0519             10%  4000\n</code></pre> Source code in <code>src/tea_tasting/metrics/mean.py</code> <pre><code>def __init__(  # noqa: PLR0913\n    self,\n    value: str,\n    covariate: str | None = None,\n    *,\n    alternative: Literal[\"two-sided\", \"greater\", \"less\"] | None = None,\n    confidence_level: float | None = None,\n    equal_var: bool | None = None,\n    use_t: bool | None = None,\n    alpha: float | None = None,\n    ratio: float | int | None = None,\n    power: float | None = None,\n    effect_size: float | int | Sequence[float | int] | None = None,\n    rel_effect_size: float | Sequence[float] | None = None,\n    n_obs: int | Sequence[int] | None = None,\n) -&gt; None:\n    \"\"\"Metric for the analysis of means.\n\n    Args:\n        value: Metric value column name.\n        covariate: Metric covariate column name.\n        alternative: Alternative hypothesis:\n\n            - `\"two-sided\"`: the means are unequal,\n            - `\"greater\"`: the mean in the treatment variant is greater than the mean\n                in the control variant,\n            - `\"less\"`: the mean in the treatment variant is less than the mean\n                in the control variant.\n\n        confidence_level: Confidence level for the confidence interval.\n        equal_var: Defines whether equal variance is assumed. If `True`,\n            pooled variance is used for the calculation of the standard error\n            of the difference between two means.\n        use_t: Defines whether to use the Student's t-distribution (`True`) or\n            the Normal distribution (`False`).\n        alpha: Significance level. Only for the analysis of power.\n        ratio: Ratio of the number of observations in the treatment\n            relative to the control. Only for the analysis of power.\n        power: Statistical power. Only for the analysis of power.\n        effect_size: Absolute effect size. Difference between the two means.\n            Only for the analysis of power.\n        rel_effect_size: Relative effect size. Difference between the two means,\n            divided by the control mean. Only for the analysis of power.\n        n_obs: Number of observations in the control and in the treatment together.\n            Only for the analysis of power.\n\n    Parameter defaults:\n        Defaults for parameters `alpha`, `alternative`, `confidence_level`,\n        `equal_var`, `n_obs`, `power`, `ratio`, and `use_t` can be changed\n        using the `config_context` and `set_context` functions.\n        See the [Global configuration](https://tea-tasting.e10v.me/api/config/)\n        reference for details.\n\n    References:\n        - [Deng, A., Knoblich, U., &amp; Lu, J. (2018). Applying the Delta Method in Metric Analytics: A Practical Guide with Novel Ideas](https://alexdeng.github.io/public/files/kdd2018-dm.pdf).\n        - [Deng, A., Xu, Y., Kohavi, R., &amp; Walker, T. (2013). Improving the Sensitivity of Online Controlled Experiments by Utilizing Pre-Experiment Data](https://exp-platform.com/Documents/2013-02-CUPED-ImprovingSensitivityOfControlledExperiments.pdf).\n\n    Examples:\n        ```pycon\n        &gt;&gt;&gt; import tea_tasting as tt\n\n        &gt;&gt;&gt; experiment = tt.Experiment(\n        ...     orders_per_user=tt.Mean(\"orders\"),\n        ...     revenue_per_user=tt.Mean(\"revenue\"),\n        ... )\n        &gt;&gt;&gt; data = tt.make_users_data(seed=42)\n        &gt;&gt;&gt; result = experiment.analyze(data)\n        &gt;&gt;&gt; result\n                  metric control treatment rel_effect_size rel_effect_size_ci pvalue\n         orders_per_user   0.530     0.573            8.0%       [-2.0%, 19%]  0.118\n        revenue_per_user    5.24      5.73            9.3%       [-2.4%, 22%]  0.123\n\n        ```\n\n        With CUPED:\n\n        ```pycon\n        &gt;&gt;&gt; experiment = tt.Experiment(\n        ...     orders_per_user=tt.Mean(\"orders\", \"orders_covariate\"),\n        ...     revenue_per_user=tt.Mean(\"revenue\", \"revenue_covariate\"),\n        ... )\n        &gt;&gt;&gt; data = tt.make_users_data(seed=42, covariates=True)\n        &gt;&gt;&gt; result = experiment.analyze(data)\n        &gt;&gt;&gt; result\n                  metric control treatment rel_effect_size rel_effect_size_ci  pvalue\n         orders_per_user   0.523     0.581             11%        [2.9%, 20%] 0.00733\n        revenue_per_user    5.12      5.85             14%        [3.8%, 26%] 0.00674\n\n        ```\n\n        Power analysis:\n\n        ```pycon\n        &gt;&gt;&gt; data = tt.make_users_data(\n        ...     seed=42,\n        ...     sessions_uplift=0,\n        ...     orders_uplift=0,\n        ...     revenue_uplift=0,\n        ...     covariates=True,\n        ... )\n        &gt;&gt;&gt; orders_per_user = tt.Mean(\n        ...     \"orders\",\n        ...     \"orders_covariate\",\n        ...     n_obs=(10_000, 20_000),\n        ... )\n        &gt;&gt;&gt; # Solve for effect size.\n        &gt;&gt;&gt; orders_per_user.solve_power(data)\n        power effect_size rel_effect_size n_obs\n          80%      0.0374            7.2% 10000\n          80%      0.0264            5.1% 20000\n\n        &gt;&gt;&gt; orders_per_user = tt.Mean(\n        ...     \"orders\",\n        ...     \"orders_covariate\",\n        ...     rel_effect_size=0.05,\n        ... )\n        &gt;&gt;&gt; # Solve for the total number of observations.\n        &gt;&gt;&gt; orders_per_user.solve_power(data, \"n_obs\")\n        power effect_size rel_effect_size n_obs\n          80%      0.0260            5.0% 20733\n\n        &gt;&gt;&gt; orders_per_user = tt.Mean(\n        ...     \"orders\",\n        ...     \"orders_covariate\",\n        ...     rel_effect_size=0.1,\n        ... )\n        &gt;&gt;&gt; # Solve for power. Infer number of observations from the sample.\n        &gt;&gt;&gt; orders_per_user.solve_power(data, \"power\")\n        power effect_size rel_effect_size n_obs\n          69%      0.0519             10%  4000\n\n        ```\n    \"\"\"  # noqa: E501\n    super().__init__(\n        numer=value,\n        denom=None,\n        numer_covariate=covariate,\n        denom_covariate=None,\n        alternative=alternative,\n        confidence_level=confidence_level,\n        equal_var=equal_var,\n        use_t=use_t,\n        alpha=alpha,\n        ratio=ratio,\n        power=power,\n        effect_size=effect_size,\n        rel_effect_size=rel_effect_size,\n        n_obs=n_obs,\n    )\n    self.value = value\n    self.covariate = covariate\n</code></pre>"},{"location":"api/metrics/mean/#tea_tasting.metrics.mean.Mean.aggr_cols","title":"<code>aggr_cols</code>  <code>property</code>","text":"<p>Columns to be aggregated for a metric analysis.</p>"},{"location":"api/metrics/mean/#tea_tasting.metrics.mean.Mean.analyze","title":"<code>analyze(data, control, treatment, variant=None)</code>","text":"<p>Analyze a metric in an experiment.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IntoFrame | Table | dict[object, Aggregates]</code> <p>Experimental data.</p> required <code>control</code> <code>object</code> <p>Control variant.</p> required <code>treatment</code> <code>object</code> <p>Treatment variant.</p> required <code>variant</code> <code>str | None</code> <p>Variant column name.</p> <code>None</code> <p>Returns:</p> Type Description <code>R</code> <p>Analysis result.</p> Source code in <code>src/tea_tasting/metrics/base.py</code> <pre><code>def analyze(\n    self,\n    data: narwhals.typing.IntoFrame | ibis.expr.types.Table | dict[\n        object, tea_tasting.aggr.Aggregates],\n    control: object,\n    treatment: object,\n    variant: str | None = None,\n) -&gt; R:\n    \"\"\"Analyze a metric in an experiment.\n\n    Args:\n        data: Experimental data.\n        control: Control variant.\n        treatment: Treatment variant.\n        variant: Variant column name.\n\n    Returns:\n        Analysis result.\n    \"\"\"\n    tea_tasting.utils.check_scalar(variant, \"variant\", typ=str | None)\n    aggr = aggregate_by_variants(\n        data,\n        aggr_cols=self.aggr_cols,\n        variant=variant,\n    )\n    return self.analyze_aggregates(\n        control=aggr[control],\n        treatment=aggr[treatment],\n    )\n</code></pre>"},{"location":"api/metrics/mean/#tea_tasting.metrics.mean.Mean.analyze_aggregates","title":"<code>analyze_aggregates(control, treatment)</code>","text":"<p>Analyze a metric in an experiment using aggregated statistics.</p> <p>Parameters:</p> Name Type Description Default <code>control</code> <code>Aggregates</code> <p>Control data.</p> required <code>treatment</code> <code>Aggregates</code> <p>Treatment data.</p> required <p>Returns:</p> Type Description <code>MeanResult</code> <p>Analysis result.</p> Source code in <code>src/tea_tasting/metrics/mean.py</code> <pre><code>def analyze_aggregates(\n    self,\n    control: tea_tasting.aggr.Aggregates,\n    treatment: tea_tasting.aggr.Aggregates,\n) -&gt; MeanResult:\n    \"\"\"Analyze a metric in an experiment using aggregated statistics.\n\n    Args:\n        control: Control data.\n        treatment: Treatment data.\n\n    Returns:\n        Analysis result.\n    \"\"\"\n    control = control.with_zero_div()\n    treatment = treatment.with_zero_div()\n    total = control + treatment\n    covariate_coef = self._covariate_coef(total)\n    covariate_mean = total.mean(self.numer_covariate) / total.mean(\n        self.denom_covariate)\n    return self._analyze_stats(\n        contr_mean=self._metric_mean(control, covariate_coef, covariate_mean),\n        contr_var=self._metric_var(control, covariate_coef),\n        contr_count=control.count(),\n        treat_mean=self._metric_mean(treatment, covariate_coef, covariate_mean),\n        treat_var=self._metric_var(treatment, covariate_coef),\n        treat_count=treatment.count(),\n    )\n</code></pre>"},{"location":"api/metrics/mean/#tea_tasting.metrics.mean.Mean.solve_power","title":"<code>solve_power(data, parameter='rel_effect_size')</code>","text":"<p>Solve for a parameter of the power of a test.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IntoFrame | Table | Aggregates</code> <p>Sample data.</p> required <code>parameter</code> <code>Literal['power', 'effect_size', 'rel_effect_size', 'n_obs']</code> <p>Parameter name.</p> <code>'rel_effect_size'</code> <p>Returns:</p> Type Description <code>S</code> <p>Power analysis result.</p> Source code in <code>src/tea_tasting/metrics/base.py</code> <pre><code>def solve_power(\n    self,\n    data: (\n        narwhals.typing.IntoFrame |\n        ibis.expr.types.Table |\n        tea_tasting.aggr.Aggregates\n    ),\n    parameter: Literal[\n        \"power\", \"effect_size\", \"rel_effect_size\", \"n_obs\"] = \"rel_effect_size\",\n) -&gt; S:\n    \"\"\"Solve for a parameter of the power of a test.\n\n    Args:\n        data: Sample data.\n        parameter: Parameter name.\n\n    Returns:\n        Power analysis result.\n    \"\"\"\n    tea_tasting.utils.check_scalar(\n        parameter,\n        \"parameter\",\n        in_={\"power\", \"effect_size\", \"rel_effect_size\", \"n_obs\"},\n    )\n    if not isinstance(data, tea_tasting.aggr.Aggregates):\n        data = tea_tasting.aggr.read_aggregates(\n            data=data,\n            group_col=None,\n            **self.aggr_cols._asdict(),\n        )\n    return self.solve_power_from_aggregates(data=data, parameter=parameter)\n</code></pre>"},{"location":"api/metrics/mean/#tea_tasting.metrics.mean.Mean.solve_power_from_aggregates","title":"<code>solve_power_from_aggregates(data, parameter='rel_effect_size')</code>","text":"<p>Solve for a parameter of the power of a test.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Aggregates</code> <p>Sample data.</p> required <code>parameter</code> <code>Literal['power', 'effect_size', 'rel_effect_size', 'n_obs']</code> <p>Parameter name.</p> <code>'rel_effect_size'</code> <p>Returns:</p> Type Description <code>MeanPowerResults</code> <p>Power analysis result.</p> Source code in <code>src/tea_tasting/metrics/mean.py</code> <pre><code>def solve_power_from_aggregates(\n    self,\n    data: tea_tasting.aggr.Aggregates,\n    parameter: Literal[\n        \"power\", \"effect_size\", \"rel_effect_size\", \"n_obs\"] = \"rel_effect_size\",\n) -&gt; MeanPowerResults:\n    \"\"\"Solve for a parameter of the power of a test.\n\n    Args:\n        data: Sample data.\n        parameter: Parameter name.\n\n    Returns:\n        Power analysis result.\n    \"\"\"\n    data = data.with_zero_div()\n    covariate_coef = self._covariate_coef(data)\n    covariate_mean = data.mean(self.numer_covariate) / data.mean(\n        self.denom_covariate)\n    metric_mean = self._metric_mean(data, covariate_coef, covariate_mean)\n    metric_var = self._metric_var(data, covariate_coef)\n\n    power, effect_size, rel_effect_size, n_obs = self._validate_power_parameters(\n        metric_mean=metric_mean,\n        sample_count=data.count(),\n        parameter=parameter,\n    )\n\n    result = MeanPowerResults()\n    for effect_size_i, rel_effect_size_i in zip(\n        effect_size,\n        rel_effect_size,\n        strict=True,\n    ):\n        for n_obs_i in n_obs:\n            parameter_value = self._solve_power_from_stats(\n                sample_var=metric_var,\n                sample_count=n_obs_i,\n                effect_size=effect_size_i,\n                power=power,\n            )\n            result.append(MeanPowerResult(\n                power=parameter_value if parameter == \"power\" else power,  # type: ignore\n                effect_size=(\n                    parameter_value\n                    if parameter in {\"effect_size\", \"rel_effect_size\"}\n                    else effect_size_i\n                ),  # type: ignore\n                rel_effect_size=(\n                    parameter_value / metric_mean\n                    if parameter in {\"effect_size\", \"rel_effect_size\"}\n                    else rel_effect_size_i\n                ),  # type: ignore\n                n_obs=(\n                    math.ceil(parameter_value)\n                    if parameter == \"n_obs\"\n                    else n_obs_i\n                ),  # type: ignore\n            ))\n\n    return result\n</code></pre>"},{"location":"api/metrics/mean/#tea_tasting.metrics.mean.MeanPowerResult","title":"<code>MeanPowerResult</code>","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Power analysis results.</p> <p>Attributes:</p> Name Type Description <code>power</code> <code>float</code> <p>Statistical power.</p> <code>effect_size</code> <code>float</code> <p>Absolute effect size. Difference between the two means.</p> <code>rel_effect_size</code> <code>float</code> <p>Relative effect size. Difference between the two means, divided by the control mean.</p> <code>n_obs</code> <code>float</code> <p>Number of observations in the control and in the treatment together.</p>"},{"location":"api/metrics/mean/#tea_tasting.metrics.mean.MeanResult","title":"<code>MeanResult</code>","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Result of the analysis of means.</p> <p>Attributes:</p> Name Type Description <code>control</code> <code>float</code> <p>Control mean.</p> <code>treatment</code> <code>float</code> <p>Treatment mean.</p> <code>effect_size</code> <code>float</code> <p>Absolute effect size. Difference between the two means.</p> <code>effect_size_ci_lower</code> <code>float</code> <p>Lower bound of the absolute effect size confidence interval.</p> <code>effect_size_ci_upper</code> <code>float</code> <p>Upper bound of the absolute effect size confidence interval.</p> <code>rel_effect_size</code> <code>float</code> <p>Relative effect size. Difference between the two means, divided by the control mean.</p> <code>rel_effect_size_ci_lower</code> <code>float</code> <p>Lower bound of the relative effect size confidence interval.</p> <code>rel_effect_size_ci_upper</code> <code>float</code> <p>Upper bound of the relative effect size confidence interval.</p> <code>pvalue</code> <code>float</code> <p>P-value</p> <code>statistic</code> <code>float</code> <p>Statistic (standardized effect size).</p>"},{"location":"api/metrics/mean/#tea_tasting.metrics.mean.RatioOfMeans","title":"<code>RatioOfMeans(numer, denom=None, numer_covariate=None, denom_covariate=None, *, alternative=None, confidence_level=None, equal_var=None, use_t=None, alpha=None, ratio=None, power=None, effect_size=None, rel_effect_size=None, n_obs=None)</code>","text":"<p>               Bases: <code>MetricBaseAggregated[MeanResult]</code>, <code>PowerBaseAggregated[MeanPowerResults]</code></p> <p>Metric for the analysis of ratios of means.</p> <p>Parameters:</p> Name Type Description Default <code>numer</code> <code>str</code> <p>Numerator column name.</p> required <code>denom</code> <code>str | None</code> <p>Denominator column name.</p> <code>None</code> <code>numer_covariate</code> <code>str | None</code> <p>Covariate numerator column name.</p> <code>None</code> <code>denom_covariate</code> <code>str | None</code> <p>Covariate denominator column name.</p> <code>None</code> <code>alternative</code> <code>Literal['two-sided', 'greater', 'less'] | None</code> <p>Alternative hypothesis:</p> <ul> <li><code>\"two-sided\"</code>: the means are unequal,</li> <li><code>\"greater\"</code>: the mean in the treatment variant is greater than the mean     in the control variant,</li> <li><code>\"less\"</code>: the mean in the treatment variant is less than the mean     in the control variant.</li> </ul> <code>None</code> <code>confidence_level</code> <code>float | None</code> <p>Confidence level for the confidence interval.</p> <code>None</code> <code>equal_var</code> <code>bool | None</code> <p>Defines whether equal variance is assumed. If <code>True</code>, pooled variance is used for the calculation of the standard error of the difference between two means.</p> <code>None</code> <code>use_t</code> <code>bool | None</code> <p>Defines whether to use the Student's t-distribution (<code>True</code>) or the Normal distribution (<code>False</code>).</p> <code>None</code> <code>alpha</code> <code>float | None</code> <p>Significance level. Only for the analysis of power.</p> <code>None</code> <code>ratio</code> <code>float | int | None</code> <p>Ratio of the number of observations in the treatment relative to the control. Only for the analysis of power.</p> <code>None</code> <code>power</code> <code>float | None</code> <p>Statistical power. Only for the analysis of power.</p> <code>None</code> <code>effect_size</code> <code>float | int | Sequence[float | int] | None</code> <p>Absolute effect size. Difference between the two means. Only for the analysis of power.</p> <code>None</code> <code>rel_effect_size</code> <code>float | Sequence[float] | None</code> <p>Relative effect size. Difference between the two means, divided by the control mean. Only for the analysis of power.</p> <code>None</code> <code>n_obs</code> <code>int | Sequence[int] | None</code> <p>Number of observations in the control and in the treatment together. Only for the analysis of power.</p> <code>None</code> Parameter defaults <p>Defaults for parameters <code>alpha</code>, <code>alternative</code>, <code>confidence_level</code>, <code>equal_var</code>, <code>n_obs</code>, <code>power</code>, <code>ratio</code>, and <code>use_t</code> can be changed using the <code>config_context</code> and <code>set_context</code> functions. See the Global configuration reference for details.</p> References <ul> <li>Deng, A., Knoblich, U., &amp; Lu, J. (2018). Applying the Delta Method in Metric Analytics: A Practical Guide with Novel Ideas.</li> <li>Deng, A., Xu, Y., Kohavi, R., &amp; Walker, T. (2013). Improving the Sensitivity of Online Controlled Experiments by Utilizing Pre-Experiment Data.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; experiment = tt.Experiment(\n...     orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\"),\n... )\n&gt;&gt;&gt; data = tt.make_users_data(seed=42)\n&gt;&gt;&gt; result = experiment.analyze(data)\n&gt;&gt;&gt; result\n            metric control treatment rel_effect_size rel_effect_size_ci pvalue\norders_per_session   0.266     0.289            8.8%      [-0.89%, 19%] 0.0762\n</code></pre> <p>With CUPED:</p> <pre><code>&gt;&gt;&gt; experiment = tt.Experiment(\n...     orders_per_session=tt.RatioOfMeans(\n...         \"orders\",\n...         \"sessions\",\n...         \"orders_covariate\",\n...         \"sessions_covariate\",\n...     ),\n... )\n&gt;&gt;&gt; data = tt.make_users_data(seed=42, covariates=True)\n&gt;&gt;&gt; result = experiment.analyze(data)\n&gt;&gt;&gt; result\n            metric control treatment rel_effect_size rel_effect_size_ci  pvalue\norders_per_session   0.262     0.293             12%        [4.2%, 21%] 0.00229\n</code></pre> <p>Power analysis:</p> <pre><code>&gt;&gt;&gt; data = tt.make_users_data(\n...     seed=42,\n...     sessions_uplift=0,\n...     orders_uplift=0,\n...     revenue_uplift=0,\n...     covariates=True,\n... )\n&gt;&gt;&gt; orders_per_session = tt.RatioOfMeans(\n...     \"orders\",\n...     \"sessions\",\n...     \"orders_covariate\",\n...     \"sessions_covariate\",\n...     n_obs=(10_000, 20_000),\n... )\n&gt;&gt;&gt; # Solve for effect size.\n&gt;&gt;&gt; orders_per_session.solve_power(data)\npower effect_size rel_effect_size n_obs\n  80%      0.0177            6.8% 10000\n  80%      0.0125            4.8% 20000\n\n&gt;&gt;&gt; orders_per_session = tt.RatioOfMeans(\n...     \"orders\",\n...     \"sessions\",\n...     \"orders_covariate\",\n...     \"sessions_covariate\",\n...     rel_effect_size=0.05,\n... )\n&gt;&gt;&gt; # Solve for the total number of observations.\n&gt;&gt;&gt; orders_per_session.solve_power(data, \"n_obs\")\npower effect_size rel_effect_size n_obs\n  80%      0.0130            5.0% 18515\n\n&gt;&gt;&gt; orders_per_session = tt.RatioOfMeans(\n...     \"orders\",\n...     \"sessions\",\n...     \"orders_covariate\",\n...     \"sessions_covariate\",\n...     rel_effect_size=0.1,\n... )\n&gt;&gt;&gt; # Solve for power. Infer number of observations from the sample.\n&gt;&gt;&gt; orders_per_session.solve_power(data, \"power\")\npower effect_size rel_effect_size n_obs\n  74%      0.0261             10%  4000\n</code></pre> Source code in <code>src/tea_tasting/metrics/mean.py</code> <pre><code>def __init__(  # noqa: PLR0913\n    self,\n    numer: str,\n    denom: str | None = None,\n    numer_covariate: str | None = None,\n    denom_covariate: str | None = None,\n    *,\n    alternative: Literal[\"two-sided\", \"greater\", \"less\"] | None = None,\n    confidence_level: float | None = None,\n    equal_var: bool | None = None,\n    use_t: bool | None = None,\n    alpha: float | None = None,\n    ratio: float | int | None = None,\n    power: float | None = None,\n    effect_size: float | int | Sequence[float | int] | None = None,\n    rel_effect_size: float | Sequence[float] | None = None,\n    n_obs: int | Sequence[int] | None = None,\n) -&gt; None:\n    \"\"\"Metric for the analysis of ratios of means.\n\n    Args:\n        numer: Numerator column name.\n        denom: Denominator column name.\n        numer_covariate: Covariate numerator column name.\n        denom_covariate: Covariate denominator column name.\n        alternative: Alternative hypothesis:\n\n            - `\"two-sided\"`: the means are unequal,\n            - `\"greater\"`: the mean in the treatment variant is greater than the mean\n                in the control variant,\n            - `\"less\"`: the mean in the treatment variant is less than the mean\n                in the control variant.\n\n        confidence_level: Confidence level for the confidence interval.\n        equal_var: Defines whether equal variance is assumed. If `True`,\n            pooled variance is used for the calculation of the standard error\n            of the difference between two means.\n        use_t: Defines whether to use the Student's t-distribution (`True`) or\n            the Normal distribution (`False`).\n        alpha: Significance level. Only for the analysis of power.\n        ratio: Ratio of the number of observations in the treatment\n            relative to the control. Only for the analysis of power.\n        power: Statistical power. Only for the analysis of power.\n        effect_size: Absolute effect size. Difference between the two means.\n            Only for the analysis of power.\n        rel_effect_size: Relative effect size. Difference between the two means,\n            divided by the control mean. Only for the analysis of power.\n        n_obs: Number of observations in the control and in the treatment together.\n            Only for the analysis of power.\n\n    Parameter defaults:\n        Defaults for parameters `alpha`, `alternative`, `confidence_level`,\n        `equal_var`, `n_obs`, `power`, `ratio`, and `use_t` can be changed\n        using the `config_context` and `set_context` functions.\n        See the [Global configuration](https://tea-tasting.e10v.me/api/config/)\n        reference for details.\n\n    References:\n        - [Deng, A., Knoblich, U., &amp; Lu, J. (2018). Applying the Delta Method in Metric Analytics: A Practical Guide with Novel Ideas](https://alexdeng.github.io/public/files/kdd2018-dm.pdf).\n        - [Deng, A., Xu, Y., Kohavi, R., &amp; Walker, T. (2013). Improving the Sensitivity of Online Controlled Experiments by Utilizing Pre-Experiment Data](https://exp-platform.com/Documents/2013-02-CUPED-ImprovingSensitivityOfControlledExperiments.pdf).\n\n    Examples:\n        ```pycon\n        &gt;&gt;&gt; import tea_tasting as tt\n\n        &gt;&gt;&gt; experiment = tt.Experiment(\n        ...     orders_per_session=tt.RatioOfMeans(\"orders\", \"sessions\"),\n        ... )\n        &gt;&gt;&gt; data = tt.make_users_data(seed=42)\n        &gt;&gt;&gt; result = experiment.analyze(data)\n        &gt;&gt;&gt; result\n                    metric control treatment rel_effect_size rel_effect_size_ci pvalue\n        orders_per_session   0.266     0.289            8.8%      [-0.89%, 19%] 0.0762\n\n        ```\n\n        With CUPED:\n\n        ```pycon\n        &gt;&gt;&gt; experiment = tt.Experiment(\n        ...     orders_per_session=tt.RatioOfMeans(\n        ...         \"orders\",\n        ...         \"sessions\",\n        ...         \"orders_covariate\",\n        ...         \"sessions_covariate\",\n        ...     ),\n        ... )\n        &gt;&gt;&gt; data = tt.make_users_data(seed=42, covariates=True)\n        &gt;&gt;&gt; result = experiment.analyze(data)\n        &gt;&gt;&gt; result\n                    metric control treatment rel_effect_size rel_effect_size_ci  pvalue\n        orders_per_session   0.262     0.293             12%        [4.2%, 21%] 0.00229\n\n        ```\n\n        Power analysis:\n\n        ```pycon\n        &gt;&gt;&gt; data = tt.make_users_data(\n        ...     seed=42,\n        ...     sessions_uplift=0,\n        ...     orders_uplift=0,\n        ...     revenue_uplift=0,\n        ...     covariates=True,\n        ... )\n        &gt;&gt;&gt; orders_per_session = tt.RatioOfMeans(\n        ...     \"orders\",\n        ...     \"sessions\",\n        ...     \"orders_covariate\",\n        ...     \"sessions_covariate\",\n        ...     n_obs=(10_000, 20_000),\n        ... )\n        &gt;&gt;&gt; # Solve for effect size.\n        &gt;&gt;&gt; orders_per_session.solve_power(data)\n        power effect_size rel_effect_size n_obs\n          80%      0.0177            6.8% 10000\n          80%      0.0125            4.8% 20000\n\n        &gt;&gt;&gt; orders_per_session = tt.RatioOfMeans(\n        ...     \"orders\",\n        ...     \"sessions\",\n        ...     \"orders_covariate\",\n        ...     \"sessions_covariate\",\n        ...     rel_effect_size=0.05,\n        ... )\n        &gt;&gt;&gt; # Solve for the total number of observations.\n        &gt;&gt;&gt; orders_per_session.solve_power(data, \"n_obs\")\n        power effect_size rel_effect_size n_obs\n          80%      0.0130            5.0% 18515\n\n        &gt;&gt;&gt; orders_per_session = tt.RatioOfMeans(\n        ...     \"orders\",\n        ...     \"sessions\",\n        ...     \"orders_covariate\",\n        ...     \"sessions_covariate\",\n        ...     rel_effect_size=0.1,\n        ... )\n        &gt;&gt;&gt; # Solve for power. Infer number of observations from the sample.\n        &gt;&gt;&gt; orders_per_session.solve_power(data, \"power\")\n        power effect_size rel_effect_size n_obs\n          74%      0.0261             10%  4000\n\n        ```\n    \"\"\"  # noqa: E501\n    self.numer = tea_tasting.utils.check_scalar(numer, \"numer\", typ=str)\n    self.denom = tea_tasting.utils.check_scalar(denom, \"denom\", typ=str | None)\n    self.numer_covariate = tea_tasting.utils.check_scalar(\n        numer_covariate, \"numer_covariate\", typ=str | None)\n    self.denom_covariate = tea_tasting.utils.check_scalar(\n        denom_covariate, \"denom_covariate\", typ=str | None)\n    self.alternative = (\n        tea_tasting.utils.auto_check(alternative, \"alternative\")\n        if alternative is not None\n        else tea_tasting.config.get_config(\"alternative\")\n    )\n    self.confidence_level = (\n        tea_tasting.utils.auto_check(confidence_level, \"confidence_level\")\n        if confidence_level is not None\n        else tea_tasting.config.get_config(\"confidence_level\")\n    )\n    self.equal_var = (\n        tea_tasting.utils.auto_check(equal_var, \"equal_var\")\n        if equal_var is not None\n        else tea_tasting.config.get_config(\"equal_var\")\n    )\n    self.use_t = (\n        tea_tasting.utils.auto_check(use_t, \"use_t\")\n        if use_t is not None\n        else tea_tasting.config.get_config(\"use_t\")\n    )\n    self.alpha = (\n        tea_tasting.utils.auto_check(alpha, \"alpha\")\n        if alpha is not None\n        else tea_tasting.config.get_config(\"alpha\")\n    )\n    self.ratio = (\n        tea_tasting.utils.auto_check(ratio, \"ratio\")\n        if ratio is not None\n        else tea_tasting.config.get_config(\"ratio\")\n    )\n    self.power = (\n        tea_tasting.utils.auto_check(power, \"power\")\n        if power is not None\n        else tea_tasting.config.get_config(\"power\")\n    )\n    if effect_size is not None and rel_effect_size is not None:\n        raise ValueError(\n            \"Both `effect_size` and `rel_effect_size` are not `None`. \"\n            \"Only one of them should be defined.\",\n        )\n    if isinstance(effect_size, Sequence):\n        for x in effect_size:\n            tea_tasting.utils.check_scalar(\n                x, \"effect_size\", typ=float | int,\n                gt=float(\"-inf\"), lt=float(\"inf\"), ne=0,\n            )\n    elif effect_size is not None:\n        tea_tasting.utils.check_scalar(\n            effect_size, \"effect_size\", typ=float | int,\n            gt=float(\"-inf\"), lt=float(\"inf\"), ne=0,\n        )\n    self.effect_size = effect_size\n    if isinstance(rel_effect_size, Sequence):\n        for x in rel_effect_size:\n            tea_tasting.utils.check_scalar(\n                x, \"rel_effect_size\", typ=float | int,\n                gt=float(\"-inf\"), lt=float(\"inf\"), ne=0,\n            )\n    elif rel_effect_size is not None:\n        tea_tasting.utils.check_scalar(\n            rel_effect_size, \"rel_effect_size\", typ=float | int,\n            gt=float(\"-inf\"), lt=float(\"inf\"), ne=0,\n        )\n    self.rel_effect_size = rel_effect_size\n    self.n_obs = (\n        tea_tasting.utils.auto_check(n_obs, \"n_obs\")\n        if n_obs is not None\n        else tea_tasting.config.get_config(\"n_obs\")\n    )\n</code></pre>"},{"location":"api/metrics/mean/#tea_tasting.metrics.mean.RatioOfMeans.aggr_cols","title":"<code>aggr_cols</code>  <code>property</code>","text":"<p>Columns to be aggregated for a metric analysis.</p>"},{"location":"api/metrics/mean/#tea_tasting.metrics.mean.RatioOfMeans.analyze","title":"<code>analyze(data, control, treatment, variant=None)</code>","text":"<p>Analyze a metric in an experiment.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IntoFrame | Table | dict[object, Aggregates]</code> <p>Experimental data.</p> required <code>control</code> <code>object</code> <p>Control variant.</p> required <code>treatment</code> <code>object</code> <p>Treatment variant.</p> required <code>variant</code> <code>str | None</code> <p>Variant column name.</p> <code>None</code> <p>Returns:</p> Type Description <code>R</code> <p>Analysis result.</p> Source code in <code>src/tea_tasting/metrics/base.py</code> <pre><code>def analyze(\n    self,\n    data: narwhals.typing.IntoFrame | ibis.expr.types.Table | dict[\n        object, tea_tasting.aggr.Aggregates],\n    control: object,\n    treatment: object,\n    variant: str | None = None,\n) -&gt; R:\n    \"\"\"Analyze a metric in an experiment.\n\n    Args:\n        data: Experimental data.\n        control: Control variant.\n        treatment: Treatment variant.\n        variant: Variant column name.\n\n    Returns:\n        Analysis result.\n    \"\"\"\n    tea_tasting.utils.check_scalar(variant, \"variant\", typ=str | None)\n    aggr = aggregate_by_variants(\n        data,\n        aggr_cols=self.aggr_cols,\n        variant=variant,\n    )\n    return self.analyze_aggregates(\n        control=aggr[control],\n        treatment=aggr[treatment],\n    )\n</code></pre>"},{"location":"api/metrics/mean/#tea_tasting.metrics.mean.RatioOfMeans.analyze_aggregates","title":"<code>analyze_aggregates(control, treatment)</code>","text":"<p>Analyze a metric in an experiment using aggregated statistics.</p> <p>Parameters:</p> Name Type Description Default <code>control</code> <code>Aggregates</code> <p>Control data.</p> required <code>treatment</code> <code>Aggregates</code> <p>Treatment data.</p> required <p>Returns:</p> Type Description <code>MeanResult</code> <p>Analysis result.</p> Source code in <code>src/tea_tasting/metrics/mean.py</code> <pre><code>def analyze_aggregates(\n    self,\n    control: tea_tasting.aggr.Aggregates,\n    treatment: tea_tasting.aggr.Aggregates,\n) -&gt; MeanResult:\n    \"\"\"Analyze a metric in an experiment using aggregated statistics.\n\n    Args:\n        control: Control data.\n        treatment: Treatment data.\n\n    Returns:\n        Analysis result.\n    \"\"\"\n    control = control.with_zero_div()\n    treatment = treatment.with_zero_div()\n    total = control + treatment\n    covariate_coef = self._covariate_coef(total)\n    covariate_mean = total.mean(self.numer_covariate) / total.mean(\n        self.denom_covariate)\n    return self._analyze_stats(\n        contr_mean=self._metric_mean(control, covariate_coef, covariate_mean),\n        contr_var=self._metric_var(control, covariate_coef),\n        contr_count=control.count(),\n        treat_mean=self._metric_mean(treatment, covariate_coef, covariate_mean),\n        treat_var=self._metric_var(treatment, covariate_coef),\n        treat_count=treatment.count(),\n    )\n</code></pre>"},{"location":"api/metrics/mean/#tea_tasting.metrics.mean.RatioOfMeans.solve_power","title":"<code>solve_power(data, parameter='rel_effect_size')</code>","text":"<p>Solve for a parameter of the power of a test.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IntoFrame | Table | Aggregates</code> <p>Sample data.</p> required <code>parameter</code> <code>Literal['power', 'effect_size', 'rel_effect_size', 'n_obs']</code> <p>Parameter name.</p> <code>'rel_effect_size'</code> <p>Returns:</p> Type Description <code>S</code> <p>Power analysis result.</p> Source code in <code>src/tea_tasting/metrics/base.py</code> <pre><code>def solve_power(\n    self,\n    data: (\n        narwhals.typing.IntoFrame |\n        ibis.expr.types.Table |\n        tea_tasting.aggr.Aggregates\n    ),\n    parameter: Literal[\n        \"power\", \"effect_size\", \"rel_effect_size\", \"n_obs\"] = \"rel_effect_size\",\n) -&gt; S:\n    \"\"\"Solve for a parameter of the power of a test.\n\n    Args:\n        data: Sample data.\n        parameter: Parameter name.\n\n    Returns:\n        Power analysis result.\n    \"\"\"\n    tea_tasting.utils.check_scalar(\n        parameter,\n        \"parameter\",\n        in_={\"power\", \"effect_size\", \"rel_effect_size\", \"n_obs\"},\n    )\n    if not isinstance(data, tea_tasting.aggr.Aggregates):\n        data = tea_tasting.aggr.read_aggregates(\n            data=data,\n            group_col=None,\n            **self.aggr_cols._asdict(),\n        )\n    return self.solve_power_from_aggregates(data=data, parameter=parameter)\n</code></pre>"},{"location":"api/metrics/mean/#tea_tasting.metrics.mean.RatioOfMeans.solve_power_from_aggregates","title":"<code>solve_power_from_aggregates(data, parameter='rel_effect_size')</code>","text":"<p>Solve for a parameter of the power of a test.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Aggregates</code> <p>Sample data.</p> required <code>parameter</code> <code>Literal['power', 'effect_size', 'rel_effect_size', 'n_obs']</code> <p>Parameter name.</p> <code>'rel_effect_size'</code> <p>Returns:</p> Type Description <code>MeanPowerResults</code> <p>Power analysis result.</p> Source code in <code>src/tea_tasting/metrics/mean.py</code> <pre><code>def solve_power_from_aggregates(\n    self,\n    data: tea_tasting.aggr.Aggregates,\n    parameter: Literal[\n        \"power\", \"effect_size\", \"rel_effect_size\", \"n_obs\"] = \"rel_effect_size\",\n) -&gt; MeanPowerResults:\n    \"\"\"Solve for a parameter of the power of a test.\n\n    Args:\n        data: Sample data.\n        parameter: Parameter name.\n\n    Returns:\n        Power analysis result.\n    \"\"\"\n    data = data.with_zero_div()\n    covariate_coef = self._covariate_coef(data)\n    covariate_mean = data.mean(self.numer_covariate) / data.mean(\n        self.denom_covariate)\n    metric_mean = self._metric_mean(data, covariate_coef, covariate_mean)\n    metric_var = self._metric_var(data, covariate_coef)\n\n    power, effect_size, rel_effect_size, n_obs = self._validate_power_parameters(\n        metric_mean=metric_mean,\n        sample_count=data.count(),\n        parameter=parameter,\n    )\n\n    result = MeanPowerResults()\n    for effect_size_i, rel_effect_size_i in zip(\n        effect_size,\n        rel_effect_size,\n        strict=True,\n    ):\n        for n_obs_i in n_obs:\n            parameter_value = self._solve_power_from_stats(\n                sample_var=metric_var,\n                sample_count=n_obs_i,\n                effect_size=effect_size_i,\n                power=power,\n            )\n            result.append(MeanPowerResult(\n                power=parameter_value if parameter == \"power\" else power,  # type: ignore\n                effect_size=(\n                    parameter_value\n                    if parameter in {\"effect_size\", \"rel_effect_size\"}\n                    else effect_size_i\n                ),  # type: ignore\n                rel_effect_size=(\n                    parameter_value / metric_mean\n                    if parameter in {\"effect_size\", \"rel_effect_size\"}\n                    else rel_effect_size_i\n                ),  # type: ignore\n                n_obs=(\n                    math.ceil(parameter_value)\n                    if parameter == \"n_obs\"\n                    else n_obs_i\n                ),  # type: ignore\n            ))\n\n    return result\n</code></pre>"},{"location":"api/metrics/proportion/","title":"Proportion","text":""},{"location":"api/metrics/proportion/#tea_tasting.metrics.proportion","title":"<code>tea_tasting.metrics.proportion</code>","text":"<p>Metrics for the analysis of proportions.</p>"},{"location":"api/metrics/proportion/#tea_tasting.metrics.proportion.SampleRatio","title":"<code>SampleRatio(ratio=1, *, method='auto', correction=True)</code>","text":"<p>               Bases: <code>MetricBaseAggregated[SampleRatioResult]</code></p> <p>Metric for sample ratio mismatch check.</p> <p>Parameters:</p> Name Type Description Default <code>ratio</code> <code>float | int | dict[object, float | int]</code> <p>Expected ratio of the number of observations in the treatment relative to the control.</p> <code>1</code> <code>method</code> <code>Literal['auto', 'binom', 'norm']</code> <p>Statistical test used for calculation of p-value:</p> <ul> <li><code>\"auto\"</code>: Apply exact binomial test if the total number     of observations is &lt; 1000; or normal approximation otherwise.</li> <li><code>\"binom\"</code>: Apply exact binomial test.</li> <li><code>\"norm\"</code>: Apply normal approximation of the binomial distribution.</li> </ul> <code>'auto'</code> <code>correction</code> <code>bool</code> <p>If <code>True</code>, add continuity correction. Only for normal approximation.</p> <code>True</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; experiment = tt.Experiment(\n...     sample_ratio=tt.SampleRatio(),\n... )\n&gt;&gt;&gt; data = tt.make_users_data(seed=42)\n&gt;&gt;&gt; result = experiment.analyze(data)\n&gt;&gt;&gt; result.with_keys((\"metric\", \"control\", \"treatment\", \"pvalue\"))\n      metric control treatment pvalue\nsample_ratio    2023      1977  0.477\n</code></pre> <p>Different expected ratio:</p> <pre><code>&gt;&gt;&gt; experiment = tt.Experiment(\n...     sample_ratio=tt.SampleRatio(0.5),\n... )\n&gt;&gt;&gt; data = tt.make_users_data(seed=42)\n&gt;&gt;&gt; result = experiment.analyze(data)\n&gt;&gt;&gt; result.with_keys((\"metric\", \"control\", \"treatment\", \"pvalue\"))\n      metric control treatment    pvalue\nsample_ratio    2023      1977 3.26e-103\n</code></pre> Source code in <code>src/tea_tasting/metrics/proportion.py</code> <pre><code>def __init__(\n    self,\n    ratio: float | int | dict[object, float | int] = 1,\n    *,\n    method: Literal[\"auto\", \"binom\", \"norm\"] = \"auto\",\n    correction: bool = True,\n) -&gt; None:\n    \"\"\"Metric for sample ratio mismatch check.\n\n    Args:\n        ratio: Expected ratio of the number of observations in the treatment\n            relative to the control.\n        method: Statistical test used for calculation of p-value:\n\n            - `\"auto\"`: Apply exact binomial test if the total number\n                of observations is &lt; 1000; or normal approximation otherwise.\n            - `\"binom\"`: Apply exact binomial test.\n            - `\"norm\"`: Apply normal approximation of the binomial distribution.\n\n        correction: If `True`, add continuity correction.\n            Only for normal approximation.\n\n    Examples:\n        ```pycon\n        &gt;&gt;&gt; import tea_tasting as tt\n\n        &gt;&gt;&gt; experiment = tt.Experiment(\n        ...     sample_ratio=tt.SampleRatio(),\n        ... )\n        &gt;&gt;&gt; data = tt.make_users_data(seed=42)\n        &gt;&gt;&gt; result = experiment.analyze(data)\n        &gt;&gt;&gt; result.with_keys((\"metric\", \"control\", \"treatment\", \"pvalue\"))\n              metric control treatment pvalue\n        sample_ratio    2023      1977  0.477\n\n        ```\n\n        Different expected ratio:\n\n        ```pycon\n        &gt;&gt;&gt; experiment = tt.Experiment(\n        ...     sample_ratio=tt.SampleRatio(0.5),\n        ... )\n        &gt;&gt;&gt; data = tt.make_users_data(seed=42)\n        &gt;&gt;&gt; result = experiment.analyze(data)\n        &gt;&gt;&gt; result.with_keys((\"metric\", \"control\", \"treatment\", \"pvalue\"))\n              metric control treatment    pvalue\n        sample_ratio    2023      1977 3.26e-103\n\n        ```\n    \"\"\"\n    if isinstance(ratio, dict):\n        for val in ratio.values():\n            tea_tasting.utils.auto_check(val, \"ratio\")\n    else:\n        tea_tasting.utils.auto_check(ratio, \"ratio\")\n    self.ratio = ratio\n\n    self.method = tea_tasting.utils.check_scalar(\n        method, \"method\", typ=str, in_={\"auto\", \"binom\", \"norm\"})\n    self.correction = tea_tasting.utils.auto_check(correction, \"correction\")\n</code></pre>"},{"location":"api/metrics/proportion/#tea_tasting.metrics.proportion.SampleRatio.aggr_cols","title":"<code>aggr_cols</code>  <code>property</code>","text":"<p>Columns to be aggregated for a metric analysis.</p>"},{"location":"api/metrics/proportion/#tea_tasting.metrics.proportion.SampleRatio.analyze","title":"<code>analyze(data, control, treatment, variant=None)</code>","text":"<p>Perform a sample ratio mismatch check.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IntoFrame | Table | dict[object, Aggregates]</code> <p>Experimental data.</p> required <code>control</code> <code>object</code> <p>Control variant.</p> required <code>treatment</code> <code>object</code> <p>Treatment variant.</p> required <code>variant</code> <code>str | None</code> <p>Variant column name.</p> <code>None</code> <p>Returns:</p> Type Description <code>SampleRatioResult</code> <p>Analysis result.</p> Source code in <code>src/tea_tasting/metrics/proportion.py</code> <pre><code>def analyze(\n    self,\n    data: narwhals.typing.IntoFrame | ibis.expr.types.Table | dict[\n        object, tea_tasting.aggr.Aggregates],\n    control: object,\n    treatment: object,\n    variant: str | None = None,\n) -&gt; SampleRatioResult:\n    \"\"\"Perform a sample ratio mismatch check.\n\n    Args:\n        data: Experimental data.\n        control: Control variant.\n        treatment: Treatment variant.\n        variant: Variant column name.\n\n    Returns:\n        Analysis result.\n    \"\"\"\n    tea_tasting.utils.check_scalar(variant, \"variant\", typ=str | None)\n    aggr = tea_tasting.metrics.aggregate_by_variants(\n        data,\n        aggr_cols=self.aggr_cols,\n        variant=variant,\n    )\n\n    k = aggr[treatment].count()\n    n = k + aggr[control].count()\n\n    r = (\n        self.ratio\n        if isinstance(self.ratio, float | int)\n        else self.ratio[treatment] / self.ratio[control]\n    )\n    p = r / (1 + r)\n\n    if (\n        self.method == \"binom\" or\n        (self.method == \"auto\" and n &lt; _MAX_EXACT_THRESHOLD)\n    ):\n        pvalue = scipy.stats.binomtest(k=int(k), n=int(n), p=p).pvalue\n    else:  # norm\n        d = k - n*p\n        if self.correction and d != 0:\n            d = min(d + 0.5, 0) if d &lt; 0 else max(d - 0.5, 0)\n        z = d / math.sqrt(n * p * (1 - p))\n        pvalue = 2 * scipy.stats.norm.sf(abs(z))\n\n    return SampleRatioResult(\n        control=n - k,\n        treatment=k,\n        pvalue=pvalue,  # type: ignore\n    )\n</code></pre>"},{"location":"api/metrics/proportion/#tea_tasting.metrics.proportion.SampleRatio.analyze_aggregates","title":"<code>analyze_aggregates(control, treatment)</code>","text":"<p>Stub method for compatibility with the base class.</p> Source code in <code>src/tea_tasting/metrics/proportion.py</code> <pre><code>def analyze_aggregates(\n    self,\n    control: tea_tasting.aggr.Aggregates,\n    treatment: tea_tasting.aggr.Aggregates,\n) -&gt; SampleRatioResult:\n    \"\"\"Stub method for compatibility with the base class.\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/metrics/proportion/#tea_tasting.metrics.proportion.SampleRatioResult","title":"<code>SampleRatioResult</code>","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Result of the sample ratio mismatch check.</p> <p>Attributes:</p> Name Type Description <code>control</code> <code>float</code> <p>Number of observations in control.</p> <code>treatment</code> <code>float</code> <p>Number of observations in treatment.</p> <code>pvalue</code> <code>float</code> <p>P-value</p>"},{"location":"api/metrics/resampling/","title":"Resampling","text":""},{"location":"api/metrics/resampling/#tea_tasting.metrics.resampling","title":"<code>tea_tasting.metrics.resampling</code>","text":"<p>Metrics analyzed using resampling methods.</p>"},{"location":"api/metrics/resampling/#tea_tasting.metrics.resampling.Bootstrap","title":"<code>Bootstrap(columns, statistic, *, alternative=None, confidence_level=None, n_resamples=None, method='bca', batch=None, random_state=None)</code>","text":"<p>               Bases: <code>MetricBaseGranular[BootstrapResult]</code></p> <p>Metric for analysis of a statistic using bootstrap resampling.</p> <p>If <code>columns</code> is a sequence of strings, then the sample passed to the statistic callable contains an extra dimension in the first axis. See examples below.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>str | Sequence[str]</code> <p>Names of the columns to be used in the analysis.</p> required <code>statistic</code> <code>Callable[..., NDArray[number]]</code> <p>Statistic. It must be a vectorized callable that accepts a NumPy array as the first argument and returns the resulting statistic. It must also accept a keyword argument <code>axis</code> and be vectorized to compute the statistic along the provided axis.</p> required <code>alternative</code> <code>Literal['two-sided', 'greater', 'less'] | None</code> <p>Alternative hypothesis:</p> <ul> <li><code>\"two-sided\"</code>: the means are unequal,</li> <li><code>\"greater\"</code>: the mean in the treatment variant is greater than the mean     in the control variant,</li> <li><code>\"less\"</code>: the mean in the treatment variant is less than the mean     in the control variant.</li> </ul> <code>None</code> <code>confidence_level</code> <code>float | None</code> <p>Confidence level for the confidence interval.</p> <code>None</code> <code>n_resamples</code> <code>int | None</code> <p>The number of resamples performed to form the bootstrap distribution of the statistic.</p> <code>None</code> <code>method</code> <code>Literal['percentile', 'basic', 'bca']</code> <p>Whether to return the \"percentile\" bootstrap confidence interval (<code>\"percentile\"</code>), the \"basic\" (AKA \"reverse\") bootstrap confidence interval (<code>\"basic\"</code>), or the bias-corrected and accelerated bootstrap confidence interval (<code>\"bca\"</code>).</p> <code>'bca'</code> <code>batch</code> <code>int | None</code> <p>The number of resamples to process in each vectorized call to statistic. Memory usage is O(<code>batch * n</code>), where <code>n</code> is the sample size. Default is <code>None</code>, in which case <code>batch = n_resamples</code> (or <code>batch = max(n_resamples, n)</code> for method=\"bca\").</p> <code>None</code> <code>random_state</code> <code>int | Generator | SeedSequence | None</code> <p>Pseudorandom number generator state used to generate resamples.</p> <code>None</code> Parameter defaults <p>Defaults for parameters <code>alternative</code>, <code>confidence_level</code>, and <code>n_resamples</code> can be changed using the <code>config_context</code> and <code>set_context</code> functions. See the Global configuration reference for details.</p> References <ul> <li>Bootstrapping (statistics) \u2014 Wikipedia.</li> <li>scipy.stats.bootstrap \u2014 SciPy Manual.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; experiment = tt.Experiment(\n...     orders_per_user=tt.Bootstrap(\"orders\", np.mean, random_state=42),\n... )\n&gt;&gt;&gt; data = tt.make_users_data(seed=42)\n&gt;&gt;&gt; result = experiment.analyze(data)\n&gt;&gt;&gt; result\n         metric control treatment rel_effect_size rel_effect_size_ci pvalue\norders_per_user   0.530     0.573            8.0%       [-1.8%, 19%]      -\n</code></pre> <p>With multiple columns:</p> <pre><code>&gt;&gt;&gt; def ratio_of_means(sample, axis):\n...     means = np.mean(sample, axis=axis)\n...     return means[0] / means[1]\n\n&gt;&gt;&gt; experiment = tt.Experiment(\n...     orders_per_session=tt.Bootstrap(\n...         (\"orders\", \"sessions\"),\n...         ratio_of_means,\n...         random_state=42,\n...     ),\n... )\n&gt;&gt;&gt; data = tt.make_users_data(seed=42)\n&gt;&gt;&gt; result = experiment.analyze(data)\n&gt;&gt;&gt; result\n            metric control treatment rel_effect_size rel_effect_size_ci pvalue\norders_per_session   0.266     0.289            8.8%      [-0.61%, 20%]      -\n</code></pre> Source code in <code>src/tea_tasting/metrics/resampling.py</code> <pre><code>def __init__(\n    self,\n    columns: str | Sequence[str],\n    statistic: Callable[..., npt.NDArray[np.number]],\n    *,\n    alternative: Literal[\"two-sided\", \"greater\", \"less\"] | None = None,\n    confidence_level: float | None = None,\n    n_resamples: int | None = None,\n    method: Literal[\"percentile\", \"basic\", \"bca\"] = \"bca\",\n    batch: int | None = None,\n    random_state: int | np.random.Generator | np.random.SeedSequence | None = None,\n) -&gt; None:\n    \"\"\"Metric for analysis of a statistic using bootstrap resampling.\n\n    If `columns` is a sequence of strings, then the sample passed\n    to the statistic callable contains an extra dimension in the first axis.\n    See examples below.\n\n    Args:\n        columns: Names of the columns to be used in the analysis.\n        statistic: Statistic. It must be a vectorized callable\n            that accepts a NumPy array as the first argument and returns\n            the resulting statistic.\n            It must also accept a keyword argument `axis` and be vectorized\n            to compute the statistic along the provided axis.\n        alternative: Alternative hypothesis:\n\n            - `\"two-sided\"`: the means are unequal,\n            - `\"greater\"`: the mean in the treatment variant is greater than the mean\n                in the control variant,\n            - `\"less\"`: the mean in the treatment variant is less than the mean\n                in the control variant.\n\n        confidence_level: Confidence level for the confidence interval.\n        n_resamples: The number of resamples performed to form\n            the bootstrap distribution of the statistic.\n        method: Whether to return the \"percentile\" bootstrap confidence\n            interval (`\"percentile\"`), the \"basic\" (AKA \"reverse\") bootstrap\n            confidence interval (`\"basic\"`), or the bias-corrected\n            and accelerated bootstrap confidence interval (`\"bca\"`).\n        batch: The number of resamples to process in each vectorized call\n            to statistic. Memory usage is O(`batch * n`), where `n` is\n            the sample size. Default is `None`, in which case `batch = n_resamples`\n            (or `batch = max(n_resamples, n)` for method=\"bca\").\n        random_state: Pseudorandom number generator state used\n            to generate resamples.\n\n    Parameter defaults:\n        Defaults for parameters `alternative`, `confidence_level`,\n        and `n_resamples` can be changed using the\n        `config_context` and `set_context` functions.\n        See the [Global configuration](https://tea-tasting.e10v.me/api/config/)\n        reference for details.\n\n    References:\n        - [Bootstrapping (statistics) &amp;#8212; Wikipedia](https://en.wikipedia.org/wiki/Bootstrapping_(statistics)).\n        - [scipy.stats.bootstrap &amp;#8212; SciPy Manual](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html#scipy-stats-bootstrap).\n\n    Examples:\n        ```pycon\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; import tea_tasting as tt\n\n        &gt;&gt;&gt; experiment = tt.Experiment(\n        ...     orders_per_user=tt.Bootstrap(\"orders\", np.mean, random_state=42),\n        ... )\n        &gt;&gt;&gt; data = tt.make_users_data(seed=42)\n        &gt;&gt;&gt; result = experiment.analyze(data)\n        &gt;&gt;&gt; result\n                 metric control treatment rel_effect_size rel_effect_size_ci pvalue\n        orders_per_user   0.530     0.573            8.0%       [-1.8%, 19%]      -\n\n        ```\n\n        With multiple columns:\n\n        ```pycon\n        &gt;&gt;&gt; def ratio_of_means(sample, axis):\n        ...     means = np.mean(sample, axis=axis)\n        ...     return means[0] / means[1]\n\n        &gt;&gt;&gt; experiment = tt.Experiment(\n        ...     orders_per_session=tt.Bootstrap(\n        ...         (\"orders\", \"sessions\"),\n        ...         ratio_of_means,\n        ...         random_state=42,\n        ...     ),\n        ... )\n        &gt;&gt;&gt; data = tt.make_users_data(seed=42)\n        &gt;&gt;&gt; result = experiment.analyze(data)\n        &gt;&gt;&gt; result\n                    metric control treatment rel_effect_size rel_effect_size_ci pvalue\n        orders_per_session   0.266     0.289            8.8%      [-0.61%, 20%]      -\n\n        ```\n    \"\"\"  # noqa: E501\n    tea_tasting.utils.check_scalar(columns, \"columns\", typ=str | Sequence)\n    if not isinstance(columns, str):\n        for col in columns:\n            tea_tasting.utils.check_scalar(col, \"column\", typ=str)\n    self.columns = columns\n\n    self.statistic = tea_tasting.utils.check_scalar(\n        statistic, \"statistic\", typ=Callable)\n\n    self.alternative = (\n        tea_tasting.utils.auto_check(alternative, \"alternative\")\n        if alternative is not None\n        else tea_tasting.config.get_config(\"alternative\")\n    )\n\n    self.confidence_level = (\n        tea_tasting.utils.auto_check(confidence_level, \"confidence_level\")\n        if confidence_level is not None\n        else tea_tasting.config.get_config(\"confidence_level\")\n    )\n\n    self.n_resamples = (\n        tea_tasting.utils.auto_check(n_resamples, \"n_resamples\")\n        if n_resamples is not None\n        else tea_tasting.config.get_config(\"n_resamples\")\n    )\n\n    self.method = tea_tasting.utils.check_scalar(\n        method, \"method\", typ=str, in_={\"percentile\", \"basic\", \"bca\"})\n\n    self.batch = tea_tasting.utils.check_scalar(batch, \"batch\", typ=int | None)\n\n    self.random_state = tea_tasting.utils.check_scalar(\n        random_state,\n        \"random_state\",\n        typ=int | np.random.Generator | np.random.SeedSequence | None,\n    )\n</code></pre>"},{"location":"api/metrics/resampling/#tea_tasting.metrics.resampling.Bootstrap.cols","title":"<code>cols</code>  <code>property</code>","text":"<p>Columns to be fetched for a metric analysis.</p>"},{"location":"api/metrics/resampling/#tea_tasting.metrics.resampling.Bootstrap.analyze","title":"<code>analyze(data, control, treatment, variant=None)</code>","text":"<p>Analyze a metric in an experiment.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IntoFrame | Table | dict[object, Table]</code> <p>Experimental data.</p> required <code>control</code> <code>object</code> <p>Control variant.</p> required <code>treatment</code> <code>object</code> <p>Treatment variant.</p> required <code>variant</code> <code>str | None</code> <p>Variant column name.</p> <code>None</code> <p>Returns:</p> Type Description <code>R</code> <p>Analysis result.</p> Source code in <code>src/tea_tasting/metrics/base.py</code> <pre><code>def analyze(\n    self,\n    data: (\n        narwhals.typing.IntoFrame |\n        ibis.expr.types.Table |\n        dict[object, pa.Table]\n    ),\n    control: object,\n    treatment: object,\n    variant: str | None = None,\n) -&gt; R:\n    \"\"\"Analyze a metric in an experiment.\n\n    Args:\n        data: Experimental data.\n        control: Control variant.\n        treatment: Treatment variant.\n        variant: Variant column name.\n\n    Returns:\n        Analysis result.\n    \"\"\"\n    tea_tasting.utils.check_scalar(variant, \"variant\", typ=str | None)\n    dfs = read_granular(\n        data,\n        cols=self.cols,\n        variant=variant,\n    )\n    return self.analyze_granular(\n        control=dfs[control],\n        treatment=dfs[treatment],\n    )\n</code></pre>"},{"location":"api/metrics/resampling/#tea_tasting.metrics.resampling.Bootstrap.analyze_granular","title":"<code>analyze_granular(control, treatment)</code>","text":"<p>Analyze metric in an experiment using granular data.</p> <p>Parameters:</p> Name Type Description Default <code>control</code> <code>Table</code> <p>Control data.</p> required <code>treatment</code> <code>Table</code> <p>Treatment data.</p> required <p>Returns:</p> Type Description <code>BootstrapResult</code> <p>Analysis result.</p> Source code in <code>src/tea_tasting/metrics/resampling.py</code> <pre><code>def analyze_granular(\n    self,\n    control: pa.Table,\n    treatment: pa.Table,\n) -&gt; BootstrapResult:\n    \"\"\"Analyze metric in an experiment using granular data.\n\n    Args:\n        control: Control data.\n        treatment: Treatment data.\n\n    Returns:\n        Analysis result.\n    \"\"\"\n    def statistic(\n        contr: npt.NDArray[np.number],\n        treat: npt.NDArray[np.number],\n        axis: int = -1,\n    ) -&gt; npt.NDArray[np.number]:\n        contr_stat = self.statistic(contr, axis=axis)\n        treat_stat = self.statistic(treat, axis=axis)\n\n        effect_size = treat_stat - contr_stat\n        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n            rel_effect_size = np.divide(treat_stat, contr_stat) - 1\n\n        return np.stack((effect_size, rel_effect_size), axis=0)\n\n    contr = _select_as_numpy(control, self.columns)\n    treat = _select_as_numpy(treatment, self.columns)\n    stat = statistic(contr, treat, axis=0)\n\n    result = scipy.stats.bootstrap(\n        (contr, treat),\n        statistic,\n        n_resamples=self.n_resamples,\n        batch=self.batch,\n        axis=0,\n        confidence_level=self.confidence_level,\n        alternative=self.alternative,\n        method=self.method,\n        random_state=self.random_state,  # type: ignore\n    )\n    ci = result.confidence_interval\n\n    return BootstrapResult(\n        control=self.statistic(contr, axis=0),  # type: ignore\n        treatment=self.statistic(treat, axis=0),  # type: ignore\n        effect_size=stat[0],\n        effect_size_ci_lower=ci.low[0],\n        effect_size_ci_upper=ci.high[0],\n        rel_effect_size=stat[1],\n        rel_effect_size_ci_lower=ci.low[1],\n        rel_effect_size_ci_upper=ci.high[1],\n    )\n</code></pre>"},{"location":"api/metrics/resampling/#tea_tasting.metrics.resampling.BootstrapResult","title":"<code>BootstrapResult</code>","text":"<p>               Bases: <code>NamedTuple</code></p> <p>Result of the analysis using bootstrap resampling.</p> <p>Attributes:</p> Name Type Description <code>control</code> <code>float</code> <p>Control statistic value.</p> <code>treatment</code> <code>float</code> <p>Treatment statistic value.</p> <code>effect_size</code> <code>float</code> <p>Absolute effect size. Difference between the two statistic values.</p> <code>effect_size_ci_lower</code> <code>float</code> <p>Lower bound of the absolute effect size confidence interval.</p> <code>effect_size_ci_upper</code> <code>float</code> <p>Upper bound of the absolute effect size confidence interval.</p> <code>rel_effect_size</code> <code>float</code> <p>Relative effect size. Difference between the two statistic values, divided by the control statistic value.</p> <code>rel_effect_size_ci_lower</code> <code>float</code> <p>Lower bound of the relative effect size confidence interval.</p> <code>rel_effect_size_ci_upper</code> <code>float</code> <p>Upper bound of the relative effect size confidence interval.</p>"},{"location":"api/metrics/resampling/#tea_tasting.metrics.resampling.Quantile","title":"<code>Quantile(column, q=0.5, *, alternative=None, confidence_level=None, n_resamples=None, method='basic', batch=None, random_state=None)</code>","text":"<p>               Bases: <code>Bootstrap</code></p> <p>Metric for the analysis of quantiles using bootstrap resampling.</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>Name of the column for the quantiles to compute.</p> required <code>q</code> <code>float</code> <p>Probability for the quantiles to compute.</p> <code>0.5</code> <code>alternative</code> <code>Literal['two-sided', 'greater', 'less'] | None</code> <p>Alternative hypothesis:</p> <ul> <li><code>\"two-sided\"</code>: the means are unequal,</li> <li><code>\"greater\"</code>: the mean in the treatment variant is greater than the mean     in the control variant,</li> <li><code>\"less\"</code>: the mean in the treatment variant is less than the mean     in the control variant.</li> </ul> <code>None</code> <code>confidence_level</code> <code>float | None</code> <p>Confidence level for the confidence interval.</p> <code>None</code> <code>n_resamples</code> <code>int | None</code> <p>The number of resamples performed to form the bootstrap distribution of the statistic.</p> <code>None</code> <code>method</code> <code>Literal['percentile', 'basic', 'bca']</code> <p>Whether to return the \"percentile\" bootstrap confidence interval (<code>\"percentile\"</code>), the \"basic\" (AKA \"reverse\") bootstrap confidence interval (<code>\"basic\"</code>), or the bias-corrected and accelerated bootstrap confidence interval (<code>\"bca\"</code>).</p> <p>Default method is \"basic\" which is different from default method \"bca\" in <code>Bootstrap</code>. The \"bca\" confidence intervals cannot be calculated when the bootstrap distribution is degenerate (e.g. all elements are identical). This is often the case for the quantile metrics.</p> <code>'basic'</code> <code>batch</code> <code>int | None</code> <p>The number of resamples to process in each vectorized call to statistic. Memory usage is O(<code>batch * n</code>), where <code>n</code> is the sample size. Default is <code>None</code>, in which case <code>batch = n_resamples</code> (or <code>batch = max(n_resamples, n)</code> for method=\"bca\").</p> <code>None</code> <code>random_state</code> <code>int | Generator | SeedSequence | None</code> <p>Pseudorandom number generator state used to generate resamples.</p> <code>None</code> Parameter defaults <p>Defaults for parameters <code>alternative</code>, <code>confidence_level</code>, and <code>n_resamples</code> can be changed using the <code>config_context</code> and <code>set_context</code> functions. See the Global configuration reference for details.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import tea_tasting as tt\n\n&gt;&gt;&gt; experiment = tt.Experiment(\n...     revenue_per_user_p80=tt.Quantile(\"revenue\", 0.8, random_state=42),\n... )\n&gt;&gt;&gt; data = tt.make_users_data(seed=42)\n&gt;&gt;&gt; result = experiment.analyze(data)\n&gt;&gt;&gt; result\n              metric control treatment rel_effect_size rel_effect_size_ci pvalue\nrevenue_per_user_p80    10.6      11.6            9.1%       [-1.2%, 21%]      -\n</code></pre> Source code in <code>src/tea_tasting/metrics/resampling.py</code> <pre><code>def __init__(\n    self,\n    column: str,\n    q: float = 0.5,\n    *,\n    alternative: Literal[\"two-sided\", \"greater\", \"less\"] | None = None,\n    confidence_level: float | None = None,\n    n_resamples: int | None = None,\n    method: Literal[\"percentile\", \"basic\", \"bca\"] = \"basic\",\n    batch: int | None = None,\n    random_state: int | np.random.Generator | np.random.SeedSequence | None = None,\n) -&gt; None:\n    \"\"\"Metric for the analysis of quantiles using bootstrap resampling.\n\n    Args:\n        column: Name of the column for the quantiles to compute.\n        q: Probability for the quantiles to compute.\n        alternative: Alternative hypothesis:\n\n            - `\"two-sided\"`: the means are unequal,\n            - `\"greater\"`: the mean in the treatment variant is greater than the mean\n                in the control variant,\n            - `\"less\"`: the mean in the treatment variant is less than the mean\n                in the control variant.\n\n        confidence_level: Confidence level for the confidence interval.\n        n_resamples: The number of resamples performed to form\n            the bootstrap distribution of the statistic.\n        method: Whether to return the \"percentile\" bootstrap confidence\n            interval (`\"percentile\"`), the \"basic\" (AKA \"reverse\") bootstrap\n            confidence interval (`\"basic\"`), or the bias-corrected\n            and accelerated bootstrap confidence interval (`\"bca\"`).\n\n            Default method is \"basic\" which is different from default\n            method \"bca\" in `Bootstrap`. The \"bca\" confidence intervals cannot\n            be calculated when the bootstrap distribution is degenerate\n            (e.g. all elements are identical). This is often the case for the\n            quantile metrics.\n\n        batch: The number of resamples to process in each vectorized call\n            to statistic. Memory usage is O(`batch * n`), where `n` is\n            the sample size. Default is `None`, in which case `batch = n_resamples`\n            (or `batch = max(n_resamples, n)` for method=\"bca\").\n        random_state: Pseudorandom number generator state used\n            to generate resamples.\n\n    Parameter defaults:\n        Defaults for parameters `alternative`, `confidence_level`,\n        and `n_resamples` can be changed using the\n        `config_context` and `set_context` functions.\n        See the [Global configuration](https://tea-tasting.e10v.me/api/config/)\n        reference for details.\n\n    Examples:\n        ```pycon\n        &gt;&gt;&gt; import tea_tasting as tt\n\n        &gt;&gt;&gt; experiment = tt.Experiment(\n        ...     revenue_per_user_p80=tt.Quantile(\"revenue\", 0.8, random_state=42),\n        ... )\n        &gt;&gt;&gt; data = tt.make_users_data(seed=42)\n        &gt;&gt;&gt; result = experiment.analyze(data)\n        &gt;&gt;&gt; result\n                      metric control treatment rel_effect_size rel_effect_size_ci pvalue\n        revenue_per_user_p80    10.6      11.6            9.1%       [-1.2%, 21%]      -\n\n        ```\n    \"\"\"  # noqa: E501\n    self.column = tea_tasting.utils.check_scalar(column, \"column\", typ=str)\n    self.q = tea_tasting.utils.check_scalar(q, \"q\", typ=float, ge=0, le=1)\n    super().__init__(\n        columns=column,\n        statistic=functools.partial(np.nanquantile, q=q),\n        alternative=alternative,\n        confidence_level=confidence_level,\n        n_resamples=n_resamples,\n        method=method,\n        batch=batch,\n        random_state=random_state,\n    )\n</code></pre>"},{"location":"api/metrics/resampling/#tea_tasting.metrics.resampling.Quantile.cols","title":"<code>cols</code>  <code>property</code>","text":"<p>Columns to be fetched for a metric analysis.</p>"},{"location":"api/metrics/resampling/#tea_tasting.metrics.resampling.Quantile.analyze","title":"<code>analyze(data, control, treatment, variant=None)</code>","text":"<p>Analyze a metric in an experiment.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>IntoFrame | Table | dict[object, Table]</code> <p>Experimental data.</p> required <code>control</code> <code>object</code> <p>Control variant.</p> required <code>treatment</code> <code>object</code> <p>Treatment variant.</p> required <code>variant</code> <code>str | None</code> <p>Variant column name.</p> <code>None</code> <p>Returns:</p> Type Description <code>R</code> <p>Analysis result.</p> Source code in <code>src/tea_tasting/metrics/base.py</code> <pre><code>def analyze(\n    self,\n    data: (\n        narwhals.typing.IntoFrame |\n        ibis.expr.types.Table |\n        dict[object, pa.Table]\n    ),\n    control: object,\n    treatment: object,\n    variant: str | None = None,\n) -&gt; R:\n    \"\"\"Analyze a metric in an experiment.\n\n    Args:\n        data: Experimental data.\n        control: Control variant.\n        treatment: Treatment variant.\n        variant: Variant column name.\n\n    Returns:\n        Analysis result.\n    \"\"\"\n    tea_tasting.utils.check_scalar(variant, \"variant\", typ=str | None)\n    dfs = read_granular(\n        data,\n        cols=self.cols,\n        variant=variant,\n    )\n    return self.analyze_granular(\n        control=dfs[control],\n        treatment=dfs[treatment],\n    )\n</code></pre>"},{"location":"api/metrics/resampling/#tea_tasting.metrics.resampling.Quantile.analyze_granular","title":"<code>analyze_granular(control, treatment)</code>","text":"<p>Analyze metric in an experiment using granular data.</p> <p>Parameters:</p> Name Type Description Default <code>control</code> <code>Table</code> <p>Control data.</p> required <code>treatment</code> <code>Table</code> <p>Treatment data.</p> required <p>Returns:</p> Type Description <code>BootstrapResult</code> <p>Analysis result.</p> Source code in <code>src/tea_tasting/metrics/resampling.py</code> <pre><code>def analyze_granular(\n    self,\n    control: pa.Table,\n    treatment: pa.Table,\n) -&gt; BootstrapResult:\n    \"\"\"Analyze metric in an experiment using granular data.\n\n    Args:\n        control: Control data.\n        treatment: Treatment data.\n\n    Returns:\n        Analysis result.\n    \"\"\"\n    def statistic(\n        contr: npt.NDArray[np.number],\n        treat: npt.NDArray[np.number],\n        axis: int = -1,\n    ) -&gt; npt.NDArray[np.number]:\n        contr_stat = self.statistic(contr, axis=axis)\n        treat_stat = self.statistic(treat, axis=axis)\n\n        effect_size = treat_stat - contr_stat\n        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n            rel_effect_size = np.divide(treat_stat, contr_stat) - 1\n\n        return np.stack((effect_size, rel_effect_size), axis=0)\n\n    contr = _select_as_numpy(control, self.columns)\n    treat = _select_as_numpy(treatment, self.columns)\n    stat = statistic(contr, treat, axis=0)\n\n    result = scipy.stats.bootstrap(\n        (contr, treat),\n        statistic,\n        n_resamples=self.n_resamples,\n        batch=self.batch,\n        axis=0,\n        confidence_level=self.confidence_level,\n        alternative=self.alternative,\n        method=self.method,\n        random_state=self.random_state,  # type: ignore\n    )\n    ci = result.confidence_interval\n\n    return BootstrapResult(\n        control=self.statistic(contr, axis=0),  # type: ignore\n        treatment=self.statistic(treat, axis=0),  # type: ignore\n        effect_size=stat[0],\n        effect_size_ci_lower=ci.low[0],\n        effect_size_ci_upper=ci.high[0],\n        rel_effect_size=stat[1],\n        rel_effect_size_ci_lower=ci.low[1],\n        rel_effect_size_ci_upper=ci.high[1],\n    )\n</code></pre>"}]}