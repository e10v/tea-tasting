# /// script
# requires-python = ">=3.10"
# dependencies = [
#     "marimo",
#     "polars",
#     "tea-tasting",
# ]
# [tool.marimo.display]
# cell_output = "below"
# ///

import marimo

__generated_with = "0.13.6"
app = marimo.App()


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        # User guide

        ## Installation

        ```bash
        uv pip install tea-tasting
        ```

        Install Pandas or Polars to serialize analysis results as a Pandas DataFrame or a Polars DataFrame, respectively. These packages are not installed with tea-tasting by default.

        ## Basic usage

        Begin with this simple example to understand the basic functionality:
        """
    )
    return


@app.cell
def _():
    import tea_tasting as tt

    data = tt.make_users_data(seed=42)
    experiment = tt.Experiment(
        sessions_per_user=tt.Mean("sessions"),
        orders_per_session=tt.RatioOfMeans("orders", "sessions"),
        orders_per_user=tt.Mean("orders"),
        revenue_per_user=tt.Mean("revenue"),
    )
    result = experiment.analyze(data)
    result
    return data, experiment, result, tt


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        In the following sections, each step of this process is explained in detail.

        ### Input data

        The [`make_users_data`](https://tea-tasting.e10v.me/api/datasets/#tea_tasting.datasets.make_users_data) function creates synthetic data for demonstration purposes. This data mimics what you might encounter in an A/B test for an online store. Each row represents an individual user, with the following columns:

        - `user`: The unique identifier for each user.
        - `variant`: The specific variant (e.g., 0 or 1) assigned to each user in the A/B test.
        - `sessions`: The total number of user's sessions.
        - `orders`: The total number of user's orders.
        - `revenue`: The total revenue generated by the user.

        By default, `make_users_data` returns a PyArrow Table:
        """
    )
    return


@app.cell
def _(data):
    data
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        You can control return type using the `return_type` parameter. The other possible output types are Pandas DataFrame and Polars DataFrame. They require Pandas or Polars packages respectively.

        tea-tasting can process data in the form of an Ibis Table or a DataFrame supported by Narwhals:

        - [Ibis](https://github.com/ibis-project/ibis) is a DataFrame API to various data backends. It supports many backends including BigQuery, ClickHouse, DuckDB, PostgreSQL, Snowflake, Spark etc. You can write an SQL query, [wrap](https://ibis-project.org/how-to/extending/sql#backend.sql) it as an Ibis Table and pass it to tea-tasting.
        - [Narwhals](https://github.com/narwhals-dev/narwhals) is a compatibility layer between dataframe libraries. It supports cuDF, Dask, Modin, pandas, Polars, PyArrow dataframes. You can use any of these dataframes as an input to tea-tasting.

        Many statistical tests, such as the Student's t-test or the Z-test, require only aggregated data for analysis. For these tests, tea-tasting retrieves only aggregated statistics like mean and variance instead of downloading all detailed data. See more details in the [guide on data backends](https://tea-tasting.e10v.me/data-backends/).

        tea-tasting assumes that:

        - Data is grouped by randomization units, such as individual users.
        - There is a column indicating the variant of the A/B test (typically labeled as A, B, etc.).
        - All necessary columns for metric calculations (like the number of orders, revenue, etc.) are included in the table.

        ### A/B test definition

        The [`Experiment`](https://tea-tasting.e10v.me/api/experiment/#tea_tasting.experiment.Experiment) class defines parameters of an A/B test: metrics and a variant column name. There are two ways to define metrics:

        - Using keyword parameters, with metric names as parameter names, and metric definitions as parameter values, as in example above.
        - Using the first argument `metrics` which accepts metrics in a form of dictionary with metric names as keys and metric definitions as values.

        By default, tea-tasting assumes that the A/B test variant is stored in a column named `"variant"`. You can change it using the `variant` parameter of the `Experiment` class.

        Example usage:
        """
    )
    return


@app.cell
def _(tt):
    new_experiment = tt.Experiment(
        {
            "sessions per user": tt.Mean("sessions"),
            "orders per session": tt.RatioOfMeans("orders", "sessions"),
            "orders per user": tt.Mean("orders"),
            "revenue per user": tt.Mean("revenue"),
        },
        variant="variant",
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        ### Metrics

        Metrics are instances of metric classes which define how metrics are calculated. Those calculations include calculation of effect size, confidence interval, p-value and other statistics.

        Use the [`Mean`](https://tea-tasting.e10v.me/api/metrics/mean/#tea_tasting.metrics.mean.Mean) class to compare averages between variants of an A/B test. For example, average number of orders per user, where user is a randomization unit of an experiment. Specify the column containing the metric values using the first parameter `value`.

        Use the [`RatioOfMeans`](https://tea-tasting.e10v.me/api/metrics/mean/#tea_tasting.metrics.mean.RatioOfMeans) class to compare ratios of averages between variants of an A/B test. For example, average number of orders per average number of sessions. Specify the columns containing the numerator and denominator values using parameters `numer` and `denom`.

        Use the following parameters of `Mean` and `RatioOfMeans` to customize the analysis:

        - `alternative`: Alternative hypothesis. The following options are available:
            - `"two-sided"` (default): the means are unequal.
            - `"greater"`: the mean in the treatment variant is greater than the mean in the control variant.
            - `"less"`: the mean in the treatment variant is less than the mean in the control variant.
        - `confidence_level`: Confidence level of the confidence interval. Default is `0.95`.
        - `equal_var`: Defines whether equal variance is assumed. If `True`, pooled variance is used for the calculation of the standard error of the difference between two means. Default is `False`.
        - `use_t`: Defines whether to use the Student's t-distribution (`True`) or the Normal distribution (`False`). Default is `True`.

        Example usage:
        """
    )
    return


@app.cell
def _(tt):
    another_experiment = tt.Experiment(
        sessions_per_user=tt.Mean("sessions", alternative="greater"),
        orders_per_session=tt.RatioOfMeans("orders", "sessions", confidence_level=0.9),
        orders_per_user=tt.Mean("orders", equal_var=True),
        revenue_per_user=tt.Mean("revenue", use_t=False),
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        Look for other supported metrics in the [Metrics](https://tea-tasting.e10v.me/api/metrics/index/) reference.

        You can change default values of these four parameters using the [global settings](#global-settings).

        ### Analyzing and retrieving experiment results

        After defining an experiment and metrics, you can analyze the experiment data using the [`analyze`](https://tea-tasting.e10v.me/api/experiment/#tea_tasting.experiment.Experiment.analyze) method of the `Experiment` class. This method takes data as an input and returns an `ExperimentResult` object with experiment result.
        """
    )
    return


@app.cell
def _(data, experiment):
    new_result = experiment.analyze(data)
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        By default, tea-tasting assumes that the variant with the lowest ID is a control. Change default behavior using the `control` parameter:
        """
    )
    return


@app.cell
def _(data, experiment):
    result_with_non_default_control = experiment.analyze(data, control=1)
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        [`ExperimentResult`](https://tea-tasting.e10v.me/api/experiment/#tea_tasting.experiment.ExperimentResult) is a mapping. Get a metric's analysis result using metric name as a key.
        """
    )
    return


@app.cell
def _(result):
    import pprint

    pprint.pprint(result["orders_per_user"]._asdict())
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        Fields in result depend on metrics. For `Mean` and `RatioOfMeans`, the [fields include](https://tea-tasting.e10v.me/api/metrics/mean/#tea_tasting.metrics.mean.MeanResult):

        - `metric`: Metric name.
        - `control`: Mean or ratio of means in the control variant.
        - `treatment`: Mean or ratio of means in the treatment variant.
        - `effect_size`: Absolute effect size. Difference between two means.
        - `effect_size_ci_lower`: Lower bound of the absolute effect size confidence interval.
        - `effect_size_ci_upper`: Upper bound of the absolute effect size confidence interval.
        - `rel_effect_size`: Relative effect size. Difference between two means, divided by the control mean.
        - `rel_effect_size_ci_lower`: Lower bound of the relative effect size confidence interval.
        - `rel_effect_size_ci_upper`: Upper bound of the relative effect size confidence interval.
        - `pvalue`: P-value
        - `statistic`: Statistic (standardized effect size).

        [`ExperimentResult`](https://tea-tasting.e10v.me/api/experiment/#tea_tasting.experiment.ExperimentResult) provides the following methods to serialize and view the experiment result:

        - `to_dicts`: Convert the result to a sequence of dictionaries.
        - `to_arrow`: Convert the result to a PyArrow Table.
        - `to_pandas`: Convert the result to a Pandas DataFrame. Requires Pandas to be installed.
        - `to_polars`: Convert the result to a Polars DataFrame. Requires Polars to be installed.
        - `to_pretty_dicts`: Convert the result to a sequence of dictionaries with formatted values (as strings).
        - `to_string`: Convert the result to a string.
        - `to_html`: Convert the result to HTML.

        `result` is the same as `print(result.to_string())`. `ExperimentResult` provides also the `_repr_html_` method and is rendered as HTML table in IPython, Jupyter, or Marimo.
        """
    )
    return


@app.cell
def _(result):
    result
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        By default, methods `to_pretty_dicts`, `to_string`, and `to_html` return a predefined list of attributes. This list can be customized:
        """
    )
    return


@app.cell
def _(result):
    result.with_keys((
        "metric",
        "control",
        "treatment",
        "effect_size",
        "effect_size_ci",
    ))
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        Or:
        """
    )
    return


@app.cell
def _(result):
    print(result.to_string(keys=(
        "metric",
        "control",
        "treatment",
        "effect_size",
        "effect_size_ci",
    )))
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        ## More features

        ### Variance reduction with CUPED/CUPAC

        tea-tasting supports variance reduction with CUPED/CUPAC, within both [`Mean`](https://tea-tasting.e10v.me/api/metrics/mean/#tea_tasting.metrics.mean.Mean) and [`RatioOfMeans`](https://tea-tasting.e10v.me/api/metrics/mean/#tea_tasting.metrics.mean.RatioOfMeans) classes.

        Example usage:
        """
    )
    return


@app.cell
def _(tt):
    data_cuped = tt.make_users_data(seed=42, covariates=True)
    experiment_cuped = tt.Experiment(
        sessions_per_user=tt.Mean("sessions", "sessions_covariate"),
        orders_per_session=tt.RatioOfMeans(
            numer="orders",
            denom="sessions",
            numer_covariate="orders_covariate",
            denom_covariate="sessions_covariate",
        ),
        orders_per_user=tt.Mean("orders", "orders_covariate"),
        revenue_per_user=tt.Mean("revenue", "revenue_covariate"),
    )
    result_cuped = experiment_cuped.analyze(data_cuped)
    result_cuped
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        Set the `covariates` parameter of the `make_users_data` functions to `True` to add the following columns with pre-experimental data:

        - `sessions_covariate`: Number of sessions before the experiment.
        - `orders_covariate`: Number of orders before the experiment.
        - `revenue_covariate`: Revenue before the experiment.

        Define the metrics' covariates:

        - In `Mean`, specify the covariate using the `covariate` parameter.
        - In `RatioOfMeans`, specify the covariates for the numerator and denominator using the `numer_covariate` and `denom_covariate` parameters, respectively.

        ### Sample ratio mismatch check

        The [`SampleRatio`](https://tea-tasting.e10v.me/api/metrics/proportion/#tea_tasting.metrics.proportion.SampleRatio) class in tea-tasting detects mismatches in the sample ratios of different variants of an A/B test.

        Example usage:
        """
    )
    return


@app.cell
def _(data, tt):
    experiment_sample_ratio = tt.Experiment(
        orders_per_user=tt.Mean("orders"),
        revenue_per_user=tt.Mean("revenue"),
        sample_ratio=tt.SampleRatio(),
    )
    result_sample_ratio = experiment_sample_ratio.analyze(data)
    result_sample_ratio
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        By default, `SampleRatio` expects equal number of observations across all variants. To specify a different ratio, use the `ratio` parameter. It accepts two types of values:

        - Ratio of the number of observation in treatment relative to control, as a positive number. Example: `SampleRatio(0.5)`.
        - A dictionary with variants as keys and expected ratios as values. Example: `SampleRatio({"A": 2, "B": 1})`.

        The `method` parameter determines the statistical test to apply:

        - `"auto"`: Apply exact binomial test if the total number of observations is less than 1000, or normal approximation otherwise.
        - `"binom"`: Apply exact binomial test.
        - `"norm"`: Apply normal approximation of the binomial distribution.

        The [result](https://tea-tasting.e10v.me/api/metrics/proportion/#tea_tasting.metrics.proportion.SampleRatioResult) of the sample ratio mismatch includes the following attributes:

        - `metric`: Metric name.
        - `control`: Number of observations in control.
        - `treatment`: Number of observations in treatment.
        - `pvalue`: P-value

        ### Global settings

        In tea-tasting, you can change defaults for the following parameters:

        - `alternative`: Alternative hypothesis.
        - `confidence_level`: Confidence level of the confidence interval.
        - `equal_var`: If `False`, assume unequal population variances in calculation of the standard deviation and the number of degrees of freedom. Otherwise, assume equal population variance and calculate pooled standard deviation.
        - `n_resamples`: The number of resamples performed to form the bootstrap distribution of a statistic.
        - `use_t`: If `True`, use Student's t-distribution in p-value and confidence interval calculations. Otherwise use Normal distribution.
        - And [more](https://tea-tasting.e10v.me/api/config/#tea_tasting.config.config_context).

        Use [`get_config`](https://tea-tasting.e10v.me/api/config/#tea_tasting.config.get_config) with the option name as a parameter to get a global option value:
        """
    )
    return


@app.cell
def _(tt):
    tt.get_config("equal_var")
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        Use [`get_config`](https://tea-tasting.e10v.me/api/config/#tea_tasting.config.get_config) without parameters to get a dictionary of global options:
        """
    )
    return


@app.cell
def _(tt):
    global_config = tt.get_config()
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        Use [`set_config`](https://tea-tasting.e10v.me/api/config/#tea_tasting.config.set_config) to set a global option value:
        """
    )
    return


@app.cell
def _(tt):
    tt.set_config(equal_var=True, use_t=False)
    experiment_with_config = tt.Experiment(
        sessions_per_user=tt.Mean("sessions"),
        orders_per_session=tt.RatioOfMeans("orders", "sessions"),
        orders_per_user=tt.Mean("orders"),
        revenue_per_user=tt.Mean("revenue"),
    )
    tt.set_config(equal_var=False, use_t=True)
    orders_per_user = experiment_with_config.metrics["orders_per_user"]
    print(
        f"orders_per_user.equal_var: {orders_per_user.equal_var}\n"
        f"orders_per_user.use_t: {orders_per_user.use_t}"
    )
    return (experiment_with_config,)


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        Use [`config_context`](https://tea-tasting.e10v.me/api/config/#tea_tasting.config.config_context) to temporarily set a global option value within a context:
        """
    )
    return


@app.cell
def _(experiment_with_config, tt):
    with tt.config_context(equal_var=True, use_t=False):
        experiment_within_context = tt.Experiment(
            sessions_per_user=tt.Mean("sessions"),
            orders_per_session=tt.RatioOfMeans("orders", "sessions"),
            orders_per_user=tt.Mean("orders"),
            revenue_per_user=tt.Mean("revenue"),
        )

    orders_per_user_context = experiment_with_config.metrics["orders_per_user"]
    print(
        f"global_config.equal_var: {tt.get_config('equal_var')}\n"
        f"global_config.use_t: {tt.get_config('use_t')}\n\n"
        f"orders_per_user_context.equal_var: {orders_per_user_context.equal_var}\n"
        f"orders_per_user_context.use_t: {orders_per_user_context.use_t}"
    )
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        ### More than two variants

        /// admonition | Note

        This guide uses [Polars](https://github.com/pola-rs/polars) as an example data backend. Install Polars in addition to tea-tasting to reproduce the examples:

        ```bash
        uv pip install polars
        ```

        ///

        In tea-tasting, it's possible to analyze experiments with more than two variants. However, the variants will be compared in pairs through two-sample statistical tests.

        Example usage:
        """
    )
    return


@app.cell
def _(experiment, tt):
    import polars as pl

    data_three_variants = pl.concat((
        tt.make_users_data(seed=42, return_type="polars"),
        tt.make_users_data(seed=21, return_type="polars")
            .filter(pl.col("variant").eq(1))
            .with_columns(variant=pl.lit(2, pl.Int64)),
    ))
    results = experiment.analyze(data_three_variants, control=0, all_variants=True)
    results
    return data_three_variants, results


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        How variant pairs are determined:

        - Specified control variant: If a specific variant is set as `control`, as in the example above, it is then compared against each of the other variants.
        - Default control variant: When the `control` parameter of the `analyze` method is set to `None`, tea-tasting automatically compares each variant pair. The variant with the lowest ID in each pair is a control.

        Example usage without specifying a control variant:
        """
    )
    return


@app.cell
def _(data_three_variants, experiment):
    results_all = experiment.analyze(data_three_variants, all_variants=True)
    results_all
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        The result of the analysis is a mapping of `ExperimentResult` objects with tuples (control, treatment) as keys. You can view the result for a selected pair of variants:
        """
    )
    return


@app.cell
def _(results):
    results[0, 1]
    return


@app.cell(hide_code=True)
def _(mo):
    mo.md(
        r"""
        By default, tea-tasting does not adjust for multiple hypothesis testing. However, it provides several methods for multiple testing correction. For more details, see the [guide on multiple hypothesis testing](https://tea-tasting.e10v.me/multiple-testing/).
        """
    )
    return


@app.cell(hide_code=True)
def _():
    import marimo as mo
    return (mo,)


if __name__ == "__main__":
    app.run()
